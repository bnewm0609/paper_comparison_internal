{"id": 50768534, "updated": "2023-10-02 20:10:00.053", "metadata": {"title": "Learning from History and Present: Next-item Recommendation via Discriminatively Exploiting User Behaviors", "authors": "[{\"first\":\"Zhi\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Hongke\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Qi\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Zhenya\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Tao\",\"last\":\"Mei\",\"middle\":[]},{\"first\":\"Enhong\",\"last\":\"Chen\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2018, "month": 8, "day": 3}, "abstract": "In the modern e-commerce, the behaviors of customers contain rich information, e.g., consumption habits, the dynamics of preferences. Recently, session-based recommendations are becoming popular to explore the temporal characteristics of customers' interactive behaviors. However, existing works mainly exploit the short-term behaviors without fully taking the customers' long-term stable preferences and evolutions into account. In this paper, we propose a novel Behavior-Intensive Neural Network (BINN) for next-item recommendation by incorporating both users' historical stable preferences and present consumption motivations. Specifically, BINN contains two main components, i.e., Neural Item Embedding, and Discriminative Behaviors Learning. Firstly, a novel item embedding method based on user interactions is developed for obtaining an unified representation for each item. Then, with the embedded items and the interactive behaviors over item sequences, BINN discriminatively learns the historical preferences and present motivations of the target users. Thus, BINN could better perform recommendations of the next items for the target users. Finally, for evaluating the performances of BINN, we conduct extensive experiments on two real-world datasets, i.e., Tianchi and JD. The experimental results clearly demonstrate the effectiveness of BINN compared with several state-of-the-art methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1808.01075", "mag": "3106062149", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1808-01075", "doi": "10.1145/3219819.3220014"}}, "content": {"source": {"pdf_hash": "c49ac198c524f485cb9aecbaff6505c7fb7096e1", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1808.01075v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1808.01075", "status": "GREEN"}}, "grobid": {"id": "eea25660e6d56c14966bf1c2a298517b5f3b6b97", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c49ac198c524f485cb9aecbaff6505c7fb7096e1.txt", "contents": "\nLearning from History and Present: Next-item Recommendation via Discriminatively Exploiting User Behaviors\n\n\nZhi Li \nAnhui Province Key Laboratory of Big Data Analysis and Application\nUniversity of Science and Technology of China\n\n\nSchool of Software Engineering\nUniversity of Science and Technology of China\n\n\nHongke Zhao \nAnhui Province Key Laboratory of Big Data Analysis and Application\nUniversity of Science and Technology of China\n\n\nQi Liu \nAnhui Province Key Laboratory of Big Data Analysis and Application\nUniversity of Science and Technology of China\n\n\nZhenya Huang huangzhy@mail.ustc.edu.cn \nAnhui Province Key Laboratory of Big Data Analysis and Application\nUniversity of Science and Technology of China\n\n\nTao Mei tmei@jd.com \nJD AI Research\n\n\nEnhong Chen cheneh@ustc.edu.cn \nAnhui Province Key Laboratory of Big Data Analysis and Application\nUniversity of Science and Technology of China\n\n\nLearning from History and Present: Next-item Recommendation via Discriminatively Exploiting User Behaviors\n10.1145/3219819.3220014Next-item RecommendationSequential BehaviorsItem Embed- dingRecurrent Neural Networks\nIn the modern e-commerce, the behaviors of customers contain rich information, e.g., consumption habits, the dynamics of preferences. Recently, session-based recommendations are becoming popular to explore the temporal characteristics of customers' interactive behaviors. However, existing works mainly exploit the short-term behaviors without fully taking the customers' longterm stable preferences and evolutions into account. In this paper, we propose a novel Behavior-Intensive Neural Network (BINN) for next-item recommendation by incorporating both users' historical stable preferences and present consumption motivations. Specifically, BINN contains two main components, i.e., Neural Item Embedding, and Discriminative Behaviors Learning. Firstly, a novel item embedding method based on user interactions is developed for obtaining an unified representation for each item. Then, with the embedded items and the interactive behaviors over item sequences, BINN discriminatively learns the historical preferences and present motivations of the target users. Thus, BINN could better perform recommendations of the next items for the target users. Finally, for evaluating the performances of BINN, we conduct extensive experiments on two real-world datasets, i.e., Tianchi and JD. The experimental results clearly demonstrate the effectiveness of BINN compared with several state-of-the-art methods.\n\nINTRODUCTION\n\nRecommender system, as an essential component of modern ecommerce websites, tries to predict what the most suitable products or services are of users, based on the users' preferences [30]. With the mechanism development of e-commerce, a massive amount of customer interactions (e.g., browse, click, collect, cart, purchase) have been logged, which imply luxuriant consumption patterns. These information-rich logs provide opportunities for understanding customers' historical stable preferences and also their present consumption motivations, which may further contribute to smarter recommendations.\n\nAlong this line, there is a particular interest in understanding interactive behaviors of customers. Existing works can be concluded into two main paradigms. The first paradigm is the general recommenders. These works focus on mining the static relevancy between users and items from interactions, which are represented by the traditional collaborative filtering models [18,22,40]. For example, Zhang et al. made recommendations through a factorization model with different item semantic representations from the knowledge base [40]. However, most of these works have taken user-item specific relationships into consideration from the static views but neglect the dynamics and evolutions of users' preferences implied in sequential interactions. The other paradigm is recommending next items based on sequential pattern mining [34,39] or transition modeling [29,42]. Along this line, researchers recently show more interest in an e-commerce scenario where user profiles are invisible so that recommender systems are developed based on the user interactions in short sessions [15,19,27]. These session-based models have provided the comprehension about users' decision-making process in a short term, but the dynamics of preferences [38] and how to perfectly integrate both the historical stable preferences with present consumption motivations are still largely unexplored.\n\nActually, as a user's interactive behaviors naturally form a behavioral sequence over time, the user's historical preferences from the long-term view and present motivations or demands from the short-term view can be dynamically revealed. For instance, Figure 1 illustrates a typical online shopping scenario. The user's historical interactions imply that this user might be a \"Star Wars\" fan since that the user has bought or collected various spin-off products of the \"Star Wars\". Moreover, we infer that this user would like to buy dark T-shirts because a black shirt is included in the personal cart and the user has browsed many short sleeve shirts. However, following the general collaborative filtering approaches, another spin-off product may be recommended since all the preference behaviors of the user's entire history are exploited in the static manners as shown in the blue chart of Figure 1. By contraries, if we only consider the current session behaviors of this user in accordance with what the session-based models do, another similar or popular shirt would be recommended as shown in the green chart of Figure 1. Actually, by exploiting both the historical stable preferences and present consumption motivations of this user, more attention should be paid to short sleeve shirts and the \"Star Wars\" graphic T-shirts perfectly match user's tastes. Therefore, we can conclude that a smarter recommender system should not only consider users' historical stable preferences but also take into account the present consumption motivations by discriminatively exploiting different terms or types of user behaviors.\n\nBased on the intuition and observations, we propose a novel solution framework called Behavior-Intensive Neural Network (BINN) to address the next-item recommendation problem. Our BINN framework contains two main components: Neural Item Embedding and Discriminative Behaviors Learning. Specially, we propose a novel neural item embedding method to obtain a unified item representation space for learning latent vectors which could capture the sequential similarities between items. Different from the traditional item embedding methods which are based on inherent features such as item images or text descriptions, our neural item embedding method generates item representations by means of exploiting users' collaborative sequential interactions over items directly. Then, with the item embedded, we design two different behavior alignments, i.e., Session Behaviors Learning and Preference Behaviors Learning to respectively model users' present consumption motivations and historical stable preferences by discriminatively exploring interactive behaviors of users. Specific to the alignments, we respectively develop two deep neural network architectures to jointly learn the session behaviors and preference behaviors. Finally, by matching the potentially preferred items in the latent space, BINN generates recommendations for the target users. For evaluating the performances of BINN, we conduct extensive experiments on two real-world datasets. The experimental results clearly demonstrate the effectiveness of BINN compared with several state-of-the-art methods. In summary, the main contributions of this study can be summarized as follows.\n\n\u2022 We propose to make item-recommendation by integrating both the historical preferences and present motivations of users, which are all learned from the users' interactive behaviors.\n\n\u2022 We propose a novel Behavior-Intensive Neural Network (BINN) which includes embedding items by users' interactions and discriminative behavior alignments accompanied by two applicable neural network architectures.\n\n\u2022 We conduct extensive experiments on two real-world datasets.\n\nThe results show that BINN model outperforms other state-ofthe-art methods from various aspects.\n\n\nRELATED WORKS\n\nRecommender systems play an essential role in many Internetbased services [30], such as e-commerces, and have arouse the great attention from both industry and academia. The relevant works of this study can be concluded into two main paradigms: the General Recommenders and the Sequential Recommenders.\n\n\nGeneral Recommenders\n\nMost of the general recommenders focus on mining the static relevancy between users and items from their interactions, which are represented by the traditional collaborative filtering models [18,22,25]. More specifically, the most common approaches of collaborative filtering are the neighborhood methods [2,17,20,31,43] and the factorization models [4,13,14,25,41]. Neighborhood Methods are based on the similarities of entities (always users or items) and recommend the nearest neighbor items through the precomputed similarities [2,17,31,43]. For example, Bell et al. proposed a new method to simultaneously derive interpolation weights for all nearest neighbors, leading to a substantial improvement of prediction accuracy [2]. Zhao et al. considered the expertise of investors to improve the neighborhood methods for the personalized investment recommendations in P2P lending [43]. Wang et al. presented a basic probabilistic framework which formalized the learning similarity as a regression problem [35]. Moreover, they introduced a novel multi-layer similarity descriptor which modeled the joint influences of different features to improve the neighborhood methods [35].\n\nFactorization Models treat the recommendation as a user-item matrix reconstruction problem and model the user-item interactions by dot product of latent vectors [21,25,41]. Many previous works focused on better representing users or items to improve the qualities of recommender systems. For example, Liu et al. considered users' indecisiveness when the customers chose among competing product options and then proposed IMF method to mine the indecisiveness in customer behaviors to improve the performance of recommendation [22]. Zhao et al. introduced the Nash Equilibrium into the matrix factorization method to solve the group recommendation problem [41]. In recent years, deep learning has also been applied successfully to the classical collaborative filtering user-item matrix reconstruction problems from different perspectives. For example, many researches incorporated deep learning models for extracting and fusing side features, such as image features [12], text information [8,33] and multimode data [40]. Moreover, some works developed the deep neural networks to learn the relationships between the users and items [11,13].\n\nHowever, most of these works provide recommendations by mining the static relevancy between users and items. The dynamics and evolutions of users' preferences, and also their present consumption motivations are usually not given special attentions.\n\n\nSequential Recommenders\n\nIn recent years, researchers start to focus on various sequential recommendation scenarios, such as next-basket [29,36], sessionbased [15,19,27] and next-item recommendations [6,39]. Among them, session-based ones are increasingly attractive.\n\nEarly works on sequential recommenders are almost based on the sequential pattern mining [34,39] and the transition modeling [29,42]. Due to the tremendous success of deep neural networks in the past few years, approaches to sequence data modeling have made significant strides and benefit a broad range of applications, such as NLP [9], social media [37] and recommendations [15,19,27]. For example, Hidasi et al. firstly applied recurrent neural networks (RNNs) by modeling the whole session for session-based recommendations, which outperformed item-based methods significantly [15]. Quadrana et al. focused on some session-based recommendation scenarios where user profiles were readily available and developed a hierarchical recurrent neural networks with cross-session information transfer [27]. Wang et al. used a hierarchical representation model to capture both sequential behaviors and users' general tastes by involving transaction and user representations in next-basket prediction [36]. Donkers et al. extended RNNs by representing the individual users for the purpose of generating personalized next item recommendations [6].\n\nAlthough these models have taken the users' sequential information into consideration, there are still largely unexploited in the coherence of customers' sequential behaviors and the dynamics of historical preferences. Comparatively, in this paper, we propose to make item-recommendation by integrating both the historical preferences and the present motivations of users, which are all learned from the users' rich interactive behaviors over items.\n\n\nBINN: BEHAVIOR-INTENSIVE NEURAL NETWORK\n\nIn this section, we introduce our proposed model for addressing the personalized next-item recommendations. We first formally define the next-item recommendation task and overview the proposed Behavior-Intensive Neural Network (BINN). Then we describe the two main components of BINN in detail, i.e., Neural Item Embedding and Discriminative Behaviors Learning.\n\n\nPreliminaries\n\nNext-item recommendation is the task of predicting what a user would like to access next based on her historical interactions. Here, we give a formulation for the next-item recommendation. As user interactions naturally form a sequence over time, a log history H of the information system is a set of sequential interactions, i.e., H = {S 1 , S 2 , ..., S n }, where |H | = n denotes the number of users. Each user u has a corresponding interaction sequence S u \u2208 H which can be represented as\nS u = {(x 1 , b 1 ), (x 2 , b 2 ), ..., (x T , b T )},\nwhere x j denotes the j-th item that user u operates and b j denotes the behavior type (e.g., click, cart, purchase). Then, the personalized next-item recommendation task can be defined as follow:\nDefinition 1 (Personalized Next-item Recommendation).\nGiven a target user u with her sequential of interactive behaviors over items\nS u = {(x 1 , b 1 ), (x 2 , b 2 ), ..., (x T , b T )}\nand also all users' sequential interactions H , the personalized next-item recommendation task is to predict item x T +1 that the target user u is most likely to access in her next visit.\n\nIn this paper, we address this task with a novel personalized nextitem recommendation framework, i.e., Behavior-Intensive Neural Network (BINN). As shown in Figure 2, BINN contains two main components: Neural Item Embedding and Discriminative Behaviors Learning. Specifically, with a neural embedding model, we obtain a unified item representation space for learning the latent vectors that capture sequential similarities between items. Then we design two interactive behaviors assignments, named Session Behaviors Learning (SBL) and Preference Behaviors learning (PBL), to exploit the users' present consumption motivations and historical stable preferences over time. Finally, we jointly learn these two interactive alignments on the latent space of item representations and recommend top-k potentially preferred items to each target user.\n\n\nNeural Item Embedding\n\nIn the first stage of BINN, Neural Item Embedding aims to generate a unified representation for each item by learning the item similarities from a large number of sequential behaviors over items. Previous works of sequential recommenders always use 1-of-N encoding or add an additional embedding layer in the deep learning architecture to represent items [15,27]. However, for a superb collection of items in the big e-commerce platforms, on one hand, the 1-of-N encoding networks may cost unaffordable time and always cannot to be optimized well because of the high sparsity [3]. On the other hand, adding an additional embedding layer may make networks lose performances to some extend [15]. What's more, both two methods cannot reveal item sequential similarities which is implied in the user interactions. In this case, it is necessary to find an effective representation method to directly learn high-quality item vectors from the users' interaction sequences, with the result that items implied similar attractions tend to be close to each other.\n\nIn recent years, the progress in neural embedding has achieved tremendous advances in many domains, such as NLP [3,24], social networks [5,10,26] and recommendations [1]. Among these works, item2vec [1] is one of the significant extensions of Skip-gram with Negative Sampling [24] to produce item embedding for item-based collaborative filtering recommendations.\n\nIn this paper, we propose an improved item2vec to capture item similarities and generate item representations by the means of exploiting users' collaborative interactions over items directly. Different from the words in sentences, some items in user interactions have often been frequently accessed. The reason for this phenomenon is that users are usually indecisive in their decision-making process [22], causing a lot of repetitive actions on the same item. In addition, these frequently-operated items also indicate users' main motivations, and other items interspersed these repeats may be very similar or competing to these items. On the other hand, items with low frequency may be aimlessly clicked [19], which will bring noise to the item embedding. Along this line, we take one step further to capture the characteristic of interaction sequences and propose a novel item embedding method, called w-item2vec, which considers the frequency of items as a weighted factor. Inspired by item2vec [1], w-item2vec also uses a Skip-gram model with Negative Sampling method [24]. Specifically, given an item sequence S \u2032 u = {x 1 , x 2 , ..., x N } of user u from the interactive sequence S u , the Skip-gram of w-item2vec aims at maximizing the following objective:  \n... v v 2 v 1 v 4 v 3 ... w-item2vec x t +3 x t x t -1 x t +1 x t ... ... -2 x t +1 x t -1 x t +2 x t +2 x t t-1 V t-1 V t-2 V t-3 t-2 t-3 t-ts V t-ts V t i1 i2 i3 im Vim Vi3 Vi2 Vi1 h t-ts h t-3 h t-2 h t-1arg max opt = 1 K K i=1 K j i log p(x j |x i ),(1)\nwhere K is the length of sequence S u , and p(x j |x i ) is defined as the softmax function:\np(x j |x i ) = exp(w T i * v j ) k exp(w T i * v k ) ,(2)\nwhere w i and v i are the latent vectors that correspond to the target and context representations for item x i . For alleviating computational complexity of the gradient \u25bd(x j |x i ), Eq. (2) is always replaced by negative sampling:\np(x j |x i ) = \u03c3 (w T i * v j ) E k =1 \u03c3 (\u2212w T i * v k ),(3)\nwhere \u03c3 (x) = 1/(1 + exp(\u2212x)), E is the number of negative samples to be drawn per a positive sample. Then, we improve the negative sampling model of Eq. (3) 1 by considering the item frequency within interaction sequences as the weight of negative sampling process:\np(x j |x i ) = (\u03c3 \u0398(x i ) (w T i * v j ) k \u03c3 (\u2212w T i * v k )) \u0398(x i ) ,(4)\nwhere \u0398(x i ) is the frequency of item x i in the sequence. Consequently, the Skip-gram objective in Eq. (1) can be redefined as: 1 There is a mistake in the version of ACM Digital Library, we correct it here.\narg max opt = 1 K K i=1 K j i log p(x j |x i ) = 1 K K i=1 K j i \u0398(x i )(\u0398(x i ) * log \u03c3 (w T i * v j ) + E k =1 log \u03c3 (\u2212w T i * v k )).(5)\nFinally, we train the w-item2vec by gradient descent, and obtain high-quality distributed vector representations for all the items.\n\nWith w-item2vec, we can capture item similarities with the help of user interactions and generate an unified item representation space, in which the representation vectors can reveal similarities and sequential relationships of items. And for each user u, we can generate an interaction sequence with embedding items as\nP u = {v 1 , v 2 , ..., v T }, where v j denotes the d-dimensions latent vector of item x j .\n\nDiscriminative Behaviors Learning\n\nAfter obtaining item embeddings, Discriminative Behaviors Learning (DBL) could explore sequential behaviors as prior knowledge to recommend items that the target user is most likely to access in her next visit.\n\nAs illustrated in Figure 1, a user's decision-making process is mainly influenced by two factors: her present motivations and historical preferences. More specifically, users' present consumption motivations are dynamic in a short term and the recent fluctuations are also important to reflect the short-term characteristics. Considering that all the recent behaviors (e.g., click, collect, cart, purchase) may imply users' present motivations in a short term, we use all types of recent behaviors to represent the present consumption motivations. On the other hand, as for exploiting users' historical preferences, not all types of behaviors could depict users' preferences. For example, we can imply that the user do not prefer an item if she just clicks on it without purchasing at last. Therefore, for modeling users' historical preferences, we only remain the behaviors which can clearly depict users' underlying preferences from interaction histories, i.e., purchase behaviors.\n\nIn fact, the interaction process of a user is the series of implicit feedbacks over time. Thus, different from traditional recommender systems which explore the user-item interactions from a static manner, we tackle the next-item recommendation by sequential modeling. Specifically, we design two discriminative behavior alignments: Session Behaviors Learning (SBL) and Preference Behaviors Learning (PBL) to discriminatively learn users' present consumption motivations and historical stable preferences. Further, on this basis, we develop two separate deep neural architectures based on LSTM [16] to jointly learn the motivations and preferences from these two alignments of behaviors.\n\n\nSession Behaviors Learning.\n\nAs illustrated in the green chart of Figure 1, the session behaviors in a short term can reveal the users' present consumption motivations. The Session Behaviors Learning (SBL) is to model the short-term session behaviors of the target user u. More formally, suppose we already have the previous\ninteraction sequence S u = {(x 1 , b 1 ), (x 2 , b 2 ), ..., (x t \u22121 , b t \u22121 )} with embedding items P u = {v 1 , v 2 , ..., v t \u22121 }.\nThe behavior b i can be represented as an one-hot vector and the length of the vector is the number of interaction types, e.g., click. For determining whether a certain item x i would be a possible element of the session behaviors, the SBL discrimination function D S BL can be defined as follows:\nD S BL (x i , x t ) = \u03a6((t \u2212 i) \u2264 ts),(6)\nwhere function \u03a6(a) is to compute a discrimination signal that equals to 1 if a is true and equals to 0 otherwise, x t \u22121 is the previous item of the prediction and ts is a controlling indicator to control the length of SBL. Specifically, as for a session-based scenario, ts is the length of the session. And for the non-session scenarios, ts is artificially specified. In this paper, we set ts to 10 as the default.\n\nAiming at the alignment of session behaviors, we develop a Contextual LSTM (CLSTM) [9] to learn users' present consumption motivations. After the initialization, at j-th interaction step, the hidden state h j of each interaction is updated by the previous hidden state h j\u22121 , the current item embedding v j , and the current behavior vector b j as:\ni j = \u03b4 (W vi v j + W hi h j\u22121 + W ci c j\u22121 + W bi b j + b i ), f j = \u03b4 (W v f v j + W hf h j\u22121 + W c f c j\u22121 + W bf b j + b f ), c j = f j c j\u22121 + i j tanh(W vc v j + W hc h j\u22121 + W bc b j + b c ), o j = \u03b4 (W vo v j + W ho h j\u22121 + W co c j + W bo b j + b o ), h j = o j tanh(c j ),(7)\nwhere i j , f j and o j are the input gate, forget gate and output gate at j-th step respectively, v j is the embedding item vector, b j is the behavior vector, c j is the cell memory, b is the bias term, and h j is the output at j-th step.\n\nWe essentially use the final out state h t \u22121 as the representation of the present consumption motivations of user u, i.e., \u03a8 S BL = h t \u22121 . With the above network structures, SBL can naturally model fluctuations of users' session behaviors to obtain representations of present consumption motivations.\n\n\nPreference Behaviors\n\nLearning. As mentioned above, a smarter recommender system should not only consider users' present consumption motivations but also take into account the historical stable preferences. Therefore, in addition to exploiting motivations by SBL in a short term, PBL is used to learn users' stable historical preferences from the preference behaviors in a long term. Actually, only part of behaviors imply users' preferences. Thus, for determining whether a certain interaction (v i , b i ) \u2208 S u would be a possible element of the preference behaviors, the discrimination D P BL can be defined as:\nD P BL (v i , b i ) = \u03a6(b i \u2208 P),(8)\nwhere P is the preference behavior set which contains the types of preference behaviors i.e., collect, cart and purchase. Different from SBL, PBL is a global representation of historical preferences with less fluctuations. That may make the architecture of SBL can not work well to obtain users' historical preferences. Inspired by Bidirectional RNN [32], we adapt the CLSTM to a bidirectional architecture, named Bi-CLSTM, to make full use of the contextual long-term representation in both forward and backward directions. Specifically, the cell of Bi-CLSTM is the same as Eq. (7) and it can principally be trained with the same algorithms as a regular unidirectional CLSTM. At each time step s of PBL, the forward layer with hidden state \u2212 \u2192 h P s is computed based on both the previous hidden state \u2212 \u2212\u2212 \u2192 h P s\u22121 and the current item-behavior pair (v is , b is ); while the backward layer updates hidden state \u2190 \u2212 h P s with the future state \u2190 \u2212\u2212 \u2212 h P s+1 and the current item-behavior pair (v is , b is ). Therefore, each PBL hidden representation h P s can be calculated with the concatenation of the forward state and backward state, i.e.,\nh P s = concatenate( \u2212 \u2192 h P s , \u2190 \u2212 h P s )\n. After that, we can generate the unified representation of preference behaviors \u03a8 P BL for user u through an average pooling layer:\n\u03a8 P BL = avera\u0434e(h P 1 , h P 2 , ..., h P m ),(9)\nParticularly, taking embedding preference interactions as inputs of above networks, PBL is able to learn and depict the profile of each user. That can help BINN to make a good understanding of users' historical stable preferences.\n\nSo far, from Discriminative Behaviors Learning (DBL), we have modeled two behavior alignments: session behaviors learning \u03a8 S BL and preference behaviors learning \u03a8 P BL . Then, after an fully connected layer, we can generate the d-dimensions representation v t of the next item.\n\n\nModel Learning and Test Stage\n\nTaking embeddings of sequential items as inputs of networks, DBL is able to learn both users' present motivations and historical preferences by controlling recurrent states update of the two network architectures. After DBL, we can generate the prediction of next item representation v t , which is a d-dimensions vector. In the global learning stage, we use Mean Squared Error (MSE) loss [37] function to learn two behavior alignments jointly from the whole set of sequential interactions H , which can be defined as:\nL = 1 |H | S u \u2208H 1 (|S u | \u2212 ts \u2212 1) |S u | t =t s+1 \u03b6 ( v t , v t ),(10)\nwhere \u03b6 is MSE function, v t is the item representation that the target user u is access in the next visit, ts is the controlling indicator, |S u | denotes the length of the interaction sequence S u \u2208 H and |H | is the number of users. The Eq. (10) is minimized using Adagrad optimization [7]. More details of settings will be specified in experiments.\n\nSo far, we have discussed the whole training stage of BINN. After obtaining the trained BINN model, in the testing stage, given an individual interaction history S u = {(x 1 , b 1 ), (x 2 , b 2 ), ..., (x t \u22121 , b t \u22121 )}, we could predict item x t that user u is most likely to access in next visit by the following steps: (1) apply model BINN to fit user interaction process S u to get the user's states \u03a8 S BL and \u03a8 P BL at t \u2212 1 step for prediction; (2) generate the next-item embedding vector v t and compute the similarities to all the item candidates in the latent space which we have obtained in Section 3.2; (3) then we can recommend the top-k potentially preferred items in the unified representation space.\n\n\nEXPERIMENTS\n\nIn this section, we first describe the experimental setups. Then, we demonstrate the effectiveness of proposed framework from the following aspects: (1) the visualization of embedding comparisons between w-item2vec in BINN and traditional item2vec, (2) the comparisons of overall recommendation performances, (3) the analysis on cold-start scenarios and (4) parameter sensitiveness of user interactions.\n\n\nDatasets\n\nSpecifically, we conduct experiments on two real-world datasets, i.e., Tianchi dataset and JD dataset. For the reliability of experimental results, we make the necessary preprocessing as follows. First, we filter the users whose interaction lengths are less than 10 and items that appear less than 5 times. Then we respectively divide two datasets into training sets and test sets according to cut time, where 90% interactions are chosen into the training set and the remaining interactions are used for testing. Figure 3 illustrates strategy of dataset partitioning. In particular, for Tianchi dataset, we use 27 days data for training and the rest 3 days as test set while for JD dataset, we use 68 days data for training and the rest for test. Considering that collaborative filtering methods can not recommend an item which has not appeared before [15], we filter out interactions from test set where items do not appear in the training set. In the same way, we also remove users from test set who do not appear in the training set, but we take special use of this part for analysis on the cold-start scenarios. The statistics of two datasets after preprocessing are shown in Table 1.\n\n\nBaseline Methods\n\nWe compare BINN with three traditional methods (i.e., S-POP, BPR-MF, Item-KNN) and two state-of-the-art RNN-based models (i.e., GRU4Rec, HRNN) each of which contains two specific implements (i.e., GRU4Rec, GRU4Rec Concat and HRNN Init, HRNN All).\n\n\u2022 S-POP recommends the item with the largest number of interactions by the target user. This method works well in the context with high repetitiveness, and the recommendation list changes along with user interactions.  \u2022 BPR-MF [28] is one of widely used matrix factorization methods, which optimizes a pairwise ranking objective function via stochastic gradient descent.\n\n\u2022 Item-KNN [20] selects the items which are similar to the previously accessed items to users.\n\n\u2022 GRU4Rec [15] uses the basic GRU with a TOP1 loss function and session-parallel minibatching.\n\n\u2022 GRU4Rec Concat [15] is similar with GRU4Rec. Differently, we do not use the session-partition, and the users' interaction sequences are fed to the GRU4Rec independently as a whole.\n\n\u2022 HRNN Init [27] is a hierarchical RNN for personalized crosssession recommendations, which is based on GRU4Rec and adds an additional GRU layer to model information across the user's sessions for tracking the evolution of the user's interest. It is a state-of-the-art method in next-item recommendations.\n\n\u2022 HRNN All [27] is similar with HRNN, but the user representation generated by an additional GRU layer is used for initialization and propagated in input as each step of the next session.\n\nFor fair comparisons, we set all the hidden units in the RNNbased models as 100, their dropout probabilities and learning rate as 0.1. The embedding vector for each item is 64-dimensional in BINN model. The BINN and all the compared methods are defined and trained on a Linux server with two 2.20 GHz Intel Xeon E5-2650 v4 CPUs and four Tesla K80 GPUs.\n\n\nEvaluation Metrics\n\nAs recommender systems can suggest few items each time, and the relevant items should be ranked first in the recommendation list. We therefore evaluate the personalized next-item recommendation quality with the following two evaluation metrics.\n\n\u2022 Recall@20. It is the primary evaluation metric that is the proportion of cases having the desired item amongst the top-20 items in all test cases [15,19]. Note that Recall@20 does not discriminate between items with different rankings as long as they are amongst the recommended list. In other word, the rank of items in top-20 candidate set do not make a difference.\n\n\u2022 MRR@20. Another used metric is Mean Reciprocal Rank (MRR), which is the average of reciprocal ranks of the desire items. The same with Recall metric, we set 20 as contributing value, that  means the reciprocal rank is set to zero if the rank is above 20 [15,19]. Considering the the order of recommendations matters, MRR takes the rank of each recommended item into consideration.\n\nIn summary, the higher both two evaluate metrics are, the better performances the results have.\n\n\nExperimental Results\n\nWe first visualize the embedding of our proposed w-item2vec competing with item2vec, and then we show performances on next-item recommendation task. Finally, we discuss the cold-start problem of new users in recommendations and we analyze influences of the interaction lengths.\n\n\nItem Embedding Visualization.\n\nWe apply w-item2vec for generating the item embedding v j for each item x j from Eq. (5), in which item similarities and sequential-behavior relationships over items can be revealed simultaneously. We run the algorithm for 10 epochs and set the negative sampling value E = 10 and compare our method with item2vec [1] on both datasets. We apply the same settings for them.\n\nSince an effective representation method can make the items implied similar attractions tend to be close to each other, we use the item categories to visualize whether the latent representations can reveal the similarities of the items. This is motivated by the assumption that a useful representation would cluster similar items in accordance with their category. To this end, we generate embeddings for 3,000 items which are randomly selected from three categories. We apply t-SNE [23] with a squared euclidean kernel to reduce the dimensionality of item embedding vectors to 2. Then we color each item point according to its category. Figure 4 and 5 present the 2D embedding that are produced by t-SNE, for w-item2vec and item2vec, respectively. As we can see, w-item2vec provides a significantly better clustering on Tianchi and also shows better performance than item2vec on JD since the clustering boundaries in Figure 4(a) and Figure 5(a) are more clear. One possible reason is that w-item2vec takes account of the item frequencies, which makes w-item2vec can generate better representation of items than item2vec. Interestingly, both two methods have shown remarkable results on JD dataset, one possible explanation could be that JD dataset is more dense. As shown in Table 1, JD dataset log much more behavioral interactions on a smaller amount   of items and the average behaviors per item is 1,497.82, which is much larger than Tianchi dataset 13.05 behaviors per item. That makes the model could be trained better. We further observe some outlier items that because many items on either dataset in the same category are not similar to each others.\n\n\nRecommendation Performances.\n\nTo demonstrate the practical significance of our proposed model, we compare BINN with the other methods on the next-item recommendation task. The results of all methods on both Tianchi and JD datasets are shown in Table 2. For the convenience of comparing differences between traditional and RNN-based models, we highlight the improvements of RNN-based models over the best traditional method. From the overall views, our BINN model has achieved the best performances on both two datasets.\n\nFirstly, for the results on Tianchi dataset, we have some interesting observations. BINN performs significantly better than all the other methods on both Recall@20 and MRR@20. The result indicates that BINN framework is good at dealing with personalized sequential information from the user interactions. Comparing with the RNN-based models, we can note that the traditional methods provide more competitive results. We guess a possible reason is that users' interactions on Tianchi have a high degree of repetitiveness and this dateset has a large amount of item candidates when making recommendations. That fact makes the generation of \"non-trivial\" personalized recommendations (i.e., P-POP) very challenging [27]. The comparison among the five RNN-based models highlights the effectiveness to track customers' long-term preferences for next item recommendations, because models with consideration of personalized information (i.e., BINN, HRNN Init, HRNN All) outperform those methods without that (i.e., GRU4Rec, GRU4Rec Concat) on MRR@20.\n\nNext, we turn to the experiments on JD dataset, which exhibits some different results from those on Tianchi dataset. All the RNNbased models (i.e., GRU, HRNN and BINN) significantly outperform the traditional methods, which indicates that RNN-based models do have better abilities to model users' sequential interactions for nextitem recommendations than traditional methods. In addition, the non-personalized RNN-based models GRU4Rec Concat outperforms HRNN All, which indicates that improper personalizing strategy might even make the recommendation performances worse and reveals the importance of the community trends from the shortterm sequential behaviors.\n\nThen, we notice that RNN-based models perform much better on JD dataset than that on Tianchi dataset. One possible explanation could be that JD has more interactions of more users but less merchandises than Tianchi, and that may be a strong sequential recommendation scenario. Moreover, the number of users is much larger than the amount of items on JD dataset (i.e., the statistic of items on Tianchi dataset is 674,326, but 24,744 on JD dataset), that naturally makes the predicting candidate set smaller, and therefore, leads to more accurate result. Actually, this scenario is much common in the real world, such as online retailers and B2C platforms.\n\nIn summary, BINN achieves the best performances on both two datasets, followed by HRNN Init. Both two methods take user-level representations into account. That clearly demonstrates users' interactive behaviors may follow general short-term community trends  and reveal stable long-term preferences. Our BINN discriminatively models the users' historical preferences and present motivations, that leads to superior personalized recommendation quality.\n\n\nCold Start of New Users.\n\nCold start is a common problem of recommender systems that new users or items have not yet gathered sufficient information to recommend or be recommended [30]. As we have removed users from test set that are not in the training set on the above experiments, which is shown in Figure 3 shown, here we focus on these users and examine the performances of our model on cold-start problem of new users.\n\nIndeed, new users have no interactions to be pretrained and recommender systems cannot generate user profiles. That makes many user profile-based recommendation methods cannot work well, especially factorization models. However, for the RNN-based next-item recommendations, we can use a trained neural network to fit new users and predict from their second interactions one-byone and check item rank of the next interaction. Here, we test the recommendation results on fifty items from the beginning of the second ones in the interactions of the target new users. Please note that, we do not change any training process and just select coldstart users for testing, thus all the testing do not need retraining. For better illustration, we report the results of all RNN-based models, using both metrics, respectively.\n\nThe results are shown as Figure 6. In most cases, BINN performs better than the other models on both datasets. At the beginning of the user interactions, our model BINN has deteriorated to CLSTM because of the absence of personalized preferences. Then, with the number of users' interactions growing, our model shows great improvement on recommendation performances. That can indicate the effectiveness of modeling the long-term historical preferences in BINN. What's more, all the deep learning models have shown strong capacity to face the cold-start challenges of new users. Thus, we can conclude that all the RNN-based models can work well for new users. Consequently, the results indicate the effectiveness of BINN structure.\n\n\nAnalysis on the User History Length.\n\nHere, we take further analysis on performances of our BINN model and other RNN-based models. This allows to evaluate personalized recommendation methods under different amounts of historical information and reveal the capacity of users' long-term preference representations. Since we argue the length of the user history has an impact on the recommender system performances, we divide the evaluation by the length of user interactions. Specially, we use the both datasets to make the analysis and partition users into three groups: the historical interactions less than 300, between 300 and 500, and more than 500. On account of our purpose for measuring the impact of the complex long-term preference dynamics used in BINN and other RNN-based models, we respectively record performances on these three user groups. Figure 7 shows the performances on both datasets. Firstly, we pay attention to improvements over the length of user behaviors grows on Tianchi dataset. We can notice that our proposed BINN has a significantly improvement on Recall@20 as the history lengths grow. Then, we turn to the results on JD dataset. For users with largest amount of interactions, our proposed BINN performs best with at least 3.92% improvement compared to other RNN-based models. Interestingly, BINN and both two HRNN models have an improvement with the history length growing, but GRU4Rec and GRU4Rec Concat do not show continuous improvement between 300-500 and larger than 500 scales. In summary, the length of the user interactions does have an impact on the performances of recommender systems. These results clearly demonstrate the effectiveness of exploiting personalized strategies, i.e., users' historical stable preferences, to improve the recommendation performances.\n\n\nCONCLUSIONS AND FUTURE WORKS\n\nIn this paper, we proposed a novel solution framework, the Behavior-Intensive Neural Network, to address the problem of personalized next-item recommendations. As a user's behaviors naturally form a interactive sequence over time, the user's historical preferences from the long-term view and present motivations from the shortterm view can be dynamically revealed. Along this line, we first introduced a w-item2vec method to generate item representations by considering the sequential similarities of the superb items. Then we discriminatively exploited user behaviors and proposed two alignments of the behaviors. Specific to each alignment, we respectively developed LSTM-based neural networks to learn personal historical preferences and present consumption motivations. Finally, we conducted extensive experiments on two industrial datasets. The experimental results clearly demonstrated the effective of our proposed model in personalized next-item recommendations.\n\nIn the future, we plan to study the impact of different types of user behaviors to generate user representations and improve the next-item recommendation even further. We also plan to investigate our model in other domain, such as advertisements.\n\nFigure 1 :\n1Recommending by integrating preference behaviors and session behaviors.\n\nFigure 2 :\n2The overview of Behavior-Intensive Neural Network (BINN). A. Neural Item Embedding converts sequential items into a unified embedding space by w-item2vec. B. Discriminative Behaviors Learning constructs two alignments of user behaviors and discriminatively learns behavior information based on two LSTM-based architectures.\n\nFigure 3 :\n3Dataset divided with a cut time.\n\nFigure 4 :\n4T-SNE embedding for item vectors produced by w-item2vec (a), item2vec (b) on Tianchi dataset. The items are colored according to the categories.\n\nFigure 5 :\n5T-SNE embedding for item vectors produced by w-item2vec (a), item2vec (b) on JD dataset. The items are colored according to the categories.\n\nFigure 6 :\n6Recommendation performances of new users cold-start on two datasets.\n\nFigure 7 :\n7Results of next-item recommendation over different history lengths.\n\n\nA. Neural Item Embedding Predicting B. Discriminative Behaviors LearningInteraction Sequence \n\nx 3 \nx 1 \n... \n\nx 2 \n\nx 4 \n\nx T \n\n... \n\n... \n\nSession Behaviors Learning \n\nh 2 \nh 3 \n\nh 3 \nh 2 \n\nh 1 \n\nh 1 \n\nh \n\nh \n\n... \n... \n\n... \n\n... \n\nPreference Behaviors Learning \n\n... \n\n\n\nTable 1 :\n1Statistics of datasets after preprocessing.Statistics \nTianchi \nJD \n# of users \n19,502 \n102,683 \n# of items \n674,326 \n24,744 \n# of behaviors \n8,799,573 37,061,992 \n# of behavior types \n4 \n6 \nAvg. behaviors per user \n451.30 \n360.94 \nAvg. behaviors per item \n13.05 \n1,497.82 \n# of behaviors in training set 7,874,102 31,811,364 \n# of behaviors in test set \n925,471 \n5,250,646 \n\n\u2022 Tianchi 2 is a public dataset by Alibaba's competition of Ali \nMobile Recommendation Algorithm, which is based on the real \nusers-commodities behavior data on Alibaba's M-Commerce plat-\nforms. It provides 23,291,027 interactions of 20,000 customers on \n4,758,484 items within a month. In this dataset, customer behav-\niors include click, collect, cart and purchase, the corresponding \nvalues are 1, 2, 3 and 4, respectively. \n\n\u2022 JD is provided by a Chinese e-commerce company Jingdong 3 , \nwhich is one of the top two largest B2C online retailers in China \nby transaction volume and revenue. Specially, it provides 37,087,895 \ninteractions of 105,180 customers on 28,710 items within 75 days \nbased on the real log data of users-commodities behaviors. In this \ndataset, customer behaviors include browse, cart, delete-to-cart, \npurchase, collect and click with the corresponding values 1, 2, 3, \n4, 5 and 6, respectively. \n\n\n\nTable 2 :\n2Performance comparisons of BINN with baseline methods on two datasets (The improvements of RNN-based models over the best traditional method have been marked).Methods \nTianchi \nJD \n\nRecall@20 \nMRR@20 \nRecall@20 \nMRR@20 \n\nP-POP \n0.2262 \n0.0824 \n0.5854 \n0.2176 \nBPR-MF \n0.0559 \n0.0165 \n0.1873 \n0.0664 \nItem-KNN \n0.1964 \n0.0883 \n0.1246 \n0.0361 \n\nGRU4Rec \n0.2025(-10.48%) \n0.0861(-2.49%) \n0.7034(+20.16%) \n0.4198(+92.92%) \nGRU4Rec Concat 0.2287(+1.11%) \n0.0859(-2.72%) \n0.7934(+35.53%) \n0.5932(+172.61%) \nHRNN Init \n0.2305(+1.9%) \n0.0897(+1.59%) \n0.8073(+37.91%) \n0.6098(+180.23%) \nHRNN All \n0.2167(-4.20%) \n0.0893(+1.13%) \n0.7762(+32.59%) \n0.4335(+99.22%) \nBINN \n0.2376(+5.04%) 0.0936(+6.00%) 0.8430(+44.00%) 0.7082(+225.46%) \n\n\nhttps://tianchi.aliyun.com/getStart/information.htm?spm=5176.100067.5678.2.30a8b6d 933N6Rr&raceId=231522 3 https://www.jd.com/\nACKNOWLEDGMENTS\nItem2vec: neural item embedding for collaborative filtering. Oren Barkan, Noam Koenigstein, Machine Learning for Signal Processing. Oren Barkan and Noam Koenigstein. 2016. Item2vec: neural item embedding for collaborative filtering. In Machine Learning for Signal Processing (MLSP), 2016 IEEE 26th International Workshop on. IEEE, 1-6.\n\nScalable collaborative filtering with jointly derived neighborhood interpolation weights. M Robert, Yehuda Bell, Koren, Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE. Robert M Bell and Yehuda Koren. 2007. Scalable collaborative filtering with jointly derived neighborhood interpolation weights. In Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE, 43-52.\n\nRepresentation learning: A review and new perspectives. Yoshua Bengio, Aaron Courville, Pascal Vincent, IEEE transactions. 35Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence 35, 8 (2013), 1798-1828.\n\nWho should share what?: item-level social influence prediction for users and posts ranking. Peng Cui, Fei Wang, Shaowei Liu, Mingdong Ou, Shiqiang Yang, Lifeng Sun, Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval. the 34th international ACM SIGIR conference on Research and development in Information RetrievalACMPeng Cui, Fei Wang, Shaowei Liu, Mingdong Ou, Shiqiang Yang, and Lifeng Sun. 2011. Who should share what?: item-level social influence prediction for users and posts ranking. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval. ACM, 185-194.\n\n. Peng Cui, Xiao Wang, Jian Pei, Wenwu Zhu, arXiv:1711.08752A Survey on Network Embedding. arXiv preprintPeng Cui, Xiao Wang, Jian Pei, and Wenwu Zhu. 2017. A Survey on Network Embedding. arXiv preprint arXiv:1711.08752 (2017).\n\nSequential User-based Recurrent Neural Network Recommendations. Tim Donkers, Benedikt Loepp, J\u00fcrgen Ziegler, Proceedings of the Eleventh ACM Conference on Recommender Systems (RecSys '17). the Eleventh ACM Conference on Recommender Systems (RecSys '17)New York, NY, USAACMTim Donkers, Benedikt Loepp, and J\u00fcrgen Ziegler. 2017. Sequential User-based Recurrent Neural Network Recommendations. In Proceedings of the Eleventh ACM Conference on Recommender Systems (RecSys '17). ACM, New York, NY, USA, 152-160.\n\nAdaptive subgradient methods for online learning and stochastic optimization. John Duchi, Elad Hazan, Yoram Singer, Journal of Machine Learning Research. 12John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research 12, Jul (2011), 2121-2159.\n\nA Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems. Ali Mamdouh Elkahky, Yang Song, Xiaodong He, Proceedings of the 24th International Conference on World Wide Web (WWW '15. the 24th International Conference on World Wide Web (WWW '15Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015. A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Sys- tems. In Proceedings of the 24th International Conference on World Wide Web (WWW '15). 278-288.\n\nShalini Ghosh, Oriol Vinyals, Brian Strope, Scott Roy, Tom Dean, Larry Heck, arXiv:1602.06291Contextual lstm (clstm) models for large scale nlp tasks. arXiv preprintShalini Ghosh, Oriol Vinyals, Brian Strope, Scott Roy, Tom Dean, and Larry Heck. 2016. Contextual lstm (clstm) models for large scale nlp tasks. arXiv preprint arXiv:1602.06291 (2016).\n\n2016. node2vec: Scalable feature learning for networks. Aditya Grover, Jure Leskovec, Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on Knowledge discovery and data miningACMAditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855-864.\n\nDeepFM: A Factorization-Machine based Neural Network for CTR Prediction. Huifeng Guo, Tang Ruiming, Yunming Ye, Zhenguo Li, Xiuqiang He, Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17. the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17Huifeng Guo, Ruiming TANG, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17. 1725-1731.\n\nVBPR: Visual Bayesian Personalized Ranking from Implicit Feedback. Ruining He, Julian Mcauley, AAAI. Ruining He and Julian McAuley. 2016. VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback.. In AAAI. 144-150.\n\nNeural Collaborative Filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of the 26th International Conference on World Wide Web (WWW '17. the 26th International Conference on World Wide Web (WWW '17Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web (WWW '17). 173-182.\n\nFast matrix factorization for online recommendation with implicit feedback. Xiangnan He, Hanwang Zhang, Min-Yen Kan, Tat-Seng Chua, Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. the 39th International ACM SIGIR conference on Research and Development in Information RetrievalACMXiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast ma- trix factorization for online recommendation with implicit feedback. In Proceed- ings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 549-558.\n\nBal\u00e1zs Hidasi, Alexandros Karatzoglou, arXiv:1511.06939Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprintBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.\n\nFactorization meets the neighborhood: a multifaceted collaborative filtering model. Yehuda Koren, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. the 14th ACM SIGKDD international conference on Knowledge discovery and data miningACMYehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 426-434.\n\nCollaborative filtering with temporal dynamics. Yehuda Koren, Commun. ACM. 53Yehuda Koren. 2010. Collaborative filtering with temporal dynamics. Commun. ACM 53, 4 (2010), 89-97.\n\nNeural Attentive Session-based Recommendation. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, Jun Ma, Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (CIKM '17. the 2017 ACM on Conference on Information and Knowledge Management (CIKM '17Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (CIKM '17). 1419-1428.\n\nAmazon. com recommendations: Item-to-item collaborative filtering. Greg Linden, Brent Smith, Jeremy York, IEEE Internet computing. 7Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon. com recommenda- tions: Item-to-item collaborative filtering. IEEE Internet computing 7, 1 (2003), 76-80.\n\nPersonalized travel package recommendation. Qi Liu, Yong Ge, Zhongmou Li, Enhong Chen, Hui Xiong, IEEE 11th International Conference on. IEEE. Data Mining (ICDM)Qi Liu, Yong Ge, Zhongmou Li, Enhong Chen, and Hui Xiong. 2011. Personal- ized travel package recommendation. In Data Mining (ICDM), 2011 IEEE 11th International Conference on. IEEE, 407-416.\n\nMining indecisiveness in customer behaviors. Qi Liu, Xianyu Zeng, Hengshu Zhu, Enhong Chen, Hui Xiong, Xing Xie, Data Mining (ICDM), 2015 IEEE International Conference on. IEEE. Qi Liu, Xianyu Zeng, Hengshu Zhu, Enhong Chen, Hui Xiong, Xing Xie, et al. 2015. Mining indecisiveness in customer behaviors. In Data Mining (ICDM), 2015 IEEE International Conference on. IEEE, 281-290.\n\nVisualizing data using t-SNE. Laurens Van Der Maaten, Geoffrey Hinton, Journal of Machine Learning Research. 9Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of Machine Learning Research 9, Nov (2008), 2579-2605.\n\nDistributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, Advances in neural information processing systems. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111-3119.\n\nProbabilistic matrix factorization. Andriy Mnih, R Ruslan, Salakhutdinov, Advances in neural information processing systems. Andriy Mnih and Ruslan R Salakhutdinov. 2008. Probabilistic matrix factorization. In Advances in neural information processing systems. 1257-1264.\n\nDeepwalk: Online learning of social representations. Bryan Perozzi, Rami Al-Rfou, Steven Skiena, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. the 20th ACM SIGKDD international conference on Knowledge discovery and data miningACMBryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 701-710.\n\nPersonalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks. Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, Paolo Cremonesi, Proceedings of the Eleventh ACM Conference on Recommender Systems (RecSys '17. the Eleventh ACM Conference on Recommender Systems (RecSys '17Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, and Paolo Cremonesi. 2017. Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks. In Proceedings of the Eleventh ACM Conference on Recommender Systems (RecSys '17). 130-137.\n\nBPR: Bayesian personalized ranking from implicit feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence. the twenty-fifth conference on uncertainty in artificial intelligenceAUAI PressSteffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence. AUAI Press, 452-461.\n\nFactorizing personalized markov chains for next-basket recommendation. Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme, Proceedings of the 19th international conference on World wide web. the 19th international conference on World wide webACMSteffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor- izing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web. ACM, 811-820.\n\nRecommender systems handbook. Francesco Ricci, Lior Rokach, Bracha Shapira, Paul B Kantor, SpringerFrancesco Ricci, Lior Rokach, Bracha Shapira, and Paul B Kantor. 2015. Recom- mender systems handbook. Springer.\n\nItem-based collaborative filtering recommendation algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, Proceedings of the 10th international conference on World Wide Web. the 10th international conference on World Wide WebACMBadrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web. ACM, 285-295.\n\nBidirectional recurrent neural networks. Mike Schuster, K Kuldip, Paliwal, IEEE Transactions on Signal Processing. 45Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural net- works. IEEE Transactions on Signal Processing 45, 11 (1997), 2673-2681.\n\nUser Oriented Trajectory Search for Trip Recommendation. Shuo Shang, Ruogu Ding, Bo Yuan, Kexin Xie, Kai Zheng, Panos Kalnis, Proceedings of the 15th International Conference on Extending Database Technology (EDBT '12). the 15th International Conference on Extending Database Technology (EDBT '12)New York, NY, USAACMShuo Shang, Ruogu Ding, Bo Yuan, Kexin Xie, Kai Zheng, and Panos Kalnis. 2012. User Oriented Trajectory Search for Trip Recommendation. In Proceedings of the 15th International Conference on Extending Database Technology (EDBT '12). ACM, New York, NY, USA, 156-167.\n\nPersonalized trajectory matching in spatial networks. Shuo Shang, Ruogu Ding, Kai Zheng, S Christian, Panos Jensen, Xiaofang Kalnis, Zhou, The VLDB Journal. 23Shuo Shang, Ruogu Ding, Kai Zheng, Christian S Jensen, Panos Kalnis, and Xiaofang Zhou. 2014. Personalized trajectory matching in spatial networks. The VLDB Journal 23, 3 (2014), 449-468.\n\nA probabilistic view of neighborhood-based recommendation methods. Jun Wang, Qiang Tang, IEEE 16th International Conference on. IEEE. Data Mining Workshops (ICDMW)Jun Wang and Qiang Tang. 2016. A probabilistic view of neighborhood-based recommendation methods. In Data Mining Workshops (ICDMW), 2016 IEEE 16th International Conference on. IEEE, 14-20.\n\nLearning Hierarchical Representation Model for NextBasket Recommendation. Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, Xueqi Cheng, Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '15). the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '15)New York, NY, USAACMPengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2015. Learning Hierarchical Representation Model for NextBasket Rec- ommendation. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '15). ACM, New York, NY, USA, 403-412.\n\nSequential Prediction of Social Media Popularity with Deep Temporal Context Networks. Bo Wu, Wen-Huang Cheng, Yongdong Zhang, Qiushi Huang, Jintao Li, Tao Mei, Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17. the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17Bo Wu, Wen-Huang Cheng, Yongdong Zhang, Qiushi Huang, Jintao Li, and Tao Mei. 2017. Sequential Prediction of Social Media Popularity with Deep Temporal Context Networks. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17. 3062-3068.\n\nUnfolding Temporal Dynamics: Predicting Social Media Popularity Using Multi-scale Temporal Decomposition. Bo Wu, Tao Mei, Wen-Huang Cheng, Yongdong Zhang, AAAI. Bo Wu, Tao Mei, Wen-Huang Cheng, Yongdong Zhang, et al. 2016. Unfold- ing Temporal Dynamics: Predicting Social Media Popularity Using Multi-scale Temporal Decomposition.. In AAAI. 272-278.\n\nEffective next-items recommendation via personalized sequential pattern mining. Xiao-Li Ghim-Eng Yap, Philip Li, Yu, Database Systems for Advanced Applications. Berlin/HeidelbergSpringerGhim-Eng Yap, Xiao-Li Li, and Philip Yu. 2012. Effective next-items recommenda- tion via personalized sequential pattern mining. In Database Systems for Advanced Applications. Springer Berlin/Heidelberg, 48-64.\n\nCollaborative knowledge base embedding for recommender systems. Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, Wei-Ying Ma, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data miningACMFuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, and Wei-Ying Ma. 2016. Collaborative knowledge base embedding for recommender systems. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 353-362.\n\nGroup Preference Aggregation: A Nash Equilibrium Approach. Hongke Zhao, Qi Liu, Yong Ge, Ruoyan Kong, Enhong Chen, IEEE 16th International Conference on. IEEE. Data Mining (ICDM)Hongke Zhao, Qi Liu, Yong Ge, Ruoyan Kong, and Enhong Chen. 2016. Group Preference Aggregation: A Nash Equilibrium Approach. In Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 679-688.\n\nA sequential approach to market state modeling and analysis in online p2p lending. Hongke Zhao, Qi Liu, Hengshu Zhu, Yong Ge, Enhong Chen, Yan Zhu, Junping Du, IEEE Transactions on Systems, Man, and Cybernetics. Hongke Zhao, Qi Liu, Hengshu Zhu, Yong Ge, Enhong Chen, Yan Zhu, and Junping Du. 2017. A sequential approach to market state modeling and analysis in online p2p lending. IEEE Transactions on Systems, Man, and Cybernetics: Systems (2017).\n\nInvestment recommendation in p2p lending: A portfolio perspective with risk management. Hongke Zhao, Le Wu, Qi Liu, Yong Ge, Enhong Chen, Data Mining (ICDM). Hongke Zhao, Le Wu, Qi Liu, Yong Ge, and Enhong Chen. 2014. Investment recommendation in p2p lending: A portfolio perspective with risk management. In Data Mining (ICDM), 2014 IEEE International Conference on. IEEE, 1109-1114.\n", "annotations": {"author": "[{\"end\":311,\"start\":110},{\"end\":439,\"start\":312},{\"end\":562,\"start\":440},{\"end\":717,\"start\":563},{\"end\":755,\"start\":718},{\"end\":902,\"start\":756}]", "publisher": null, "author_last_name": "[{\"end\":116,\"start\":114},{\"end\":323,\"start\":319},{\"end\":446,\"start\":443},{\"end\":575,\"start\":570},{\"end\":725,\"start\":722},{\"end\":767,\"start\":763}]", "author_first_name": "[{\"end\":113,\"start\":110},{\"end\":318,\"start\":312},{\"end\":442,\"start\":440},{\"end\":569,\"start\":563},{\"end\":721,\"start\":718},{\"end\":762,\"start\":756}]", "author_affiliation": "[{\"end\":231,\"start\":118},{\"end\":310,\"start\":233},{\"end\":438,\"start\":325},{\"end\":561,\"start\":448},{\"end\":716,\"start\":603},{\"end\":754,\"start\":739},{\"end\":901,\"start\":788}]", "title": "[{\"end\":107,\"start\":1},{\"end\":1009,\"start\":903}]", "venue": null, "abstract": "[{\"end\":2520,\"start\":1119}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2723,\"start\":2719},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3511,\"start\":3507},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3514,\"start\":3511},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3517,\"start\":3514},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3669,\"start\":3665},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3968,\"start\":3964},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3971,\"start\":3968},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3999,\"start\":3995},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4002,\"start\":3999},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4216,\"start\":4212},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4219,\"start\":4216},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4222,\"start\":4219},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4373,\"start\":4369},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8446,\"start\":8442},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8890,\"start\":8886},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8893,\"start\":8890},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8896,\"start\":8893},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9003,\"start\":9000},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9006,\"start\":9003},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9009,\"start\":9006},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9012,\"start\":9009},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9015,\"start\":9012},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9048,\"start\":9045},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9051,\"start\":9048},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9054,\"start\":9051},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9057,\"start\":9054},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9060,\"start\":9057},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9230,\"start\":9227},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9233,\"start\":9230},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9236,\"start\":9233},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9239,\"start\":9236},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9425,\"start\":9422},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9580,\"start\":9576},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9705,\"start\":9701},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9872,\"start\":9868},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10040,\"start\":10036},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10043,\"start\":10040},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10046,\"start\":10043},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10404,\"start\":10400},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10533,\"start\":10529},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10843,\"start\":10839},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10865,\"start\":10862},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10868,\"start\":10865},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10892,\"start\":10888},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11009,\"start\":11005},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11012,\"start\":11009},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11407,\"start\":11403},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11410,\"start\":11407},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11429,\"start\":11425},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11432,\"start\":11429},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11435,\"start\":11432},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11469,\"start\":11466},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11472,\"start\":11469},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11628,\"start\":11624},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11631,\"start\":11628},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11664,\"start\":11660},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11667,\"start\":11664},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11871,\"start\":11868},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11890,\"start\":11886},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11915,\"start\":11911},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11918,\"start\":11915},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11921,\"start\":11918},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12120,\"start\":12116},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12335,\"start\":12331},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12533,\"start\":12529},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12673,\"start\":12670},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15896,\"start\":15892},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":15899,\"start\":15896},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16116,\"start\":16113},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16229,\"start\":16225},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16706,\"start\":16703},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16709,\"start\":16706},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16730,\"start\":16727},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16733,\"start\":16730},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":16736,\"start\":16733},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":16760,\"start\":16757},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":16793,\"start\":16790},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16871,\"start\":16867},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17360,\"start\":17356},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17665,\"start\":17661},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17957,\"start\":17954},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18032,\"start\":18028},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":19400,\"start\":19399},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":21997,\"start\":21993},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23394,\"start\":23391},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":25499,\"start\":25495},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":27460,\"start\":27456},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":27953,\"start\":27950},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":30020,\"start\":30016},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30853,\"start\":30849},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31009,\"start\":31005},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":31104,\"start\":31100},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":31207,\"start\":31203},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31386,\"start\":31382},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31692,\"start\":31688},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":32639,\"start\":32635},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32642,\"start\":32639},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33118,\"start\":33114},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":33121,\"start\":33118},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":34533,\"start\":34529},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":36945,\"start\":36941},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":39233,\"start\":39229}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44168,\"start\":44084},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44505,\"start\":44169},{\"attributes\":{\"id\":\"fig_2\"},\"end\":44551,\"start\":44506},{\"attributes\":{\"id\":\"fig_4\"},\"end\":44709,\"start\":44552},{\"attributes\":{\"id\":\"fig_6\"},\"end\":44862,\"start\":44710},{\"attributes\":{\"id\":\"fig_8\"},\"end\":44944,\"start\":44863},{\"attributes\":{\"id\":\"fig_10\"},\"end\":45025,\"start\":44945},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":45301,\"start\":45026},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":46616,\"start\":45302},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":47354,\"start\":46617}]", "paragraph": "[{\"end\":3135,\"start\":2536},{\"end\":4510,\"start\":3137},{\"end\":6138,\"start\":4512},{\"end\":7788,\"start\":6140},{\"end\":7972,\"start\":7790},{\"end\":8188,\"start\":7974},{\"end\":8252,\"start\":8190},{\"end\":8350,\"start\":8254},{\"end\":8670,\"start\":8368},{\"end\":9873,\"start\":8695},{\"end\":11013,\"start\":9875},{\"end\":11263,\"start\":11015},{\"end\":11533,\"start\":11291},{\"end\":12674,\"start\":11535},{\"end\":13125,\"start\":12676},{\"end\":13530,\"start\":13169},{\"end\":14041,\"start\":13548},{\"end\":14293,\"start\":14097},{\"end\":14425,\"start\":14348},{\"end\":14667,\"start\":14480},{\"end\":15511,\"start\":14669},{\"end\":16589,\"start\":15537},{\"end\":16953,\"start\":16591},{\"end\":18222,\"start\":16955},{\"end\":18573,\"start\":18481},{\"end\":18865,\"start\":18632},{\"end\":19193,\"start\":18927},{\"end\":19478,\"start\":19269},{\"end\":19750,\"start\":19619},{\"end\":20071,\"start\":19752},{\"end\":20412,\"start\":20202},{\"end\":21397,\"start\":20414},{\"end\":22086,\"start\":21399},{\"end\":22413,\"start\":22118},{\"end\":22847,\"start\":22550},{\"end\":23306,\"start\":22890},{\"end\":23657,\"start\":23308},{\"end\":24184,\"start\":23944},{\"end\":24489,\"start\":24186},{\"end\":25107,\"start\":24514},{\"end\":26293,\"start\":25145},{\"end\":26471,\"start\":26339},{\"end\":26752,\"start\":26522},{\"end\":27033,\"start\":26754},{\"end\":27585,\"start\":27067},{\"end\":28013,\"start\":27661},{\"end\":28732,\"start\":28015},{\"end\":29151,\"start\":28748},{\"end\":30352,\"start\":29164},{\"end\":30619,\"start\":30373},{\"end\":30992,\"start\":30621},{\"end\":31088,\"start\":30994},{\"end\":31184,\"start\":31090},{\"end\":31368,\"start\":31186},{\"end\":31675,\"start\":31370},{\"end\":31864,\"start\":31677},{\"end\":32218,\"start\":31866},{\"end\":32485,\"start\":32241},{\"end\":32856,\"start\":32487},{\"end\":33240,\"start\":32858},{\"end\":33337,\"start\":33242},{\"end\":33639,\"start\":33362},{\"end\":34044,\"start\":33673},{\"end\":35705,\"start\":34046},{\"end\":36227,\"start\":35738},{\"end\":37272,\"start\":36229},{\"end\":37936,\"start\":37274},{\"end\":38593,\"start\":37938},{\"end\":39046,\"start\":38595},{\"end\":39473,\"start\":39075},{\"end\":40290,\"start\":39475},{\"end\":41022,\"start\":40292},{\"end\":42831,\"start\":41063},{\"end\":43835,\"start\":42864},{\"end\":44083,\"start\":43837}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14096,\"start\":14042},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14347,\"start\":14294},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14479,\"start\":14426},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18430,\"start\":18223},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18480,\"start\":18430},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18631,\"start\":18574},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18926,\"start\":18866},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19268,\"start\":19194},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19618,\"start\":19479},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20165,\"start\":20072},{\"attributes\":{\"id\":\"formula_10\"},\"end\":22549,\"start\":22414},{\"attributes\":{\"id\":\"formula_11\"},\"end\":22889,\"start\":22848},{\"attributes\":{\"id\":\"formula_12\"},\"end\":23943,\"start\":23658},{\"attributes\":{\"id\":\"formula_13\"},\"end\":25144,\"start\":25108},{\"attributes\":{\"id\":\"formula_14\"},\"end\":26338,\"start\":26294},{\"attributes\":{\"id\":\"formula_15\"},\"end\":26521,\"start\":26472},{\"attributes\":{\"id\":\"formula_16\"},\"end\":27660,\"start\":27586}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30351,\"start\":30344},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35329,\"start\":35322},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":35959,\"start\":35952}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2534,\"start\":2522},{\"attributes\":{\"n\":\"2\"},\"end\":8366,\"start\":8353},{\"attributes\":{\"n\":\"2.1\"},\"end\":8693,\"start\":8673},{\"attributes\":{\"n\":\"2.2\"},\"end\":11289,\"start\":11266},{\"attributes\":{\"n\":\"3\"},\"end\":13167,\"start\":13128},{\"attributes\":{\"n\":\"3.1\"},\"end\":13546,\"start\":13533},{\"attributes\":{\"n\":\"3.2\"},\"end\":15535,\"start\":15514},{\"attributes\":{\"n\":\"3.3\"},\"end\":20200,\"start\":20167},{\"attributes\":{\"n\":\"3.3.1\"},\"end\":22116,\"start\":22089},{\"attributes\":{\"n\":\"3.3.2\"},\"end\":24512,\"start\":24492},{\"attributes\":{\"n\":\"3.4\"},\"end\":27065,\"start\":27036},{\"attributes\":{\"n\":\"4\"},\"end\":28746,\"start\":28735},{\"attributes\":{\"n\":\"4.1\"},\"end\":29162,\"start\":29154},{\"attributes\":{\"n\":\"4.2\"},\"end\":30371,\"start\":30355},{\"attributes\":{\"n\":\"4.3\"},\"end\":32239,\"start\":32221},{\"attributes\":{\"n\":\"4.4\"},\"end\":33360,\"start\":33340},{\"attributes\":{\"n\":\"4.4.1\"},\"end\":33671,\"start\":33642},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":35736,\"start\":35708},{\"attributes\":{\"n\":\"4.4.3\"},\"end\":39073,\"start\":39049},{\"attributes\":{\"n\":\"4.4.4\"},\"end\":41061,\"start\":41025},{\"attributes\":{\"n\":\"5\"},\"end\":42862,\"start\":42834},{\"end\":44095,\"start\":44085},{\"end\":44180,\"start\":44170},{\"end\":44517,\"start\":44507},{\"end\":44563,\"start\":44553},{\"end\":44721,\"start\":44711},{\"end\":44874,\"start\":44864},{\"end\":44956,\"start\":44946},{\"end\":45312,\"start\":45303},{\"end\":46627,\"start\":46618}]", "table": "[{\"end\":45301,\"start\":45100},{\"end\":46616,\"start\":45357},{\"end\":47354,\"start\":46788}]", "figure_caption": "[{\"end\":44168,\"start\":44097},{\"end\":44505,\"start\":44182},{\"end\":44551,\"start\":44519},{\"end\":44709,\"start\":44565},{\"end\":44862,\"start\":44723},{\"end\":44944,\"start\":44876},{\"end\":45025,\"start\":44958},{\"end\":45100,\"start\":45028},{\"end\":45357,\"start\":45314},{\"end\":46788,\"start\":46629}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4773,\"start\":4765},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5416,\"start\":5408},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5642,\"start\":5634},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14834,\"start\":14826},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20440,\"start\":20432},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22163,\"start\":22155},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":29685,\"start\":29677},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":34692,\"start\":34684},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":34972,\"start\":34964},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":34988,\"start\":34980},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39359,\"start\":39351},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":40325,\"start\":40317},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":41887,\"start\":41879}]", "bib_author_first_name": "[{\"end\":47563,\"start\":47559},{\"end\":47576,\"start\":47572},{\"end\":47926,\"start\":47925},{\"end\":47941,\"start\":47935},{\"end\":48312,\"start\":48306},{\"end\":48326,\"start\":48321},{\"end\":48344,\"start\":48338},{\"end\":48674,\"start\":48670},{\"end\":48683,\"start\":48680},{\"end\":48697,\"start\":48690},{\"end\":48711,\"start\":48703},{\"end\":48724,\"start\":48716},{\"end\":48737,\"start\":48731},{\"end\":49267,\"start\":49263},{\"end\":49277,\"start\":49273},{\"end\":49288,\"start\":49284},{\"end\":49299,\"start\":49294},{\"end\":49557,\"start\":49554},{\"end\":49575,\"start\":49567},{\"end\":49589,\"start\":49583},{\"end\":50080,\"start\":50076},{\"end\":50092,\"start\":50088},{\"end\":50105,\"start\":50100},{\"end\":50442,\"start\":50439},{\"end\":50464,\"start\":50460},{\"end\":50479,\"start\":50471},{\"end\":50870,\"start\":50863},{\"end\":50883,\"start\":50878},{\"end\":50898,\"start\":50893},{\"end\":50912,\"start\":50907},{\"end\":50921,\"start\":50918},{\"end\":50933,\"start\":50928},{\"end\":51276,\"start\":51270},{\"end\":51289,\"start\":51285},{\"end\":51773,\"start\":51766},{\"end\":51783,\"start\":51779},{\"end\":51800,\"start\":51793},{\"end\":51812,\"start\":51805},{\"end\":51825,\"start\":51817},{\"end\":52352,\"start\":52345},{\"end\":52363,\"start\":52357},{\"end\":52543,\"start\":52535},{\"end\":52552,\"start\":52548},{\"end\":52566,\"start\":52559},{\"end\":52581,\"start\":52574},{\"end\":52590,\"start\":52587},{\"end\":52603,\"start\":52595},{\"end\":53039,\"start\":53031},{\"end\":53051,\"start\":53044},{\"end\":53066,\"start\":53059},{\"end\":53080,\"start\":53072},{\"end\":53582,\"start\":53576},{\"end\":53601,\"start\":53591},{\"end\":53961,\"start\":53957},{\"end\":53980,\"start\":53974},{\"end\":54219,\"start\":54213},{\"end\":54689,\"start\":54683},{\"end\":54865,\"start\":54861},{\"end\":54877,\"start\":54870},{\"end\":54889,\"start\":54883},{\"end\":54904,\"start\":54896},{\"end\":54913,\"start\":54910},{\"end\":54923,\"start\":54920},{\"end\":55401,\"start\":55397},{\"end\":55415,\"start\":55410},{\"end\":55429,\"start\":55423},{\"end\":55671,\"start\":55669},{\"end\":55681,\"start\":55677},{\"end\":55694,\"start\":55686},{\"end\":55705,\"start\":55699},{\"end\":55715,\"start\":55712},{\"end\":56026,\"start\":56024},{\"end\":56038,\"start\":56032},{\"end\":56052,\"start\":56045},{\"end\":56064,\"start\":56058},{\"end\":56074,\"start\":56071},{\"end\":56086,\"start\":56082},{\"end\":56398,\"start\":56391},{\"end\":56423,\"start\":56415},{\"end\":56697,\"start\":56692},{\"end\":56711,\"start\":56707},{\"end\":56726,\"start\":56723},{\"end\":56737,\"start\":56733},{\"end\":56739,\"start\":56738},{\"end\":56753,\"start\":56749},{\"end\":57074,\"start\":57068},{\"end\":57082,\"start\":57081},{\"end\":57363,\"start\":57358},{\"end\":57377,\"start\":57373},{\"end\":57393,\"start\":57387},{\"end\":57909,\"start\":57902},{\"end\":57930,\"start\":57920},{\"end\":57950,\"start\":57944},{\"end\":57964,\"start\":57959},{\"end\":58449,\"start\":58442},{\"end\":58467,\"start\":58458},{\"end\":58487,\"start\":58483},{\"end\":58501,\"start\":58497},{\"end\":59017,\"start\":59010},{\"end\":59035,\"start\":59026},{\"end\":59055,\"start\":59051},{\"end\":59464,\"start\":59455},{\"end\":59476,\"start\":59472},{\"end\":59491,\"start\":59485},{\"end\":59507,\"start\":59501},{\"end\":59706,\"start\":59700},{\"end\":59721,\"start\":59715},{\"end\":59737,\"start\":59731},{\"end\":59751,\"start\":59747},{\"end\":60143,\"start\":60139},{\"end\":60155,\"start\":60154},{\"end\":60427,\"start\":60423},{\"end\":60440,\"start\":60435},{\"end\":60449,\"start\":60447},{\"end\":60461,\"start\":60456},{\"end\":60470,\"start\":60467},{\"end\":60483,\"start\":60478},{\"end\":61008,\"start\":61004},{\"end\":61021,\"start\":61016},{\"end\":61031,\"start\":61028},{\"end\":61040,\"start\":61039},{\"end\":61057,\"start\":61052},{\"end\":61074,\"start\":61066},{\"end\":61368,\"start\":61365},{\"end\":61380,\"start\":61375},{\"end\":61732,\"start\":61725},{\"end\":61746,\"start\":61739},{\"end\":61758,\"start\":61752},{\"end\":61767,\"start\":61764},{\"end\":61781,\"start\":61772},{\"end\":61792,\"start\":61787},{\"end\":62464,\"start\":62462},{\"end\":62478,\"start\":62469},{\"end\":62494,\"start\":62486},{\"end\":62508,\"start\":62502},{\"end\":62522,\"start\":62516},{\"end\":62530,\"start\":62527},{\"end\":63115,\"start\":63113},{\"end\":63123,\"start\":63120},{\"end\":63138,\"start\":63129},{\"end\":63154,\"start\":63146},{\"end\":63445,\"start\":63438},{\"end\":63466,\"start\":63460},{\"end\":63827,\"start\":63820},{\"end\":63843,\"start\":63835},{\"end\":63848,\"start\":63844},{\"end\":63859,\"start\":63855},{\"end\":63870,\"start\":63866},{\"end\":63884,\"start\":63876},{\"end\":64401,\"start\":64395},{\"end\":64410,\"start\":64408},{\"end\":64420,\"start\":64416},{\"end\":64431,\"start\":64425},{\"end\":64444,\"start\":64438},{\"end\":64811,\"start\":64805},{\"end\":64820,\"start\":64818},{\"end\":64833,\"start\":64826},{\"end\":64843,\"start\":64839},{\"end\":64854,\"start\":64848},{\"end\":64864,\"start\":64861},{\"end\":64877,\"start\":64870},{\"end\":65267,\"start\":65261},{\"end\":65276,\"start\":65274},{\"end\":65283,\"start\":65281},{\"end\":65293,\"start\":65289},{\"end\":65304,\"start\":65298}]", "bib_author_last_name": "[{\"end\":47570,\"start\":47564},{\"end\":47588,\"start\":47577},{\"end\":47933,\"start\":47927},{\"end\":47946,\"start\":47942},{\"end\":47953,\"start\":47948},{\"end\":48319,\"start\":48313},{\"end\":48336,\"start\":48327},{\"end\":48352,\"start\":48345},{\"end\":48678,\"start\":48675},{\"end\":48688,\"start\":48684},{\"end\":48701,\"start\":48698},{\"end\":48714,\"start\":48712},{\"end\":48729,\"start\":48725},{\"end\":48741,\"start\":48738},{\"end\":49271,\"start\":49268},{\"end\":49282,\"start\":49278},{\"end\":49292,\"start\":49289},{\"end\":49303,\"start\":49300},{\"end\":49565,\"start\":49558},{\"end\":49581,\"start\":49576},{\"end\":49597,\"start\":49590},{\"end\":50086,\"start\":50081},{\"end\":50098,\"start\":50093},{\"end\":50112,\"start\":50106},{\"end\":50458,\"start\":50443},{\"end\":50469,\"start\":50465},{\"end\":50482,\"start\":50480},{\"end\":50876,\"start\":50871},{\"end\":50891,\"start\":50884},{\"end\":50905,\"start\":50899},{\"end\":50916,\"start\":50913},{\"end\":50926,\"start\":50922},{\"end\":50938,\"start\":50934},{\"end\":51283,\"start\":51277},{\"end\":51298,\"start\":51290},{\"end\":51777,\"start\":51774},{\"end\":51791,\"start\":51784},{\"end\":51803,\"start\":51801},{\"end\":51815,\"start\":51813},{\"end\":51828,\"start\":51826},{\"end\":52355,\"start\":52353},{\"end\":52371,\"start\":52364},{\"end\":52546,\"start\":52544},{\"end\":52557,\"start\":52553},{\"end\":52572,\"start\":52567},{\"end\":52585,\"start\":52582},{\"end\":52593,\"start\":52591},{\"end\":52608,\"start\":52604},{\"end\":53042,\"start\":53040},{\"end\":53057,\"start\":53052},{\"end\":53070,\"start\":53067},{\"end\":53085,\"start\":53081},{\"end\":53589,\"start\":53583},{\"end\":53613,\"start\":53602},{\"end\":53972,\"start\":53962},{\"end\":53992,\"start\":53981},{\"end\":54225,\"start\":54220},{\"end\":54695,\"start\":54690},{\"end\":54868,\"start\":54866},{\"end\":54881,\"start\":54878},{\"end\":54894,\"start\":54890},{\"end\":54908,\"start\":54905},{\"end\":54918,\"start\":54914},{\"end\":54926,\"start\":54924},{\"end\":55408,\"start\":55402},{\"end\":55421,\"start\":55416},{\"end\":55434,\"start\":55430},{\"end\":55675,\"start\":55672},{\"end\":55684,\"start\":55682},{\"end\":55697,\"start\":55695},{\"end\":55710,\"start\":55706},{\"end\":55721,\"start\":55716},{\"end\":56030,\"start\":56027},{\"end\":56043,\"start\":56039},{\"end\":56056,\"start\":56053},{\"end\":56069,\"start\":56065},{\"end\":56080,\"start\":56075},{\"end\":56090,\"start\":56087},{\"end\":56413,\"start\":56399},{\"end\":56430,\"start\":56424},{\"end\":56705,\"start\":56698},{\"end\":56721,\"start\":56712},{\"end\":56731,\"start\":56727},{\"end\":56747,\"start\":56740},{\"end\":56758,\"start\":56754},{\"end\":57079,\"start\":57075},{\"end\":57089,\"start\":57083},{\"end\":57104,\"start\":57091},{\"end\":57371,\"start\":57364},{\"end\":57385,\"start\":57378},{\"end\":57400,\"start\":57394},{\"end\":57918,\"start\":57910},{\"end\":57942,\"start\":57931},{\"end\":57957,\"start\":57951},{\"end\":57974,\"start\":57965},{\"end\":58456,\"start\":58450},{\"end\":58481,\"start\":58468},{\"end\":58495,\"start\":58488},{\"end\":58516,\"start\":58502},{\"end\":59024,\"start\":59018},{\"end\":59049,\"start\":59036},{\"end\":59070,\"start\":59056},{\"end\":59470,\"start\":59465},{\"end\":59483,\"start\":59477},{\"end\":59499,\"start\":59492},{\"end\":59514,\"start\":59508},{\"end\":59713,\"start\":59707},{\"end\":59729,\"start\":59722},{\"end\":59745,\"start\":59738},{\"end\":59757,\"start\":59752},{\"end\":60152,\"start\":60144},{\"end\":60162,\"start\":60156},{\"end\":60171,\"start\":60164},{\"end\":60433,\"start\":60428},{\"end\":60445,\"start\":60441},{\"end\":60454,\"start\":60450},{\"end\":60465,\"start\":60462},{\"end\":60476,\"start\":60471},{\"end\":60490,\"start\":60484},{\"end\":61014,\"start\":61009},{\"end\":61026,\"start\":61022},{\"end\":61037,\"start\":61032},{\"end\":61050,\"start\":61041},{\"end\":61064,\"start\":61058},{\"end\":61081,\"start\":61075},{\"end\":61087,\"start\":61083},{\"end\":61373,\"start\":61369},{\"end\":61385,\"start\":61381},{\"end\":61737,\"start\":61733},{\"end\":61750,\"start\":61747},{\"end\":61762,\"start\":61759},{\"end\":61770,\"start\":61768},{\"end\":61785,\"start\":61782},{\"end\":61798,\"start\":61793},{\"end\":62467,\"start\":62465},{\"end\":62484,\"start\":62479},{\"end\":62500,\"start\":62495},{\"end\":62514,\"start\":62509},{\"end\":62525,\"start\":62523},{\"end\":62534,\"start\":62531},{\"end\":63118,\"start\":63116},{\"end\":63127,\"start\":63124},{\"end\":63144,\"start\":63139},{\"end\":63160,\"start\":63155},{\"end\":63458,\"start\":63446},{\"end\":63469,\"start\":63467},{\"end\":63473,\"start\":63471},{\"end\":63833,\"start\":63828},{\"end\":63853,\"start\":63849},{\"end\":63864,\"start\":63860},{\"end\":63874,\"start\":63871},{\"end\":63887,\"start\":63885},{\"end\":64406,\"start\":64402},{\"end\":64414,\"start\":64411},{\"end\":64423,\"start\":64421},{\"end\":64436,\"start\":64432},{\"end\":64449,\"start\":64445},{\"end\":64816,\"start\":64812},{\"end\":64824,\"start\":64821},{\"end\":64837,\"start\":64834},{\"end\":64846,\"start\":64844},{\"end\":64859,\"start\":64855},{\"end\":64868,\"start\":64865},{\"end\":64880,\"start\":64878},{\"end\":65272,\"start\":65268},{\"end\":65279,\"start\":65277},{\"end\":65287,\"start\":65284},{\"end\":65296,\"start\":65294},{\"end\":65309,\"start\":65305}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":274367},\"end\":47833,\"start\":47498},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":206784101},\"end\":48248,\"start\":47835},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":393948},\"end\":48576,\"start\":48250},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2820418},\"end\":49259,\"start\":48578},{\"attributes\":{\"doi\":\"arXiv:1711.08752\",\"id\":\"b4\"},\"end\":49488,\"start\":49261},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":38116062},\"end\":49996,\"start\":49490},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":538820},\"end\":50343,\"start\":49998},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":14936990},\"end\":50861,\"start\":50345},{\"attributes\":{\"doi\":\"arXiv:1602.06291\",\"id\":\"b8\"},\"end\":51212,\"start\":50863},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":207238980},\"end\":51691,\"start\":51214},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":970388},\"end\":52276,\"start\":51693},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3099285},\"end\":52501,\"start\":52278},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":13907106},\"end\":52953,\"start\":52503},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2896685},\"end\":53574,\"start\":52955},{\"attributes\":{\"doi\":\"arXiv:1511.06939\",\"id\":\"b14\"},\"end\":53931,\"start\":53576},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1915014},\"end\":54127,\"start\":53933},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":207168823},\"end\":54633,\"start\":54129},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3022077},\"end\":54812,\"start\":54635},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":21066930},\"end\":55328,\"start\":54814},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":14604122},\"end\":55623,\"start\":55330},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":15510183},\"end\":55977,\"start\":55625},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":9494805},\"end\":56359,\"start\":55979},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":5855042},\"end\":56613,\"start\":56361},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":16447573},\"end\":57030,\"start\":56615},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":467086},\"end\":57303,\"start\":57032},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3051291},\"end\":57811,\"start\":57305},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":10174110},\"end\":58381,\"start\":57813},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":10795036},\"end\":58937,\"start\":58383},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":207178809},\"end\":59423,\"start\":58939},{\"attributes\":{\"id\":\"b29\"},\"end\":59636,\"start\":59425},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":8047550},\"end\":60096,\"start\":59638},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":18375389},\"end\":60364,\"start\":60098},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":14935526},\"end\":60948,\"start\":60366},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":15578354},\"end\":61296,\"start\":60950},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":17577303},\"end\":61649,\"start\":61298},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":4002880},\"end\":62374,\"start\":61651},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":19836623},\"end\":63005,\"start\":62376},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":27262869},\"end\":63356,\"start\":63007},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":29347530},\"end\":63754,\"start\":63358},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":7062707},\"end\":64334,\"start\":63756},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":12196127},\"end\":64720,\"start\":64336},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":13844046},\"end\":65171,\"start\":64722},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":1118988},\"end\":65557,\"start\":65173}]", "bib_title": "[{\"end\":47557,\"start\":47498},{\"end\":47923,\"start\":47835},{\"end\":48304,\"start\":48250},{\"end\":48668,\"start\":48578},{\"end\":49552,\"start\":49490},{\"end\":50074,\"start\":49998},{\"end\":50437,\"start\":50345},{\"end\":51268,\"start\":51214},{\"end\":51764,\"start\":51693},{\"end\":52343,\"start\":52278},{\"end\":52533,\"start\":52503},{\"end\":53029,\"start\":52955},{\"end\":53955,\"start\":53933},{\"end\":54211,\"start\":54129},{\"end\":54681,\"start\":54635},{\"end\":54859,\"start\":54814},{\"end\":55395,\"start\":55330},{\"end\":55667,\"start\":55625},{\"end\":56022,\"start\":55979},{\"end\":56389,\"start\":56361},{\"end\":56690,\"start\":56615},{\"end\":57066,\"start\":57032},{\"end\":57356,\"start\":57305},{\"end\":57900,\"start\":57813},{\"end\":58440,\"start\":58383},{\"end\":59008,\"start\":58939},{\"end\":59698,\"start\":59638},{\"end\":60137,\"start\":60098},{\"end\":60421,\"start\":60366},{\"end\":61002,\"start\":60950},{\"end\":61363,\"start\":61298},{\"end\":61723,\"start\":61651},{\"end\":62460,\"start\":62376},{\"end\":63111,\"start\":63007},{\"end\":63436,\"start\":63358},{\"end\":63818,\"start\":63756},{\"end\":64393,\"start\":64336},{\"end\":64803,\"start\":64722},{\"end\":65259,\"start\":65173}]", "bib_author": "[{\"end\":47572,\"start\":47559},{\"end\":47590,\"start\":47572},{\"end\":47935,\"start\":47925},{\"end\":47948,\"start\":47935},{\"end\":47955,\"start\":47948},{\"end\":48321,\"start\":48306},{\"end\":48338,\"start\":48321},{\"end\":48354,\"start\":48338},{\"end\":48680,\"start\":48670},{\"end\":48690,\"start\":48680},{\"end\":48703,\"start\":48690},{\"end\":48716,\"start\":48703},{\"end\":48731,\"start\":48716},{\"end\":48743,\"start\":48731},{\"end\":49273,\"start\":49263},{\"end\":49284,\"start\":49273},{\"end\":49294,\"start\":49284},{\"end\":49305,\"start\":49294},{\"end\":49567,\"start\":49554},{\"end\":49583,\"start\":49567},{\"end\":49599,\"start\":49583},{\"end\":50088,\"start\":50076},{\"end\":50100,\"start\":50088},{\"end\":50114,\"start\":50100},{\"end\":50460,\"start\":50439},{\"end\":50471,\"start\":50460},{\"end\":50484,\"start\":50471},{\"end\":50878,\"start\":50863},{\"end\":50893,\"start\":50878},{\"end\":50907,\"start\":50893},{\"end\":50918,\"start\":50907},{\"end\":50928,\"start\":50918},{\"end\":50940,\"start\":50928},{\"end\":51285,\"start\":51270},{\"end\":51300,\"start\":51285},{\"end\":51779,\"start\":51766},{\"end\":51793,\"start\":51779},{\"end\":51805,\"start\":51793},{\"end\":51817,\"start\":51805},{\"end\":51830,\"start\":51817},{\"end\":52357,\"start\":52345},{\"end\":52373,\"start\":52357},{\"end\":52548,\"start\":52535},{\"end\":52559,\"start\":52548},{\"end\":52574,\"start\":52559},{\"end\":52587,\"start\":52574},{\"end\":52595,\"start\":52587},{\"end\":52610,\"start\":52595},{\"end\":53044,\"start\":53031},{\"end\":53059,\"start\":53044},{\"end\":53072,\"start\":53059},{\"end\":53087,\"start\":53072},{\"end\":53591,\"start\":53576},{\"end\":53615,\"start\":53591},{\"end\":53974,\"start\":53957},{\"end\":53994,\"start\":53974},{\"end\":54227,\"start\":54213},{\"end\":54697,\"start\":54683},{\"end\":54870,\"start\":54861},{\"end\":54883,\"start\":54870},{\"end\":54896,\"start\":54883},{\"end\":54910,\"start\":54896},{\"end\":54920,\"start\":54910},{\"end\":54928,\"start\":54920},{\"end\":55410,\"start\":55397},{\"end\":55423,\"start\":55410},{\"end\":55436,\"start\":55423},{\"end\":55677,\"start\":55669},{\"end\":55686,\"start\":55677},{\"end\":55699,\"start\":55686},{\"end\":55712,\"start\":55699},{\"end\":55723,\"start\":55712},{\"end\":56032,\"start\":56024},{\"end\":56045,\"start\":56032},{\"end\":56058,\"start\":56045},{\"end\":56071,\"start\":56058},{\"end\":56082,\"start\":56071},{\"end\":56092,\"start\":56082},{\"end\":56415,\"start\":56391},{\"end\":56432,\"start\":56415},{\"end\":56707,\"start\":56692},{\"end\":56723,\"start\":56707},{\"end\":56733,\"start\":56723},{\"end\":56749,\"start\":56733},{\"end\":56760,\"start\":56749},{\"end\":57081,\"start\":57068},{\"end\":57091,\"start\":57081},{\"end\":57106,\"start\":57091},{\"end\":57373,\"start\":57358},{\"end\":57387,\"start\":57373},{\"end\":57402,\"start\":57387},{\"end\":57920,\"start\":57902},{\"end\":57944,\"start\":57920},{\"end\":57959,\"start\":57944},{\"end\":57976,\"start\":57959},{\"end\":58458,\"start\":58442},{\"end\":58483,\"start\":58458},{\"end\":58497,\"start\":58483},{\"end\":58518,\"start\":58497},{\"end\":59026,\"start\":59010},{\"end\":59051,\"start\":59026},{\"end\":59072,\"start\":59051},{\"end\":59472,\"start\":59455},{\"end\":59485,\"start\":59472},{\"end\":59501,\"start\":59485},{\"end\":59516,\"start\":59501},{\"end\":59715,\"start\":59700},{\"end\":59731,\"start\":59715},{\"end\":59747,\"start\":59731},{\"end\":59759,\"start\":59747},{\"end\":60154,\"start\":60139},{\"end\":60164,\"start\":60154},{\"end\":60173,\"start\":60164},{\"end\":60435,\"start\":60423},{\"end\":60447,\"start\":60435},{\"end\":60456,\"start\":60447},{\"end\":60467,\"start\":60456},{\"end\":60478,\"start\":60467},{\"end\":60492,\"start\":60478},{\"end\":61016,\"start\":61004},{\"end\":61028,\"start\":61016},{\"end\":61039,\"start\":61028},{\"end\":61052,\"start\":61039},{\"end\":61066,\"start\":61052},{\"end\":61083,\"start\":61066},{\"end\":61089,\"start\":61083},{\"end\":61375,\"start\":61365},{\"end\":61387,\"start\":61375},{\"end\":61739,\"start\":61725},{\"end\":61752,\"start\":61739},{\"end\":61764,\"start\":61752},{\"end\":61772,\"start\":61764},{\"end\":61787,\"start\":61772},{\"end\":61800,\"start\":61787},{\"end\":62469,\"start\":62462},{\"end\":62486,\"start\":62469},{\"end\":62502,\"start\":62486},{\"end\":62516,\"start\":62502},{\"end\":62527,\"start\":62516},{\"end\":62536,\"start\":62527},{\"end\":63120,\"start\":63113},{\"end\":63129,\"start\":63120},{\"end\":63146,\"start\":63129},{\"end\":63162,\"start\":63146},{\"end\":63460,\"start\":63438},{\"end\":63471,\"start\":63460},{\"end\":63475,\"start\":63471},{\"end\":63835,\"start\":63820},{\"end\":63855,\"start\":63835},{\"end\":63866,\"start\":63855},{\"end\":63876,\"start\":63866},{\"end\":63889,\"start\":63876},{\"end\":64408,\"start\":64395},{\"end\":64416,\"start\":64408},{\"end\":64425,\"start\":64416},{\"end\":64438,\"start\":64425},{\"end\":64451,\"start\":64438},{\"end\":64818,\"start\":64805},{\"end\":64826,\"start\":64818},{\"end\":64839,\"start\":64826},{\"end\":64848,\"start\":64839},{\"end\":64861,\"start\":64848},{\"end\":64870,\"start\":64861},{\"end\":64882,\"start\":64870},{\"end\":65274,\"start\":65261},{\"end\":65281,\"start\":65274},{\"end\":65289,\"start\":65281},{\"end\":65298,\"start\":65289},{\"end\":65311,\"start\":65298}]", "bib_venue": "[{\"end\":47628,\"start\":47590},{\"end\":48031,\"start\":47955},{\"end\":48371,\"start\":48354},{\"end\":48854,\"start\":48743},{\"end\":49350,\"start\":49321},{\"end\":49677,\"start\":49599},{\"end\":50150,\"start\":50114},{\"end\":50559,\"start\":50484},{\"end\":51012,\"start\":50956},{\"end\":51398,\"start\":51300},{\"end\":51929,\"start\":51830},{\"end\":52377,\"start\":52373},{\"end\":52685,\"start\":52610},{\"end\":53198,\"start\":53087},{\"end\":53733,\"start\":53631},{\"end\":54012,\"start\":53994},{\"end\":54325,\"start\":54227},{\"end\":54708,\"start\":54697},{\"end\":55019,\"start\":54928},{\"end\":55459,\"start\":55436},{\"end\":55766,\"start\":55723},{\"end\":56155,\"start\":56092},{\"end\":56468,\"start\":56432},{\"end\":56809,\"start\":56760},{\"end\":57155,\"start\":57106},{\"end\":57500,\"start\":57402},{\"end\":58053,\"start\":57976},{\"end\":58602,\"start\":58518},{\"end\":59138,\"start\":59072},{\"end\":59453,\"start\":59425},{\"end\":59825,\"start\":59759},{\"end\":60211,\"start\":60173},{\"end\":60584,\"start\":60492},{\"end\":61105,\"start\":61089},{\"end\":61430,\"start\":61387},{\"end\":61923,\"start\":61800},{\"end\":62635,\"start\":62536},{\"end\":63166,\"start\":63162},{\"end\":63517,\"start\":63475},{\"end\":63987,\"start\":63889},{\"end\":64494,\"start\":64451},{\"end\":64932,\"start\":64882},{\"end\":65329,\"start\":65311},{\"end\":48952,\"start\":48856},{\"end\":49759,\"start\":49679},{\"end\":50621,\"start\":50561},{\"end\":51483,\"start\":51400},{\"end\":52015,\"start\":51931},{\"end\":52747,\"start\":52687},{\"end\":53296,\"start\":53200},{\"end\":54410,\"start\":54327},{\"end\":55097,\"start\":55021},{\"end\":57585,\"start\":57502},{\"end\":58117,\"start\":58055},{\"end\":58673,\"start\":58604},{\"end\":59191,\"start\":59140},{\"end\":59878,\"start\":59827},{\"end\":60680,\"start\":60586},{\"end\":62050,\"start\":61925},{\"end\":62721,\"start\":62637},{\"end\":63536,\"start\":63519},{\"end\":64072,\"start\":63989}]"}}}, "year": 2023, "month": 12, "day": 17}