{"id": 52333947, "updated": "2023-10-02 15:25:03.395", "metadata": {"title": "Towards Exploiting Background Knowledge for Building Conversation Systems", "authors": "[{\"first\":\"Nikita\",\"last\":\"Moghe\",\"middle\":[]},{\"first\":\"Siddhartha\",\"last\":\"Arora\",\"middle\":[]},{\"first\":\"Suman\",\"last\":\"Banerjee\",\"middle\":[]},{\"first\":\"Mitesh M.\",\"last\":\"Khapra\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of models which treat conversation as a sequence-to-sequence generation task (i.e., given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1809.08205", "mag": "2952713681", "acl": "D18-1255", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/MogheABK18", "doi": "10.18653/v1/d18-1255"}}, "content": {"source": {"pdf_hash": "1677f55e519781303fd6f42e3892023150cf0717", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/D18-1255.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/D18-1255.pdf", "status": "HYBRID"}}, "grobid": {"id": "aa9b8b03b857ebe8f967ccd5118c43910b89b35c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1677f55e519781303fd6f42e3892023150cf0717.txt", "contents": "\nTowards Exploiting Background Knowledge for Building Conversation Systems\nAssociation for Computational Linguistics 2322Copyright Association for Computational Linguistics 2322October 31 -November 4. 2018. 2018\n\nNikita Moghe nikitavam@cse.iitm.ac.in \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Madras\n\n\nRobert Bosch Centre for Data Science and AI (RBC-DSAI)\nIndian Institute of Technology Madras\n\n\nSiddhartha Arora sidarora@cse.iitm.ac.in \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Madras\n\n\nSuman Banerjee \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Madras\n\n\nMitesh M Khapra miteshk@cse.iitm.ac.in \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Madras\n\n\nRobert Bosch Centre for Data Science and AI (RBC-DSAI)\nIndian Institute of Technology Madras\n\n\nTowards Exploiting Background Knowledge for Building Conversation Systems\n\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\nthe 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational Linguistics 2322October 31 -November 4. 2018. 2018\nExisting dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of models which treat conversation as a sequenceto-sequence generation task (i.e., given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.\n\nIntroduction\n\nBackground knowledge plays a very important role in human conversations. For example, to have a meaningful conversation about a movie, one uses their knowledge about the plot, reviews, comments and facts about the movie. A typical conversation involves recalling important points from this background knowledge and producing them appropriately in the context of the conversation. However, most existing large scale datasets (Lowe et al., 2015b;Ritter et al., 2010;Serban et al., 2016) simply contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has led to the development of models which treat conversation as a simple sequence-to-sequence generation task and often produce output which is both syntactically incorrect and incoherent (off topic). To make conversations more coherent, there is an increasing interest in integrating structured and unstructured knowledge sources with neural conversation models. While there are already some works in this direction (Rojas-Barahona et al., 2017;Williams et al., 2016;Lowe et al., 2015a;Ghazvininejad et al., 2017) which try to integrate external knowledge sources with existing datasets, we believe that building new datasets where the utterances are explicitly linked to external background knowledge will further facilitate the development of such background aware conversation models.\n\nWith this motivation, we built a new background aware conversation dataset using crowdsourcing. Specifically, we asked workers to chat about a movie using structured and unstructured resources about the movie such as plots, reviews, comments, fact tables (see Figure 1). For every even numbered utterance, we asked the workers to consult the available background knowledge and try to construct a sentence which contains information from this background knowledge and is relevant in the current context of the conversation (akin to how humans recall things from their background knowledge and insert them appropriately in the conversation). For example, in Turn 2, Speaker 2 picked a sentence from the plot which is relevant to the current context of the conversation. Similarly, in Turn 3, Speaker 2 picked a ... The lab works on spiders and has even managed to create new species of spiders through genetic manipulation. While Peter is taking photographs of Mary Jane for the school newspaper, one of these new spiders lands on his hand and bites him Peter comes home feeling ill and immediately goes to bed. ...\n\n\nPlot\n\n... I thoroughly enjoyed \"Spider-Man\" which I saw in a screening. I thought the movie was very engrossing. Director Sam Raimi kept the action quotient high, but also emphasized the human element of the story. Tobey was brilliant as a gawky teenager...\n\n\nReview\n\nSpeaker 1(N): Which is your favourite character?\n\nSpeaker 2(C): My favorite character was Tobey Maguire.\n\nSpeaker 1(N): I thought he did an excellent job as peter parker, I didn't see what it was that turned him into Spider-Man though.\n\nSpeaker 2(P): Well this happens while Peter is taking photographs of Mary Jane for the school newspaper, one of these new spiders lands on his hand and bites him.\n\nSpeaker 1 (N): I see. I was very excited to see this film and it did not disappoint! Speaker 2(R): I agree, I thoroughly enjoyed \"Spider-Man\" Speaker 1(N): I loved that they stayed true to the comic.\n\nSpeaker 2(C): Yeah, it was a really great comic book adaptation Speaker 1(N): The movie is a great life lesson on balancing power.\n\nSpeaker 2(F): That is my most favorite line in the movie, \"With great power comes great responsibility.\" sentence from the movie review. We also asked the workers to suitably modify the content picked from the background knowledge, if needed, so that the conversation remains coherent. We collected around 9K such conversations containing a total of 90K utterances pertaining to about 921 movies. These conversations along with the background resources will be made publicly available 1 . For every utterance, we also provide information about the exact span in the resource from which this utterance was created. Lastly note that unlike existing datasets, our test set contains multiple reference responses for each test context thereby facilitating better evaluation of conversation models. We believe that this dataset will allow the community to take a fresh look at conversation modeling and will lead to the development of models which can learn to exploit background knowledge to pick appropriate responses instead of generating responses from scratch. Such a conversation strategy which produces responses from background knowledge would be useful in various domains. For example, a troubleshooting bot could exploit the information available in manuals, reviews and previous bug reports about the software. Similarly, an e-commerce bot could exploit the rich information available in product descriptions, reviews, fact tables, etc. about the product. While the proposed dataset is domain specific, it 1 https://github.com/nikitacs16/Holl-E serves as a good benchmark for developing creative background-knowledge-aware models which can then be ported to different domains by building similar datasets for other domains.\n\nWe establish some initial baselines using three different paradigms to demonstrate the various models that can be developed and evaluated using this dataset. For the sake of completeness, the first paradigm is a hierarchical variant of the sequence to sequence architecture which does not exploit any background knowledge. The second paradigm is the copy-and-generate paradigm wherein the model tries to copy text from the given resources whenever appropriate and generate it otherwise. The third paradigm borrows from the span prediction based models which are predominantly being used for Question Answering (QA). These baseline results along with the dataset would hopefully shape future research in the area of background aware conversation models.\n\n\nRelated Work\n\nThere has been an active interest in building datasets  for training dialog systems. Some of these datasets contain transcripts of human-bot conversations (Williams et al., 2013;Henderson et al., 2014a,b) while others are created using a fixed set of natural language patterns (Bordes and Weston, 2017;Dodge et al., 2016). The advent of deep learning created interest in the construction of large-scale dialog datasets (Lowe et al., 2015b;Ritter et al., 2010;Sordoni et al., 2015) leading to the development of several end-to-end conversation systems (Shang et al., 2015;Vinyals and Le, 2015;Li et al., 2016;Serban et al., 2016) which treat dialog as a sequence generation task.\n\nTo make the output of these models more coherent, there is an increasing effort in integrating external background knowledge with these models. This is because human beings rely on background knowledge for conversations as well as other tasks (Schallert, 2002). There has been considerable work on incorporating background knowledge in the context of goal-oriented dialog datasets even before the advent of large-scale datasets for deep learning (Raux et al., 2005;Seneff et al., 1991) as well as in recent times (Rojas-Barahona et al., 2017;Williams et al., 2016; where datasets include small sized knowledge graphs as background knowledge. However, the conversations in these datasets are very templated and nowhere close to open conversations in specific domains such as the ones contained in our dataset.\n\nEven in the case of open domain conversations, there are some works which have integrated external knowledge sources. Most of the entries in 2017 Amazon Alexa Prize (Ram et al., 2017) relied on background knowledge for meaningful response generation. Milabot (Serban et al., 2017a) and even the winning entry Sound-ingBoard (Liu et al., 2018) used Reddit pages, Amazon's Evi Service, and large databases like OMDB, Google Knowledge Graph and Wikidata as external knowledge. The submission named Eigen (Guss et al., 2017) used several dialog datasets and corpora belonging to related Natural Language Processing tasks to make their responses more informative. We refer the reader to (Ram et al., 2017) for detailed analysis of these systems. In the space of academic datasets, Lowe et al. (2015a) report results on the Ubuntu dataset using manpages as external knowledge whereas Ghazvininejad et al. (2017) use Foursquare tips as external knowledge for social media conversations. However, unlike our work both these works do not create a new dataset where the responses are explicitly linked to a knowledge source. The infusion of external knowledge in both these works is post facto (as opposed to our work where we take a bottom-up approach and explicitly create a dataset which allows exploitation of background knowledge). Additionally, existing large-scale datasets are noisy as they are extracted from online forums which are inherently noisy. In contrast, since we use crowdsourcing, the extent of noise is reduced since there are humans in the loop who were explicitly instructed to use only clean sentences from the external knowledge sources.\n\nWe would also like to mention some existing works such as (He et al., 2017;Lewis et al., 2017;Krause et al., 2017) which have used crowdsourcing for creating conversation datasets. In fact, our data collection method is inspired by the work of Krause et al. (2017) where the authors use selfdialogs to collect conversation data about movies, music and sports. They are referred to as selfdialogs because the same worker plays the role of both parties in the conversation. However, our work differs from Krause et al. (2017) as we provide explicit background knowledge sources to the workers from where they can copy text with the addition of suitable prefixes and suffixes to generate appropriate coherent responses.\n\n\nDataset\n\nIn the following sub-sections we describe the various stages involved in collecting our dataset.\n\n\nCurating a list of popular movies\n\nWe created a list of 921 movies containing (i) top 10 popular movies within the past five years, (ii) top 250 movies as per IMDb rankings, (iii) top 10 movies in popular genres, and (iv) other popular movie lists made available elsewhere on the Internet. These movies belonged to 22 different genres such as sci-fi, action, horror, fantasy, adventure, romance, etc. thereby ensuring that our dataset is not limited to a specific genre. We considered those movies for which enough background information such as plots, reviews, comments, facts, etc. were available on the Internet irrespective of whether they were box-office successes or not. Please find the respective urls in the Appendix.\n\n\nCollecting background knowledge\n\nFor each movie, we collected the following background knowledge:\n\n1. Review (R): For each movie, we asked some in-house workers to fetch the top 2 most popular reviews for this movie from IMDb using the sort by Total Votes option. We also instructed them to avoid choosing reviews which were less than 50 words but this was typically never the case with popular reviews. 2. Plot (P): For each movie, we extracted information about the \"Plot\" of the movie from the Wikipedia page of the movie. Wikipedia pages of movies have an explicit section on \"Plot\" making it easy to extract this information using scripts. 3. Comments (C): Websites like Reddit have a segment called \"official discussion page about X\" (where X is a movie name) containing small comments about various aspects of movie. We identified such pages and extracted the first comment on every thread on this page. We bundled all these comments into a single text file and refer to it as the resource containing \"Comments\". For a few movies, the official discussion page was not present in which case we used the review titles of all the IMDb reviews of the movie as comments. The difference between Reviews and Comments is that a Review is an opinion piece given by one person thus typically exhibiting one sentiment throughout while Comments include opinions of several people about the same movie ensuring that positive, negative and factual aspects of the movie are captured as well as some banter.\n\n4. Meta data or Fact Table (F): For each movie, we also collected factual details about the movie, viz., box office collection, similar movies (for recommendations), awards and tag-lines from the corresponding IMDb pages and Wikipedia Infoboxes. Such information would be useful for inserting facts in the conversation, for example, \"Did you know that the movie won an Oscar?\". We included only 4 fields in our fact table instead of showing the entire Wikipedia Infobox to reduce the cognitive load on turkers who already had to read the plot, reviews and comments of the movie.\n\n\nCollecting conversation starters\n\nDuring our initial pilots, we observed that if we asked the workers to converse for at least 8 turns, they used a lot of the initial turns in greetings and general chit-chat before actually chatting about a movie. To avoid this, we collected opening statements using Amazon Mechanical Turk (AMT) where the task for the workers was to answer the following questions \"What is your favorite scene from the movie X ?\", \"What is your favorite character from the movie X ?\" and \"What is your opin-ion about the movie X?\" (X is the movie name). We paid the workers 0.04$ per movie and showed the same movie to 3 different workers, thereby collecting 9 different opening statements for every movie. By using these statements as conversation starters in our data collection, the workers could now directly start conversing about the movie.\n\n\nCollecting background knowledge aware conversations via crowdsourcing\n\nOur aim is to create a conversation dataset wherein every response is explicitly linked to some structured or unstructured background knowledge. Creating such a dataset using dedicated in-house workers would obviously be expensive and time consuming and so we decided to use crowdsourcing. However, unlike other NLP and Vision tasks, where crowdsourcing has been very successful, collecting conversations via crowdsourcing is a bit challenging. The main difficulty arises from the fact that conversation is inherently a task involving two persons but it is hard to get two workers to synchronize and chat on AMT. We did try a few pilot experiments where we setup a server to connect two AMT workers but we found that the probability of two workers simultaneously logging in was very low. Thus, most workers logged in and left in a few seconds because no other worker joined simultaneously. Finally, we took inspiration from the idea of self chats Krause et al. (2017) in which, the same worker plays the role of both Speaker 1 and Speaker 2 to create the chat. In the above self chat setup, we showed every worker 3 to 4 resources related to the movie, viz., plot (P), review (R), comments (C) and fact table (F). We also showed them a randomly selected opening statement from the 9 opening statements that we had collected for each movie and requested them to continue the conversation from that point. The workers were asked to add at least 8 utterances to this initial chat. While playing the role of Speaker 1, the worker was not restricted to copy/modify sentences from the background resources but was given the freedom to create (write) original sentences. However, when playing the role of Speaker 2, the worker was strictly instructed to copy/modify sentences from the shown resources such that they were relevant in the current context of the conversation. The reason for not imposing any restrictions on Speaker 1 was to ensure that the chats look more natural and coherent. Further, Speaker 2 was allowed to add words at the beginning or end of the span selected from the resources to make the chats more coherent and natural (for example, see the prefix in utterance 2 of Speaker 2 in Figure 1). We paid the workers 40 cents for every chat. Please refer to the Appendix for the instruction screen shots.\n\n\nVerification of the collected chats\n\nEvery chat that was collected by the above process was verified by an in-house evaluator to check if the workers adhered to the instructions and produced coherent chats. Since humans typically tend to paraphrase the background knowledge acquired by reading articles, one could argue that such conversations may not look very natural because of this restriction to copy/modify content from the provided resources. To verify this, we conducted a separate human evaluation wherein we asked 15 in-house evaluators to read conversations (without the background resources) from our dataset and rate them on five different parameters. Specifically, they were asked to check if the conversations were 1) intelligible: i.e., an average reader could understand the conversation 2) coherent: i.e., there were no abrupt context switches 3) grammatically correct 4) on-topic: i.e., the chat revolved around the concerned movie with digression limited to related movies/characters/actors and 5) natural two-person chats: i.e., the roleplay setup does not make the chat look unnatural. These evaluators were post-graduate students who were fluent in English and had watched at least 100 Hollywood movies. We did not give them any information about the data creation process. We used a total of 500 chats for the evaluation and every chat was shown to 3 different evaluators. The evaluators rated the conversations on a scale of 1 (very poor) to 5 (very good). We computed inter-annotator agreement using the mean linearly weighted Cohen's \u03ba (Cohen, 1968) and mean Krippendorff's \u03b1 (Hayes and Krippendorff, 2007). The average rating for each of the 5 parameters along with the inter annotator agreement are reported in Table 1 and are very encouraging.\n\n\nStatistics\n\nIn Table 2, we show different statistics about the dataset collected using the above process. These include average number of utterances per chat, average number of words per utterance, and so on followed by the statistics of the different re-  \n\n\nModels\n\nWe evaluate three different types of models as described below. Since these are popular existing models, we describe them very briefly below and refer the reader to the original papers for more details. Note that in this work we merge the comments, reviews, plots and facts into one single document and refer to it as background knowledge. In the rest of the paper, when we refer to a resource we mean this single document which is a merger of all the resources unless specified otherwise.\n\n\nGeneration based models\n\nWe use the standard Hierarchical Recurrent Encoder Decoder model (HRED) (Serban et al., 2016) instead of its variant (Serban et al., 2017b) as the standard model performs only slightly poorly than the variant and is much easier to implement. It decomposes the context of the conversation as two level hierarchy using Recurrent Neural Networks (RNN). The lower RNN encodes individual utterances (sequence of words) which is then fed into the higher level RNN as a sequence of utterances. The decoder RNN then generates the output based on this hierarchical context representation.\n\n\nGenerate-or-Copy models\n\nGet To The Point (GTTP) (See et al., 2017) proposed a hybrid pointer generator network for abstractive summarization that learns to copy words from the source document when required and otherwise generates a word like any sequence-tosequence model. In the summarization task, the input is a document and the output is a summary whereas in our case the input is a {document, con-text} pair and the output is a response. Here, the context includes the previous two utterances and the current utterance. We modified the architecture to suit our task. We use an RNN to compute the representation of the document (like the original model) and introduce another RNN to compute a representation of the context by treating it as a single sequence of words. The decoder which is also an RNN then uses the document representation, context representation and its own internal state representation to compute a (i) probability score which indicates whether the next word should be copied or generated (ii) probability distribution over the vocabulary if the next word needs to be generated and (iii) probability distribution over the input words if the next word needs to be copied. These three probability distributions are then combined to produce the next word in the response.\n\n\nSpan prediction models\n\nBi-directional Attention Flow Model (BiDAF) (Seo et al., 2017) model is a QA model which was proposed in the context of the SQuAD dataset (Rajpurkar et al., 2016). Given a document and a question, the model uses a six-layered architecture to predict the span in the document which contains the answer. We can use their model as it is for our task without any modifications by simply treating the context as the question and the resource as the document.\n\nWe chose to evaluate on the modified generateor-copy model instead of other variants such as (Ghazvininejad et al., 2017;Lowe et al., 2015a) as the modified model already contains the extra encoder for background model which is present in these models. Moreover, the modified model uses a hybrid copy-or-generate decoder which is wellsuited to our task.\n\n\nExperimental Setup\n\nIn this section we describe the train-validationtest splits, the process used for creating training instances, the manner in which the models were trained using our data and the evaluation metrics.\n\n\nCreating train/valid/test splits\n\nOn average we have 9.14 chats per movie. We divide the collected chats into train, validation, and test splits such that all the chats corresponding to a given movie are in exactly one of the splits. This ensures that a movie seen in the test or validation set is never seen at training time. We create the splits such that the percentage of chats in the trainvalidation-test set is roughly 80%-10%-10%.\n\n\nCreating training instances\n\nFor each chat in the training data, we construct training instances of the form {resource, context, response} where the context is taken as previous two utterances and current utterance. We consider only the even numbered utterances as training examples as they are generated from the background resources thus emulating a human-bot setup. If a chat has 10 turns, we will have 5 instances. The task then is to train a model which can predict these even numbered responses. At test time the model is shown {resource, context} and predicts the response. Note that, HRED will ignore the resource and only use {context, response} as input-output pairs. BiDAF and GTTP will use {resource, context, response} as training data with relevant span instead of response for BiDAF.\n\n\nMerging resources into a single document\n\nAs stated earlier, we simply merge all the background information to create a single document which we collectively refer to as resource. For the BiDAF model, we had to restrict the length of the resource to 256 words because we found that even on a K80 GPU with 12GB RAM, this model gives an out of memory error for longer documents. We found this to be a severe limitation of this and other span based models (for example, R-Net (Wang et al., 2017)) . We experimented with three methods of creating this resource. The first method oracle uses the actual resource (plot or comments or reviews) from which the next response was generated as a resource. If that resource itself has more than 256 words then we truncate it from the beginning and the end such that the span containing the actual response is contained within the retained 256 words. The number of words that are discarded from the start or the end is chosen at random so that the correct spans do not end up in similar positions throughout the dataset. The next two methods mixed-short and mixed-long are created by merging the individual resources. We retain each resource in the merged document proportional to its length. (i.e,if there are 400 words in the plot, 200 words in the review and 100 in the comments, the merged resource will contain contiguous sentences from these three resources in the ratio of 4:2:1.) Further, we ensure that the merged resource contains the actual response span. In this way, we create mixed-short with 256 words and mixed-long with 1200 words (the maximum length of the merged resources). We will henceforth denote oracle, mixed-long and mixed-short using '(o) ', '(ms) 'and '(ml) 'respectively. We report results for BiDAF(o), BiDAF (ms), GTTP (o) and GTTP (ml).\n\n\nEvaluation metrics\n\nAs HRED and GTTP models are generation based models we use BLEU-4, ROUGE-1, ROUGE-2 and ROUGE-L as the evaluation metrics. For BiDAF we use the above metrics by comparing the predicted span with the reference span. For BiDAF, we also report F1 as stated in Rajpurkar et al. (2016).\n\nIn addition to the automatic evaluation, we also collected human judgments using 100 test responses generated for every model for every setup (oracle, mixed-short, mixed-long). These evaluators had the same qualifications as the evaluators who earlier helped us evaluate our dataset. They were asked to rate the response on scale of 1 to 5 (with 1 being the least) on the following four metrics: (1) Fluency(Flu), (2) appropriateness/relevance (apt) of the response in the current context language (3) humanness (Hum) of the response, i.e., whether the responses look as if they were generated by a human (4) and specificity (spec) of the response, i.e., whether the model produced movie-specific responses or generic responses such as \"This movie is amazing\". We report these results in Table 4.\n\n\nCollecting multiple reference responses\n\nOne common issue with evaluating dialog systems is that existing datasets typically contain only one reference response whereas in practice several responses can be correct in a given context. To solve this to a certain extent, we collected three reference responses for every Speaker 2 utterance in our dataset (note that Speaker 2 is treated as the bot while training/testing our models). We show the previous utterances ending with Speaker 1's response and ask workers to provide three appropriate responses from the given resources. We found that in some cases there was only one appropriate response like factual response and the workers could not provide multiple references . In this way we were able to create a multiple reference test set where 78.04% of the test instances have multiple responses. In Table 3, we report two sets of scores based on single-reference test dataset and multireference test dataset. While calculating the scores for multi-reference dataset, we take the maximum score over multiple reference responses.\n\nPlease refer to the Appendix section for the details of the model, hyperparameters, example of multiple references in our dataset and sample outputs produced by different models.\n\n\nResults and Discussion\n\nIn this section, we discuss the results of our experiments as summarized in Tables 3 and 4.\n\nGeneration based models v/s Span prediction models: We compare the generation based models and span prediction models only based on results in the oracle setting. Here, the span based model (BiDAF) outperforms the generation based models (HRED and GTTP). This confirms our belief that the natural language generation (NLG) capabilities of current generation based models are far from being acceptable even in case of generateor-copy modes. This also emphasizes the importance of this data which allows building models which can exploit well-formed sentences in the background knowledge and reproduce them with minor modifications instead of generating them from scratch. While the results for BiDAF are   encouraging, we reiterate that it does not scale to longer documents (we were not able to run it in the mixed-long setting). We still need much better models as BiDAF on SQuAD dataset gives an F1 of 81.52 % which is much higher than the results on our dataset. Further, note that using the predicted span as a response is not natural. This is evident from human likeliness (Hum) score of GTTP (o) being higher than both the BiDAF models. We need models which can suitably alter the span to retain the coherence of the context. Effect of including background knowledge: We observe that there isn't much difference between the performance of HRED which does not use any background knowledge when compared to GTTP (ml) which actually uses a lot of background knowledge. However, there is a substantial difference between the performance of HRED and GTTP (o) which uses only the relevant background knowledge. Further, without background knowledge, HRED learns to produce very generic responses (Spec score = 2.06). This shows that the background knowledge is important, but the models should learn to focus on the right background knowledge relevant to the current context. Alternately, we can have a two-stage network which first predicts the right resource (plot, review, comments) from which the span should be selected and then selects the span from this chosen resource.\n\nOracle v/s mixed-short resource: We observe that the performance of BiDAF (ms) is actually better than BiDAF (o) even when the resource length for both is 256 words. We would expect a poor performance for BiDAF (ms) as the resource has more noise because of the sentences from irrelevant resources. However, we speculate the model learns to regard irrelevant sentences as noise and learns to focus on sentences corresponding to the correct resource resulting in improved performance (however, this is only a hypothesis and it needs to be verified). We realize that this is clearly a poor baseline and we need better span prediction based models which can work with longer documents. At the same time, GTTP (o) and GTTP (ms) have comparable (yet poor) performance. There is no co-attention mechanism in this model which can effectively filter out noisy sentences.\n\nObservations from the copy-and-gen model: We observed that this model produced sentences where on average of 82.18% (oracle) and 71.95% (mixed-long) of the tokens were copied. One interesting observation was that it easily learns to copy longer contiguous sequences one word at a time. However, as is evident from the automatic evaluation metrics, in many cases, the 'copied' spans are not relevant to the current context.\n\nEvaluating with multiple references: When considering multiple references, the performance numbers as reported in Table 3 indeed improve. This shows the importance of having multiple references and the need to develop metrics which account for multiple dissimilar references.\n\n\nConclusion\n\nWe introduce a new dataset for building dialog systems which would hopefully allow the community to take a fresh look at this task. Unlike existing datasets which only contain a sequence of utterances, in our dataset each response is explic-itly linked to some background knowledge. This mimics how humans converse by recalling information from their background knowledge and use it appropriately in the context of the conversation. Using this dataset, we evaluated models belonging to three different paradigms, viz., generation based models, generate-or-copy models and span prediction models. Our results suggest that the NLG capabilities of existing seq-to-seq models are still far from desirable while span based models which completely bypass the process of NLG show some promise but with clear scope for improvement.\n\nGoing forward, we would like to build models which are a hybrid of span prediction models and generation models. Specifically, we would like to build models which can learn to copy a large sequence from the input instead of one word at a time. Another important aspect is to build less complex models which can handle longer documents. For example, the BiDAF model has an expensive outer product between two large matrices which makes it infeasible for long documents (because the size of these matrices grows with the length of the document). Alternately, we would like to build two-stage models which first select the correct resource from which the next response is to be generated and then generate or copy the response from the resource.\n\nTable\nMovie: Spider-Man ... Crazy attention to detail. My favorite character was Tobey Maguire. I can't get over the \"I'm gonna kill you dead\" line. It was too heavily reliant on constant light-hearted humor. However the constant joking around kinda bogged it down for me. A really great comic book adaptation. ....FactFigure 1: A sample chat from our dataset which uses background resources. The chosen spans used in the conversation are shown in blue. The letters in the brackets denote the type of resource that was chosen -P, C ,R, F and N indicate Plot, Comments, Review, Fact Table and None respectively.Comments \n\nAwards \nGolden Trailer \nAwards 2002 \n\nTaglines \n\nWith great \npower comes \ngreat \nresponsibility. \nGet Ready For \nSpidey ! \nSimilar \nMovies \n\nIron Man \nSpider-Man 2 \n\n\n\nTable 2 :\n2Statistics of the datasetsources which were used as background knowl-\nedge. Please note that the # unique Plots and \n# unique Reviews correspond to unique para-\ngraphs while the # unique Comments is the count \nof unique sentences. We observed that 41.2%, \n34.6%, 16.1% and 8.1% of Speaker 2 responses \ncame from Reviews, Comments, Plots and Fact \nTable respectively. \n\n\n\n\nBiDAF (ms) 45.73 51.35 32.95 39.39 45.69 50.73 40.18 45.01 43.46 46.95Model \nF1 \nBLEU \nRouge-1 \nRouge-2 \nRouge-L \nHRED \n-\n-\n5.23 \n5.38 24.55 25.38 7.61 \n8.35 18.87 19.67 \nGTTP (o) \n-\n-\n13.92 16.46 30.32 31.6 17.78 21.21 25.67 27.83 \nGTTP (ms) \n-\n-\n11.05 15.68 29.66 31.71 17.70 19.72 25.13 27.35 \nGTTP (ml) \n-\n-\n7.51 \n8.73 23.20 21.55 9.91 10.42 17.35 18.12 \nBiDAF (o) \n39.69 47.18 28.85 34.98 39.68 46.49 33.72 40.58 35.91 42.64 \n\n\nTable 3 :\n3Performance of the proposed models on our dataset. The figures on the left in each column indicate scores on single-reference test dataset while the figures on the right denote scores on multi-reference dataset.Model \nHum Apt Flu Spec \nHRED \n3.08 \n2.49 2.64 2.06 \nGTTP (o) \n4.10 \n3.73 4.03 3.33 \nGTTP (ml) 2.93 \n2.97 3.42 2.60 \nBiDAF (o) \n3.78 \n3.71 4.05 3.76 \nBiDAF(ms) 3.41 \n3.38 3.47 3.30 \n\n\n\nTable 4 :\n4Human evaluation results on the model performances.\nAcknowledgementsWe would like to thank Department of Computer Science and Engineering, and Robert Bosch Center for Data Sciences and Artificial Intelligence, IIT Madras (RBC-DSAI) for providing us with adequate resources. We also thank Gurneet Singh and Sarath Chandar for helping us in the data collection phase two and three respectively. Lastly, we thank all the AMT workers around the world and our in-house evaluators.\nLearning end-to-end goal-oriented dialog. International Conference on Learning Representations. Antoine Bordes, Jason Weston, Antoine Bordes and Jason Weston. 2017. Learning end-to-end goal-oriented dialog. International Con- ference on Learning Representations.\n\nWeighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit. Jacob Cohen, Psychological bulletin. 704213Jacob Cohen. 1968. Weighted kappa: Nominal scale agreement provision for scaled disagreement or par- tial credit. Psychological bulletin, 70(4):213.\n\nEvaluating prerequisite qualities for learning end-to-end dialog systems. Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander H Miller, Arthur Szlam, Jason Weston, abs/1511.06931International Conference on Learning Representations. Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander H. Miller, Arthur Szlam, and Jason Weston. 2016. Evaluating prereq- uisite qualities for learning end-to-end dialog sys- tems. International Conference on Learning Repre- sentations, abs/1511.06931.\n\nKey-value retrieval networks for task-oriented dialogue. Mihail Eric, Lakshmi Krishnan, Francois Charette, Christopher D Manning, Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue. the 18th Annual SIGdial Meeting on Discourse and DialogueSaarbr\u00fccken, GermanyMihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher D. Manning. 2017. Key-value retrieval networks for task-oriented dialogue. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, Saarbr\u00fccken, Germany, August 15- 17, 2017, pages 37-49.\n\nMarjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, abs/1702.01932Wen-tau Yih, and Michel Galley. 2017. A knowledge-grounded neural conversation model. CoRR. Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and Michel Galley. 2017. A knowledge-grounded neural conversation model. CoRR, abs/1702.01932.\n\nEigen: A step towards conversational ai. H William, James Guss, Phillip Bartlett, Piyush Kuznetsov, Patil, Alexa Prize ProceedingsWilliam H. Guss, James Bartlett, Phillip Kuznetsov, and Piyush Patil. 2017. Eigen: A step towards con- versational ai. Alexa Prize Proceedings.\n\nAnswering the call for a standard reliability measure for coding data. Communication methods and measures. F Andrew, Klaus Hayes, Krippendorff, 1Andrew F Hayes and Klaus Krippendorff. 2007. An- swering the call for a standard reliability measure for coding data. Communication methods and mea- sures, 1(1):77-89.\n\nLearning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings. He He, Anusha Balakrishnan, Mihail Eric, Percy Liang, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaLong Papers1He He, Anusha Balakrishnan, Mihail Eric, and Percy Liang. 2017. Learning symmetric collaborative dia- logue agents with dynamic knowledge graph embed- dings. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 -August 4, Vol- ume 1: Long Papers, pages 1766-1776.\n\nThe second dialog state tracking challenge. Matthew Henderson, Blaise Thomson, Jason D Williams, Proceedings of the SIGDIAL. the SIGDIALMatthew Henderson, Blaise Thomson, and Jason D. Williams. 2014a. The second dialog state tracking challenge. In Proceedings of the SIGDIAL 2014\n\nConference, The 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Philadelphia, PA, USAConference, The 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue, 18-20 June 2014, Philadelphia, PA, USA, pages 263-272.\n\nThe third dialog state tracking challenge. Matthew Henderson, Blaise Thomson, Jason D Williams, IEEE Spoken Language Technology Workshop. Matthew Henderson, Blaise Thomson, and Jason D. Williams. 2014b. The third dialog state tracking challenge. In 2014 IEEE Spoken Language Tech- nology Workshop, SLT 2014, South Lake Tahoe, NV, USA, December 7-10, 2014, pages 324-329.\n\nEdina: Building an open domain socialbot with self-dialogues. Ben Krause, Marco Damonte, Mihai Dobre, Daniel Duma, Joachim Fainberg, Federico Fancellu, Emmanuel Kahembwe, Jianpeng Cheng, Bonnie L Webber, Alexa Prize ProceedingsBen Krause, Marco Damonte, Mihai Dobre, Daniel Duma, Joachim Fainberg, Federico Fancellu, Em- manuel Kahembwe, Jianpeng Cheng, and Bonnie L. Webber. 2017. Edina: Building an open domain so- cialbot with self-dialogues. Alexa Prize Proceed- ings.\n\nDeal or no deal? end-to-end learning of negotiation dialogues. Mike Lewis, Denis Yarats, Yann Dauphin, Devi Parikh, Dhruv Batra, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, Denmark2017Mike Lewis, Denis Yarats, Yann Dauphin, Devi Parikh, and Dhruv Batra. 2017. Deal or no deal? end-to-end learning of negotiation dialogues. In Proceedings of the 2017 Conference on Empirical Methods in Nat- ural Language Processing, EMNLP 2017, Copen- hagen, Denmark, September 9-11, 2017, pages 2443-2453.\n\nA persona-based neural conversation model. Jiwei Li, Michel Galley, Chris Brockett, Georgios P Spithourakis, Jianfeng Gao, William B Dolan, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016. the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016Berlin, GermanyLong Papers1Jiwei Li, Michel Galley, Chris Brockett, Georgios P. Spithourakis, Jianfeng Gao, and William B. Dolan. 2016. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the As- sociation for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, pages 994-1003.\n\nDemonstrations. Yang Liu, Tim Paek, Manasi Patwardhan, Editors, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics. the 2018 Conference of the North American Chapter of the Association for Computational LinguisticsNew Orleans, Louisiana, USAAssociation for Computational LinguisticsYang Liu, Tim Paek, and Manasi Patwardhan, edi- tors. 2018. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics, NAACL-HTL 2018, New Orleans, Louisiana, USA, June 2-4, 2018, Demon- strations. Association for Computational Linguis- tics.\n\nIncorporating unstructured textual knowledge sources into neural dialogue systems. Ryan Lowe, Nissan Pow, Iulian Serban, Laurent Charlin, Joelle Pineau, Neural Information Processing Systems Workshop on Machine Learning for Spoken Language Understanding. Ryan Lowe, Nissan Pow, Iulian Serban, Laurent Char- lin, and Joelle Pineau. 2015a. Incorporating un- structured textual knowledge sources into neural di- alogue systems. In Neural Information Processing Systems Workshop on Machine Learning for Spoken Language Understanding.\n\nThe ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. Ryan Lowe, Nissan Pow, Iulian Serban, Joelle Pineau, Proceedings of the SIGDIAL. the SIGDIALRyan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau. 2015b. The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dia- logue systems. In Proceedings of the SIGDIAL 2015\n\nConference, The 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Prague, Czech RepublicConference, The 16th Annual Meeting of the Spe- cial Interest Group on Discourse and Dialogue, 2- 4 September 2015, Prague, Czech Republic, pages 285-294.\n\nSquad: 100, 000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingAustin, Texas, USAPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Nat- ural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 2383-2392.\n\nAshwin Ram, Rohit Prasad, Chandra Khatri, Anu Venkatesh, Raefer Gabriel, Qing Liu, Jeff Nunn, Behnam Hedayatnia, Ming Cheng, Ashish Nagar, Gene Hwang, and Art Pettigrue. 2017. Conversational AI: the science behind the alexa prize. Alexa Prize Proceedings. Eric King, Kate Bland, Amanda Wartick, Yi Pan, Han Song, Sk JayadevanAshwin Ram, Rohit Prasad, Chandra Khatri, Anu Venkatesh, Raefer Gabriel, Qing Liu, Jeff Nunn, Behnam Hedayatnia, Ming Cheng, Ashish Nagar, Eric King, Kate Bland, Amanda Wartick, Yi Pan, Han Song, Sk Jayadevan, Gene Hwang, and Art Pet- tigrue. 2017. Conversational AI: the science behind the alexa prize. Alexa Prize Proceedings.\n\nLet's go public! taking a spoken dialog system to the real world. Antoine Raux, Brian Langner, Dan Bohus, Alan W Black, Maxine Esk\u00e9nazi, INTERSPEECH 2005 -Eurospeech, 9th European Conference on Speech Communication and Technology. Lisbon, PortugalAntoine Raux, Brian Langner, Dan Bohus, Alan W. Black, and Maxine Esk\u00e9nazi. 2005. Let's go public! taking a spoken dialog system to the real world. In INTERSPEECH 2005 -Eurospeech, 9th European Conference on Speech Communication and Technol- ogy, Lisbon, Portugal, September 4-8, 2005, pages 885-888.\n\nUnsupervised modeling of twitter conversations. Alan Ritter, Colin Cherry, Bill Dolan, Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings. Los Angeles, California, USAAlan Ritter, Colin Cherry, and Bill Dolan. 2010. Un- supervised modeling of twitter conversations. In Human Language Technologies: Conference of the North American Chapter of the Association of Com- putational Linguistics, Proceedings, June 2-4, 2010, Los Angeles, California, USA, pages 172-180.\n\nA network-based end-to-end trainable task-oriented dialogue system. Lina Maria Rojas-Barahona, Milica Gasic, Nikola Mrksic, Pei-Hao Su, Stefan Ultes, Tsung-Hsien Wen, Steve J Young, David Vandyke, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. the 15th Conference of the European Chapter of the Association for Computational LinguisticsSpainLong Papers1Lina Maria Rojas-Barahona, Milica Gasic, Nikola Mrksic, Pei-Hao Su, Stefan Ultes, Tsung-Hsien Wen, Steve J. Young, and David Vandyke. 2017. A network-based end-to-end trainable task-oriented dialogue system. In Proceedings of the 15th Con- ference of the European Chapter of the Association for Computational Linguistics, EACL 2017, Valen- cia, Spain, April 3-7, 2017, Volume 1: Long Papers, pages 438-449.\n\nDiane L Schallert, Schema theory. Literacy in America: An encyclopedia of history, theory, and practice. Santa Barbara, CADiane L. Schallert. 2002. Schema theory. Literacy in America: An encyclopedia of history, theory, and practice Santa Barbara, CA, pages 556-558.\n\nGet to the point: Summarization with pointergenerator networks. Abigail See, J Peter, Christopher D Liu, Manning, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaLong Papers1Abigail See, Peter J. Liu, and Christopher D. Manning. 2017. Get to the point: Summarization with pointer- generator networks. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 -August 4, Volume 1: Long Papers, pages 1073- 1083.\n\nDevelopment and preliminary evaluation of the MIT ATIS system. Stephanie Seneff, James R Glass, David Goddeau, David Goodine, Lynette Hirschman, Hong C Leung, Michael S Phillips, Joseph Polifroni, Victor Zue, Speech and Natural Language. Pacific Grove, California, USAStephanie Seneff, James R. Glass, David Goddeau, David Goodine, Lynette Hirschman, Hong C. Le- ung, Michael S. Phillips, Joseph Polifroni, and Vic- tor Zue. 1991. Development and preliminary eval- uation of the MIT ATIS system. In Speech and Natural Language, Proceedings of a Workshop held at Pacific Grove, California, USA, February 19-22. 1991.\n\nBidirectional attention flow for machine comprehension. Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi, International Conference on Learning Representations. Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2017. Bidirectional atten- tion flow for machine comprehension. International Conference on Learning Representations.\n\nA survey of available corpora for building data-driven dialogue systems. Iulian Vlad Serban, Ryan Lowe, Peter Henderson, Laurent Charlin, Joelle Pineau, abs/1512.05742CoRR. Iulian Vlad Serban, Ryan Lowe, Peter Henderson, Lau- rent Charlin, and Joelle Pineau. 2015. A survey of available corpora for building data-driven dialogue systems. CoRR, abs/1512.05742.\n\nThe octopus approach to the alexa competition: A deep ensemble-based socialbot. Iulian Vlad Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath Chandar, Ke, Sai Mudumba, Alexandre de Br\u00e9bisson, Jose Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau, and Yoshua BengioAlexa Prize ProceedingsNan RosemaryIulian Vlad Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath Chandar, Nan Rosemary Ke, Sai Mudumba, Alexan- dre de Br\u00e9bisson, Jose Sotelo, Dendi Suhubdy, Vin- cent Michalski, Alexandre Nguyen, Joelle Pineau, and Yoshua Bengio. 2017a. The octopus approach to the alexa competition: A deep ensemble-based socialbot. Alexa Prize Proceedings.\n\nBuilding end-to-end dialogue systems using generative hierarchical neural network models. Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C Courville, Joelle Pineau, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. the Thirtieth AAAI Conference on Artificial IntelligencePhoenix, Arizona, USAIulian Vlad Serban, Alessandro Sordoni, Yoshua Ben- gio, Aaron C. Courville, and Joelle Pineau. 2016. Building end-to-end dialogue systems using gener- ative hierarchical neural network models. In Pro- ceedings of the Thirtieth AAAI Conference on Arti- ficial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA., pages 3776-3784.\n\nA hierarchical latent variable encoder-decoder model for generating dialogues. Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C Courville, Yoshua Bengio, Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence. the Thirty-First AAAI Conference on Artificial IntelligenceSan Francisco, California, USA.Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C. Courville, and Yoshua Bengio. 2017b. A hierarchical latent variable encoder-decoder model for generating di- alogues. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA., pages 3295- 3301.\n\nNeural responding machine for short-text conversation. Lifeng Shang, Zhengdong Lu, Hang Li, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing. the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language ProcessingBeijing, ChinaLong Papers1Lifeng Shang, Zhengdong Lu, and Hang Li. 2015. Neural responding machine for short-text conver- sation. In Proceedings of the 53rd Annual Meet- ing of the Association for Computational Linguistics and the 7th International Joint Conference on Natu- ral Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26- 31, 2015, Beijing, China, Volume 1: Long Papers, pages 1577-1586.\n\nA neural network approach to context-sensitive generation of conversational responses. Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, Bill Dolan, The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Denver, Colorado, USANAACL HLT 2015Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A neural network approach to context-sensitive gen- eration of conversational responses. In NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies, Denver, Colorado, USA, May 31 -June 5, 2015, pages 196- 205.\n\nA neural conversational model. Oriol Vinyals, V Quoc, Le, Proceedings of ICML Deep Learning Workshop. ICML Deep Learning WorkshopOriol Vinyals and Quoc V. Le. 2015. A neural con- versational model. In Proceedings of ICML Deep Learning Workshop, 2015.\n\nGated self-matching networks for reading comprehension and question answering. Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, Ming Zhou, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaLong Papers1Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, and Ming Zhou. 2017. Gated self-matching net- works for reading comprehension and question an- swering. In Proceedings of the 55th Annual Meet- ing of the Association for Computational Linguis- tics, ACL 2017, Vancouver, Canada, July 30 -August 4, Volume 1: Long Papers, pages 189-198.\n\nThe dialog state tracking challenge series: A review. Jason D Williams, Antoine Raux, Matthew Henderson, D&D. 73Jason D. Williams, Antoine Raux, and Matthew Hen- derson. 2016. The dialog state tracking challenge series: A review. D&D, 7(3):4-33.\n\nThe dialog state tracking challenge. Jason D Williams, Antoine Raux, Deepak Ramachandran, Alan W Black, The 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Metz, FranceProceedings of the SIGDIAL 2013 ConferenceJason D. Williams, Antoine Raux, Deepak Ramachan- dran, and Alan W. Black. 2013. The dialog state tracking challenge. In Proceedings of the SIGDIAL 2013 Conference, The 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue, 22-24 August 2013, SUPELEC, Metz, France, pages 404-413.\n", "annotations": {"author": "[{\"end\":433,\"start\":213},{\"end\":562,\"start\":434},{\"end\":665,\"start\":563},{\"end\":887,\"start\":666}]", "publisher": "[{\"end\":121,\"start\":75},{\"end\":1184,\"start\":1138}]", "author_last_name": "[{\"end\":225,\"start\":220},{\"end\":450,\"start\":445},{\"end\":577,\"start\":569},{\"end\":681,\"start\":675}]", "author_first_name": "[{\"end\":219,\"start\":213},{\"end\":444,\"start\":434},{\"end\":568,\"start\":563},{\"end\":672,\"start\":666},{\"end\":674,\"start\":673}]", "author_affiliation": "[{\"end\":337,\"start\":252},{\"end\":432,\"start\":339},{\"end\":561,\"start\":476},{\"end\":664,\"start\":579},{\"end\":791,\"start\":706},{\"end\":886,\"start\":793}]", "title": "[{\"end\":74,\"start\":1},{\"end\":961,\"start\":888}]", "venue": "[{\"end\":1049,\"start\":963}]", "abstract": "[{\"end\":2707,\"start\":1219}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3167,\"start\":3147},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3187,\"start\":3167},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3207,\"start\":3187},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3778,\"start\":3749},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3800,\"start\":3778},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3819,\"start\":3800},{\"end\":3846,\"start\":3819},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8917,\"start\":8894},{\"end\":8943,\"start\":8917},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9041,\"start\":9016},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9060,\"start\":9041},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9178,\"start\":9158},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9198,\"start\":9178},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9219,\"start\":9198},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9310,\"start\":9290},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9331,\"start\":9310},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9347,\"start\":9331},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9367,\"start\":9347},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9679,\"start\":9662},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9884,\"start\":9865},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9904,\"start\":9884},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9961,\"start\":9932},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9983,\"start\":9961},{\"end\":10412,\"start\":10394},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10510,\"start\":10488},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10571,\"start\":10553},{\"end\":10929,\"start\":10911},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11024,\"start\":11005},{\"end\":11134,\"start\":11107},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11958,\"start\":11941},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11977,\"start\":11958},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11997,\"start\":11977},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12147,\"start\":12127},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12406,\"start\":12386},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17425,\"start\":17405},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20352,\"start\":20340},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20410,\"start\":20391},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21431,\"start\":21410},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21477,\"start\":21455},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21987,\"start\":21969},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23302,\"start\":23284},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23402,\"start\":23378},{\"end\":23816,\"start\":23788},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23835,\"start\":23816},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":26004,\"start\":25985},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":27620,\"start\":27597}]", "figure": "[{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35815,\"start\":35027},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":36197,\"start\":35816},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36631,\"start\":36198},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":37038,\"start\":36632},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37102,\"start\":37039}]", "paragraph": "[{\"end\":4120,\"start\":2723},{\"end\":5235,\"start\":4122},{\"end\":5495,\"start\":5244},{\"end\":5554,\"start\":5506},{\"end\":5610,\"start\":5556},{\"end\":5741,\"start\":5612},{\"end\":5905,\"start\":5743},{\"end\":6106,\"start\":5907},{\"end\":6238,\"start\":6108},{\"end\":7968,\"start\":6240},{\"end\":8722,\"start\":7970},{\"end\":9417,\"start\":8739},{\"end\":10227,\"start\":9419},{\"end\":11881,\"start\":10229},{\"end\":12599,\"start\":11883},{\"end\":12707,\"start\":12611},{\"end\":13436,\"start\":12745},{\"end\":13536,\"start\":13472},{\"end\":14937,\"start\":13538},{\"end\":15517,\"start\":14939},{\"end\":16384,\"start\":15554},{\"end\":18774,\"start\":16458},{\"end\":20550,\"start\":18814},{\"end\":20810,\"start\":20565},{\"end\":21310,\"start\":20821},{\"end\":21917,\"start\":21338},{\"end\":23213,\"start\":21945},{\"end\":23693,\"start\":23240},{\"end\":24048,\"start\":23695},{\"end\":24268,\"start\":24071},{\"end\":24708,\"start\":24305},{\"end\":25509,\"start\":24740},{\"end\":27317,\"start\":25554},{\"end\":27621,\"start\":27340},{\"end\":28419,\"start\":27623},{\"end\":29502,\"start\":28463},{\"end\":29682,\"start\":29504},{\"end\":29800,\"start\":29709},{\"end\":31879,\"start\":29802},{\"end\":32743,\"start\":31881},{\"end\":33167,\"start\":32745},{\"end\":33444,\"start\":33169},{\"end\":34282,\"start\":33459},{\"end\":35026,\"start\":34284}]", "formula": null, "table_ref": "[{\"end\":14970,\"start\":14960},{\"end\":20524,\"start\":20517},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":20575,\"start\":20568},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":28418,\"start\":28411},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":29281,\"start\":29274},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":29799,\"start\":29785},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":33290,\"start\":33283}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2721,\"start\":2709},{\"end\":5242,\"start\":5238},{\"end\":5504,\"start\":5498},{\"attributes\":{\"n\":\"2\"},\"end\":8737,\"start\":8725},{\"attributes\":{\"n\":\"3\"},\"end\":12609,\"start\":12602},{\"attributes\":{\"n\":\"3.1\"},\"end\":12743,\"start\":12710},{\"attributes\":{\"n\":\"3.2\"},\"end\":13470,\"start\":13439},{\"attributes\":{\"n\":\"3.3\"},\"end\":15552,\"start\":15520},{\"attributes\":{\"n\":\"3.4\"},\"end\":16456,\"start\":16387},{\"attributes\":{\"n\":\"3.5\"},\"end\":18812,\"start\":18777},{\"attributes\":{\"n\":\"3.6\"},\"end\":20563,\"start\":20553},{\"attributes\":{\"n\":\"4\"},\"end\":20819,\"start\":20813},{\"attributes\":{\"n\":\"4.1\"},\"end\":21336,\"start\":21313},{\"attributes\":{\"n\":\"4.2\"},\"end\":21943,\"start\":21920},{\"attributes\":{\"n\":\"4.3\"},\"end\":23238,\"start\":23216},{\"attributes\":{\"n\":\"5\"},\"end\":24069,\"start\":24051},{\"attributes\":{\"n\":\"5.1\"},\"end\":24303,\"start\":24271},{\"attributes\":{\"n\":\"5.2\"},\"end\":24738,\"start\":24711},{\"attributes\":{\"n\":\"5.3\"},\"end\":25552,\"start\":25512},{\"attributes\":{\"n\":\"5.4\"},\"end\":27338,\"start\":27320},{\"attributes\":{\"n\":\"5.5\"},\"end\":28461,\"start\":28422},{\"attributes\":{\"n\":\"6\"},\"end\":29707,\"start\":29685},{\"attributes\":{\"n\":\"7\"},\"end\":33457,\"start\":33447},{\"end\":35033,\"start\":35028},{\"end\":35826,\"start\":35817},{\"end\":36642,\"start\":36633},{\"end\":37049,\"start\":37040}]", "table": "[{\"end\":35815,\"start\":35638},{\"end\":36197,\"start\":35853},{\"end\":36631,\"start\":36270},{\"end\":37038,\"start\":36855}]", "figure_caption": "[{\"end\":35638,\"start\":35034},{\"end\":35853,\"start\":35828},{\"end\":36270,\"start\":36200},{\"end\":36855,\"start\":36644},{\"end\":37102,\"start\":37051}]", "figure_ref": "[{\"end\":4390,\"start\":4382},{\"end\":18664,\"start\":18656}]", "bib_author_first_name": "[{\"end\":37630,\"start\":37623},{\"end\":37644,\"start\":37639},{\"end\":37889,\"start\":37884},{\"end\":38156,\"start\":38151},{\"end\":38171,\"start\":38164},{\"end\":38183,\"start\":38178},{\"end\":38198,\"start\":38191},{\"end\":38212,\"start\":38207},{\"end\":38230,\"start\":38221},{\"end\":38232,\"start\":38231},{\"end\":38247,\"start\":38241},{\"end\":38260,\"start\":38255},{\"end\":38680,\"start\":38674},{\"end\":38694,\"start\":38687},{\"end\":38713,\"start\":38705},{\"end\":38735,\"start\":38724},{\"end\":38737,\"start\":38736},{\"end\":39179,\"start\":39173},{\"end\":39200,\"start\":39195},{\"end\":39219,\"start\":39211},{\"end\":39231,\"start\":39227},{\"end\":39247,\"start\":39239},{\"end\":39590,\"start\":39589},{\"end\":39605,\"start\":39600},{\"end\":39619,\"start\":39612},{\"end\":39636,\"start\":39630},{\"end\":39931,\"start\":39930},{\"end\":39945,\"start\":39940},{\"end\":40229,\"start\":40227},{\"end\":40240,\"start\":40234},{\"end\":40261,\"start\":40255},{\"end\":40273,\"start\":40268},{\"end\":40863,\"start\":40856},{\"end\":40881,\"start\":40875},{\"end\":40896,\"start\":40891},{\"end\":40898,\"start\":40897},{\"end\":41406,\"start\":41399},{\"end\":41424,\"start\":41418},{\"end\":41439,\"start\":41434},{\"end\":41441,\"start\":41440},{\"end\":41793,\"start\":41790},{\"end\":41807,\"start\":41802},{\"end\":41822,\"start\":41817},{\"end\":41836,\"start\":41830},{\"end\":41850,\"start\":41843},{\"end\":41869,\"start\":41861},{\"end\":41888,\"start\":41880},{\"end\":41907,\"start\":41899},{\"end\":41921,\"start\":41915},{\"end\":41923,\"start\":41922},{\"end\":42269,\"start\":42265},{\"end\":42282,\"start\":42277},{\"end\":42295,\"start\":42291},{\"end\":42309,\"start\":42305},{\"end\":42323,\"start\":42318},{\"end\":42868,\"start\":42863},{\"end\":42879,\"start\":42873},{\"end\":42893,\"start\":42888},{\"end\":42912,\"start\":42904},{\"end\":42914,\"start\":42913},{\"end\":42937,\"start\":42929},{\"end\":42950,\"start\":42943},{\"end\":42952,\"start\":42951},{\"end\":43520,\"start\":43516},{\"end\":43529,\"start\":43526},{\"end\":43542,\"start\":43536},{\"end\":44232,\"start\":44228},{\"end\":44245,\"start\":44239},{\"end\":44257,\"start\":44251},{\"end\":44273,\"start\":44266},{\"end\":44289,\"start\":44283},{\"end\":44782,\"start\":44778},{\"end\":44795,\"start\":44789},{\"end\":44807,\"start\":44801},{\"end\":44822,\"start\":44816},{\"end\":45413,\"start\":45407},{\"end\":45429,\"start\":45425},{\"end\":45447,\"start\":45437},{\"end\":45462,\"start\":45457},{\"end\":45951,\"start\":45945},{\"end\":45962,\"start\":45957},{\"end\":45978,\"start\":45971},{\"end\":45990,\"start\":45987},{\"end\":46008,\"start\":46002},{\"end\":46022,\"start\":46018},{\"end\":46032,\"start\":46028},{\"end\":46045,\"start\":46039},{\"end\":46062,\"start\":46058},{\"end\":46076,\"start\":46070},{\"end\":46673,\"start\":46666},{\"end\":46685,\"start\":46680},{\"end\":46698,\"start\":46695},{\"end\":46710,\"start\":46706},{\"end\":46712,\"start\":46711},{\"end\":46726,\"start\":46720},{\"end\":47201,\"start\":47197},{\"end\":47215,\"start\":47210},{\"end\":47228,\"start\":47224},{\"end\":47766,\"start\":47762},{\"end\":47772,\"start\":47767},{\"end\":47795,\"start\":47789},{\"end\":47809,\"start\":47803},{\"end\":47825,\"start\":47818},{\"end\":47836,\"start\":47830},{\"end\":47855,\"start\":47844},{\"end\":47866,\"start\":47861},{\"end\":47868,\"start\":47867},{\"end\":47881,\"start\":47876},{\"end\":48522,\"start\":48517},{\"end\":48524,\"start\":48523},{\"end\":48856,\"start\":48849},{\"end\":48863,\"start\":48862},{\"end\":48882,\"start\":48871},{\"end\":48884,\"start\":48883},{\"end\":49472,\"start\":49463},{\"end\":49486,\"start\":49481},{\"end\":49488,\"start\":49487},{\"end\":49501,\"start\":49496},{\"end\":49516,\"start\":49511},{\"end\":49533,\"start\":49526},{\"end\":49549,\"start\":49545},{\"end\":49551,\"start\":49550},{\"end\":49566,\"start\":49559},{\"end\":49568,\"start\":49567},{\"end\":49585,\"start\":49579},{\"end\":49603,\"start\":49597},{\"end\":50081,\"start\":50073},{\"end\":50096,\"start\":50087},{\"end\":50110,\"start\":50107},{\"end\":50128,\"start\":50120},{\"end\":50465,\"start\":50459},{\"end\":50483,\"start\":50479},{\"end\":50495,\"start\":50490},{\"end\":50514,\"start\":50507},{\"end\":50530,\"start\":50524},{\"end\":50833,\"start\":50827},{\"end\":50859,\"start\":50847},{\"end\":50875,\"start\":50868},{\"end\":50893,\"start\":50885},{\"end\":50908,\"start\":50901},{\"end\":50921,\"start\":50914},{\"end\":50941,\"start\":50935},{\"end\":50954,\"start\":50947},{\"end\":50969,\"start\":50963},{\"end\":51670,\"start\":51664},{\"end\":51694,\"start\":51684},{\"end\":51710,\"start\":51704},{\"end\":51724,\"start\":51719},{\"end\":51726,\"start\":51725},{\"end\":51744,\"start\":51738},{\"end\":52326,\"start\":52320},{\"end\":52350,\"start\":52340},{\"end\":52364,\"start\":52360},{\"end\":52378,\"start\":52371},{\"end\":52394,\"start\":52388},{\"end\":52408,\"start\":52403},{\"end\":52410,\"start\":52409},{\"end\":52428,\"start\":52422},{\"end\":53025,\"start\":53019},{\"end\":53042,\"start\":53033},{\"end\":53051,\"start\":53047},{\"end\":54013,\"start\":54003},{\"end\":54029,\"start\":54023},{\"end\":54045,\"start\":54038},{\"end\":54057,\"start\":54052},{\"end\":54076,\"start\":54068},{\"end\":54089,\"start\":54081},{\"end\":54108,\"start\":54100},{\"end\":54122,\"start\":54114},{\"end\":54132,\"start\":54128},{\"end\":54788,\"start\":54783},{\"end\":54799,\"start\":54798},{\"end\":55089,\"start\":55083},{\"end\":55099,\"start\":55096},{\"end\":55110,\"start\":55106},{\"end\":55122,\"start\":55116},{\"end\":55134,\"start\":55130},{\"end\":55724,\"start\":55719},{\"end\":55726,\"start\":55725},{\"end\":55744,\"start\":55737},{\"end\":55758,\"start\":55751},{\"end\":55954,\"start\":55949},{\"end\":55956,\"start\":55955},{\"end\":55974,\"start\":55967},{\"end\":55987,\"start\":55981},{\"end\":56006,\"start\":56002},{\"end\":56008,\"start\":56007}]", "bib_author_last_name": "[{\"end\":37637,\"start\":37631},{\"end\":37651,\"start\":37645},{\"end\":37895,\"start\":37890},{\"end\":38162,\"start\":38157},{\"end\":38176,\"start\":38172},{\"end\":38189,\"start\":38184},{\"end\":38205,\"start\":38199},{\"end\":38219,\"start\":38213},{\"end\":38239,\"start\":38233},{\"end\":38253,\"start\":38248},{\"end\":38267,\"start\":38261},{\"end\":38685,\"start\":38681},{\"end\":38703,\"start\":38695},{\"end\":38722,\"start\":38714},{\"end\":38745,\"start\":38738},{\"end\":39193,\"start\":39180},{\"end\":39209,\"start\":39201},{\"end\":39225,\"start\":39220},{\"end\":39237,\"start\":39232},{\"end\":39251,\"start\":39248},{\"end\":39598,\"start\":39591},{\"end\":39610,\"start\":39606},{\"end\":39628,\"start\":39620},{\"end\":39646,\"start\":39637},{\"end\":39653,\"start\":39648},{\"end\":39938,\"start\":39932},{\"end\":39951,\"start\":39946},{\"end\":39965,\"start\":39953},{\"end\":40232,\"start\":40230},{\"end\":40253,\"start\":40241},{\"end\":40266,\"start\":40262},{\"end\":40279,\"start\":40274},{\"end\":40873,\"start\":40864},{\"end\":40889,\"start\":40882},{\"end\":40907,\"start\":40899},{\"end\":41103,\"start\":41093},{\"end\":41416,\"start\":41407},{\"end\":41432,\"start\":41425},{\"end\":41450,\"start\":41442},{\"end\":41800,\"start\":41794},{\"end\":41815,\"start\":41808},{\"end\":41828,\"start\":41823},{\"end\":41841,\"start\":41837},{\"end\":41859,\"start\":41851},{\"end\":41878,\"start\":41870},{\"end\":41897,\"start\":41889},{\"end\":41913,\"start\":41908},{\"end\":41930,\"start\":41924},{\"end\":42275,\"start\":42270},{\"end\":42289,\"start\":42283},{\"end\":42303,\"start\":42296},{\"end\":42316,\"start\":42310},{\"end\":42329,\"start\":42324},{\"end\":42871,\"start\":42869},{\"end\":42886,\"start\":42880},{\"end\":42902,\"start\":42894},{\"end\":42927,\"start\":42915},{\"end\":42941,\"start\":42938},{\"end\":42958,\"start\":42953},{\"end\":43524,\"start\":43521},{\"end\":43534,\"start\":43530},{\"end\":43553,\"start\":43543},{\"end\":43562,\"start\":43555},{\"end\":44237,\"start\":44233},{\"end\":44249,\"start\":44246},{\"end\":44264,\"start\":44258},{\"end\":44281,\"start\":44274},{\"end\":44296,\"start\":44290},{\"end\":44787,\"start\":44783},{\"end\":44799,\"start\":44796},{\"end\":44814,\"start\":44808},{\"end\":44829,\"start\":44823},{\"end\":45084,\"start\":45074},{\"end\":45423,\"start\":45414},{\"end\":45435,\"start\":45430},{\"end\":45455,\"start\":45448},{\"end\":45468,\"start\":45463},{\"end\":45955,\"start\":45952},{\"end\":45969,\"start\":45963},{\"end\":45985,\"start\":45979},{\"end\":46000,\"start\":45991},{\"end\":46016,\"start\":46009},{\"end\":46026,\"start\":46023},{\"end\":46037,\"start\":46033},{\"end\":46056,\"start\":46046},{\"end\":46068,\"start\":46063},{\"end\":46082,\"start\":46077},{\"end\":46678,\"start\":46674},{\"end\":46693,\"start\":46686},{\"end\":46704,\"start\":46699},{\"end\":46718,\"start\":46713},{\"end\":46735,\"start\":46727},{\"end\":47208,\"start\":47202},{\"end\":47222,\"start\":47216},{\"end\":47234,\"start\":47229},{\"end\":47787,\"start\":47773},{\"end\":47801,\"start\":47796},{\"end\":47816,\"start\":47810},{\"end\":47828,\"start\":47826},{\"end\":47842,\"start\":47837},{\"end\":47859,\"start\":47856},{\"end\":47874,\"start\":47869},{\"end\":47889,\"start\":47882},{\"end\":48534,\"start\":48525},{\"end\":48860,\"start\":48857},{\"end\":48869,\"start\":48864},{\"end\":48888,\"start\":48885},{\"end\":48897,\"start\":48890},{\"end\":49479,\"start\":49473},{\"end\":49494,\"start\":49489},{\"end\":49509,\"start\":49502},{\"end\":49524,\"start\":49517},{\"end\":49543,\"start\":49534},{\"end\":49557,\"start\":49552},{\"end\":49577,\"start\":49569},{\"end\":49595,\"start\":49586},{\"end\":49607,\"start\":49604},{\"end\":50085,\"start\":50082},{\"end\":50105,\"start\":50097},{\"end\":50118,\"start\":50111},{\"end\":50139,\"start\":50129},{\"end\":50477,\"start\":50466},{\"end\":50488,\"start\":50484},{\"end\":50505,\"start\":50496},{\"end\":50522,\"start\":50515},{\"end\":50537,\"start\":50531},{\"end\":50845,\"start\":50834},{\"end\":50866,\"start\":50860},{\"end\":50883,\"start\":50876},{\"end\":50899,\"start\":50894},{\"end\":50912,\"start\":50909},{\"end\":50933,\"start\":50922},{\"end\":50945,\"start\":50942},{\"end\":50961,\"start\":50955},{\"end\":50977,\"start\":50970},{\"end\":51682,\"start\":51671},{\"end\":51702,\"start\":51695},{\"end\":51717,\"start\":51711},{\"end\":51736,\"start\":51727},{\"end\":51751,\"start\":51745},{\"end\":52338,\"start\":52327},{\"end\":52358,\"start\":52351},{\"end\":52369,\"start\":52365},{\"end\":52386,\"start\":52379},{\"end\":52401,\"start\":52395},{\"end\":52420,\"start\":52411},{\"end\":52435,\"start\":52429},{\"end\":53031,\"start\":53026},{\"end\":53045,\"start\":53043},{\"end\":53054,\"start\":53052},{\"end\":54021,\"start\":54014},{\"end\":54036,\"start\":54030},{\"end\":54050,\"start\":54046},{\"end\":54066,\"start\":54058},{\"end\":54079,\"start\":54077},{\"end\":54098,\"start\":54090},{\"end\":54112,\"start\":54109},{\"end\":54126,\"start\":54123},{\"end\":54138,\"start\":54133},{\"end\":54796,\"start\":54789},{\"end\":54804,\"start\":54800},{\"end\":54808,\"start\":54806},{\"end\":55094,\"start\":55090},{\"end\":55104,\"start\":55100},{\"end\":55114,\"start\":55111},{\"end\":55128,\"start\":55123},{\"end\":55139,\"start\":55135},{\"end\":55735,\"start\":55727},{\"end\":55749,\"start\":55745},{\"end\":55768,\"start\":55759},{\"end\":55965,\"start\":55957},{\"end\":55979,\"start\":55975},{\"end\":56000,\"start\":55988},{\"end\":56014,\"start\":56009}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":37789,\"start\":37527},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":29694079},\"end\":38075,\"start\":37791},{\"attributes\":{\"doi\":\"abs/1511.06931\",\"id\":\"b2\",\"matched_paper_id\":2239496},\"end\":38615,\"start\":38077},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":5932528},\"end\":39171,\"start\":38617},{\"attributes\":{\"doi\":\"abs/1702.01932\",\"id\":\"b4\"},\"end\":39546,\"start\":39173},{\"attributes\":{\"id\":\"b5\"},\"end\":39821,\"start\":39548},{\"attributes\":{\"id\":\"b6\"},\"end\":40135,\"start\":39823},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3051772},\"end\":40810,\"start\":40137},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1294169},\"end\":41091,\"start\":40812},{\"attributes\":{\"id\":\"b9\"},\"end\":41354,\"start\":41093},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":17478615},\"end\":41726,\"start\":41356},{\"attributes\":{\"id\":\"b11\"},\"end\":42200,\"start\":41728},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2454882},\"end\":42818,\"start\":42202},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2955580},\"end\":43498,\"start\":42820},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":209359903},\"end\":44143,\"start\":43500},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":13812031},\"end\":44674,\"start\":44145},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8379583},\"end\":45072,\"start\":44676},{\"attributes\":{\"id\":\"b17\"},\"end\":45343,\"start\":45074},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":11816014},\"end\":45943,\"start\":45345},{\"attributes\":{\"id\":\"b19\"},\"end\":46598,\"start\":45945},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":281507},\"end\":47147,\"start\":46600},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":16322335},\"end\":47692,\"start\":47149},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":10565222},\"end\":48515,\"start\":47694},{\"attributes\":{\"id\":\"b23\"},\"end\":48783,\"start\":48517},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":8314118},\"end\":49398,\"start\":48785},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3503845},\"end\":50015,\"start\":49400},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8535316},\"end\":50384,\"start\":50017},{\"attributes\":{\"doi\":\"abs/1512.05742\",\"id\":\"b27\",\"matched_paper_id\":5415347},\"end\":50745,\"start\":50386},{\"attributes\":{\"id\":\"b28\"},\"end\":51572,\"start\":50747},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":6126582},\"end\":52239,\"start\":51574},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":14857825},\"end\":52962,\"start\":52241},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7356547},\"end\":53914,\"start\":52964},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":94285},\"end\":54750,\"start\":53916},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":12300158},\"end\":55002,\"start\":54752},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":12501880},\"end\":55663,\"start\":55004},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":14569897},\"end\":55910,\"start\":55665},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":10250499},\"end\":56453,\"start\":55912}]", "bib_title": "[{\"end\":37882,\"start\":37791},{\"end\":38149,\"start\":38077},{\"end\":38672,\"start\":38617},{\"end\":40225,\"start\":40137},{\"end\":40854,\"start\":40812},{\"end\":41397,\"start\":41356},{\"end\":42263,\"start\":42202},{\"end\":42861,\"start\":42820},{\"end\":43514,\"start\":43500},{\"end\":44226,\"start\":44145},{\"end\":44776,\"start\":44676},{\"end\":45405,\"start\":45345},{\"end\":46664,\"start\":46600},{\"end\":47195,\"start\":47149},{\"end\":47760,\"start\":47694},{\"end\":48847,\"start\":48785},{\"end\":49461,\"start\":49400},{\"end\":50071,\"start\":50017},{\"end\":50457,\"start\":50386},{\"end\":51662,\"start\":51574},{\"end\":52318,\"start\":52241},{\"end\":53017,\"start\":52964},{\"end\":54001,\"start\":53916},{\"end\":54781,\"start\":54752},{\"end\":55081,\"start\":55004},{\"end\":55717,\"start\":55665},{\"end\":55947,\"start\":55912}]", "bib_author": "[{\"end\":37639,\"start\":37623},{\"end\":37653,\"start\":37639},{\"end\":37897,\"start\":37884},{\"end\":38164,\"start\":38151},{\"end\":38178,\"start\":38164},{\"end\":38191,\"start\":38178},{\"end\":38207,\"start\":38191},{\"end\":38221,\"start\":38207},{\"end\":38241,\"start\":38221},{\"end\":38255,\"start\":38241},{\"end\":38269,\"start\":38255},{\"end\":38687,\"start\":38674},{\"end\":38705,\"start\":38687},{\"end\":38724,\"start\":38705},{\"end\":38747,\"start\":38724},{\"end\":39195,\"start\":39173},{\"end\":39211,\"start\":39195},{\"end\":39227,\"start\":39211},{\"end\":39239,\"start\":39227},{\"end\":39253,\"start\":39239},{\"end\":39600,\"start\":39589},{\"end\":39612,\"start\":39600},{\"end\":39630,\"start\":39612},{\"end\":39648,\"start\":39630},{\"end\":39655,\"start\":39648},{\"end\":39940,\"start\":39930},{\"end\":39953,\"start\":39940},{\"end\":39967,\"start\":39953},{\"end\":40234,\"start\":40227},{\"end\":40255,\"start\":40234},{\"end\":40268,\"start\":40255},{\"end\":40281,\"start\":40268},{\"end\":40875,\"start\":40856},{\"end\":40891,\"start\":40875},{\"end\":40909,\"start\":40891},{\"end\":41105,\"start\":41093},{\"end\":41418,\"start\":41399},{\"end\":41434,\"start\":41418},{\"end\":41452,\"start\":41434},{\"end\":41802,\"start\":41790},{\"end\":41817,\"start\":41802},{\"end\":41830,\"start\":41817},{\"end\":41843,\"start\":41830},{\"end\":41861,\"start\":41843},{\"end\":41880,\"start\":41861},{\"end\":41899,\"start\":41880},{\"end\":41915,\"start\":41899},{\"end\":41932,\"start\":41915},{\"end\":42277,\"start\":42265},{\"end\":42291,\"start\":42277},{\"end\":42305,\"start\":42291},{\"end\":42318,\"start\":42305},{\"end\":42331,\"start\":42318},{\"end\":42873,\"start\":42863},{\"end\":42888,\"start\":42873},{\"end\":42904,\"start\":42888},{\"end\":42929,\"start\":42904},{\"end\":42943,\"start\":42929},{\"end\":42960,\"start\":42943},{\"end\":43526,\"start\":43516},{\"end\":43536,\"start\":43526},{\"end\":43555,\"start\":43536},{\"end\":43564,\"start\":43555},{\"end\":44239,\"start\":44228},{\"end\":44251,\"start\":44239},{\"end\":44266,\"start\":44251},{\"end\":44283,\"start\":44266},{\"end\":44298,\"start\":44283},{\"end\":44789,\"start\":44778},{\"end\":44801,\"start\":44789},{\"end\":44816,\"start\":44801},{\"end\":44831,\"start\":44816},{\"end\":45086,\"start\":45074},{\"end\":45425,\"start\":45407},{\"end\":45437,\"start\":45425},{\"end\":45457,\"start\":45437},{\"end\":45470,\"start\":45457},{\"end\":45957,\"start\":45945},{\"end\":45971,\"start\":45957},{\"end\":45987,\"start\":45971},{\"end\":46002,\"start\":45987},{\"end\":46018,\"start\":46002},{\"end\":46028,\"start\":46018},{\"end\":46039,\"start\":46028},{\"end\":46058,\"start\":46039},{\"end\":46070,\"start\":46058},{\"end\":46084,\"start\":46070},{\"end\":46680,\"start\":46666},{\"end\":46695,\"start\":46680},{\"end\":46706,\"start\":46695},{\"end\":46720,\"start\":46706},{\"end\":46737,\"start\":46720},{\"end\":47210,\"start\":47197},{\"end\":47224,\"start\":47210},{\"end\":47236,\"start\":47224},{\"end\":47789,\"start\":47762},{\"end\":47803,\"start\":47789},{\"end\":47818,\"start\":47803},{\"end\":47830,\"start\":47818},{\"end\":47844,\"start\":47830},{\"end\":47861,\"start\":47844},{\"end\":47876,\"start\":47861},{\"end\":47891,\"start\":47876},{\"end\":48536,\"start\":48517},{\"end\":48862,\"start\":48849},{\"end\":48871,\"start\":48862},{\"end\":48890,\"start\":48871},{\"end\":48899,\"start\":48890},{\"end\":49481,\"start\":49463},{\"end\":49496,\"start\":49481},{\"end\":49511,\"start\":49496},{\"end\":49526,\"start\":49511},{\"end\":49545,\"start\":49526},{\"end\":49559,\"start\":49545},{\"end\":49579,\"start\":49559},{\"end\":49597,\"start\":49579},{\"end\":49609,\"start\":49597},{\"end\":50087,\"start\":50073},{\"end\":50107,\"start\":50087},{\"end\":50120,\"start\":50107},{\"end\":50141,\"start\":50120},{\"end\":50479,\"start\":50459},{\"end\":50490,\"start\":50479},{\"end\":50507,\"start\":50490},{\"end\":50524,\"start\":50507},{\"end\":50539,\"start\":50524},{\"end\":50847,\"start\":50827},{\"end\":50868,\"start\":50847},{\"end\":50885,\"start\":50868},{\"end\":50901,\"start\":50885},{\"end\":50914,\"start\":50901},{\"end\":50935,\"start\":50914},{\"end\":50947,\"start\":50935},{\"end\":50963,\"start\":50947},{\"end\":50979,\"start\":50963},{\"end\":51684,\"start\":51664},{\"end\":51704,\"start\":51684},{\"end\":51719,\"start\":51704},{\"end\":51738,\"start\":51719},{\"end\":51753,\"start\":51738},{\"end\":52340,\"start\":52320},{\"end\":52360,\"start\":52340},{\"end\":52371,\"start\":52360},{\"end\":52388,\"start\":52371},{\"end\":52403,\"start\":52388},{\"end\":52422,\"start\":52403},{\"end\":52437,\"start\":52422},{\"end\":53033,\"start\":53019},{\"end\":53047,\"start\":53033},{\"end\":53056,\"start\":53047},{\"end\":54023,\"start\":54003},{\"end\":54038,\"start\":54023},{\"end\":54052,\"start\":54038},{\"end\":54068,\"start\":54052},{\"end\":54081,\"start\":54068},{\"end\":54100,\"start\":54081},{\"end\":54114,\"start\":54100},{\"end\":54128,\"start\":54114},{\"end\":54140,\"start\":54128},{\"end\":54798,\"start\":54783},{\"end\":54806,\"start\":54798},{\"end\":54810,\"start\":54806},{\"end\":55096,\"start\":55083},{\"end\":55106,\"start\":55096},{\"end\":55116,\"start\":55106},{\"end\":55130,\"start\":55116},{\"end\":55141,\"start\":55130},{\"end\":55737,\"start\":55719},{\"end\":55751,\"start\":55737},{\"end\":55770,\"start\":55751},{\"end\":55967,\"start\":55949},{\"end\":55981,\"start\":55967},{\"end\":56002,\"start\":55981},{\"end\":56016,\"start\":56002}]", "bib_venue": "[{\"end\":37621,\"start\":37527},{\"end\":37919,\"start\":37897},{\"end\":38335,\"start\":38283},{\"end\":38819,\"start\":38747},{\"end\":39357,\"start\":39267},{\"end\":39587,\"start\":39548},{\"end\":39928,\"start\":39823},{\"end\":40368,\"start\":40281},{\"end\":40935,\"start\":40909},{\"end\":41184,\"start\":41105},{\"end\":41492,\"start\":41452},{\"end\":41788,\"start\":41728},{\"end\":42417,\"start\":42331},{\"end\":43057,\"start\":42960},{\"end\":43677,\"start\":43564},{\"end\":44398,\"start\":44298},{\"end\":44857,\"start\":44831},{\"end\":45165,\"start\":45086},{\"end\":45556,\"start\":45470},{\"end\":46199,\"start\":46084},{\"end\":46829,\"start\":46737},{\"end\":47366,\"start\":47236},{\"end\":47998,\"start\":47891},{\"end\":48620,\"start\":48536},{\"end\":48986,\"start\":48899},{\"end\":49636,\"start\":49609},{\"end\":50193,\"start\":50141},{\"end\":50557,\"start\":50553},{\"end\":50825,\"start\":50747},{\"end\":51824,\"start\":51753},{\"end\":52511,\"start\":52437},{\"end\":53272,\"start\":53056},{\"end\":54267,\"start\":54140},{\"end\":54852,\"start\":54810},{\"end\":55228,\"start\":55141},{\"end\":55773,\"start\":55770},{\"end\":56095,\"start\":56016},{\"end\":38898,\"start\":38821},{\"end\":40459,\"start\":40370},{\"end\":40948,\"start\":40937},{\"end\":41207,\"start\":41186},{\"end\":42509,\"start\":42419},{\"end\":43156,\"start\":43059},{\"end\":43804,\"start\":43679},{\"end\":44870,\"start\":44859},{\"end\":45189,\"start\":45167},{\"end\":45647,\"start\":45558},{\"end\":46270,\"start\":46201},{\"end\":46847,\"start\":46831},{\"end\":47396,\"start\":47368},{\"end\":48097,\"start\":48000},{\"end\":48639,\"start\":48622},{\"end\":49077,\"start\":48988},{\"end\":49668,\"start\":49638},{\"end\":51903,\"start\":51826},{\"end\":52603,\"start\":52513},{\"end\":53489,\"start\":53274},{\"end\":54290,\"start\":54269},{\"end\":54881,\"start\":54854},{\"end\":55319,\"start\":55230},{\"end\":56109,\"start\":56097}]"}}}, "year": 2023, "month": 12, "day": 17}