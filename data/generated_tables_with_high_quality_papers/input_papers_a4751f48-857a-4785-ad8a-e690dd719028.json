[{"paperid": "paper0", "title": "Semi-Supervised Learning With Graph Learning-Convolutional Networks", "abstract": "Graph Convolutional Neural Networks (graph CNNs) have been widely used for graph data representation and semi-supervised learning tasks. However, existing graph CNNs generally use a fixed graph which may not be optimal for semi-supervised learning tasks. In this paper, we propose a novel Graph Learning-Convolutional Network (GLCN) for graph data representation and semi-supervised learning. The aim of GLCN is to learn an optimal graph structure that best serves graph CNNs for semi-supervised learning by integrating both graph learning and graph convolution in a unified network architecture. The main advantage is that in GLCN both given labels and the estimated labels are incorporated and thus can provide useful \u2018weakly\u2019 supervised information to refine (or learn) the graph construction and also to facilitate the graph convolution operation for unknown label estimation. Experimental results on seven benchmarks demonstrate that GLCN significantly outperforms the state-of-the-art traditional fixed structure based graph CNNs.", "introduction": "\n\nDeep neural networks have been widely used in many computer vision and pattern recognition tasks. Recently, many methods have been proposed to generalize the convolution operation on arbitrary graphs to address graph structure data [5,1,15,11,19,21]. Overall, these methods can be categorized into spatial convolution and spectral convolution methods [22]. For spatial methods, they generally define graph convolution operation directly by defining an operation on node groups of neighbors. For example, Duvenaud et al. [5] propose a convolutional neural network that operates directly on graphs and provide an end-to-end feature learning for graph data. Atwood and Towsley [1] propose Diffusion-Convolutional Neural Networks (DCNNs) by employing a graph diffusion process to incorporate the contextual information of node in graph node classification. * Corresponding author Monti et al. [15] present mixture model CNNs (MoNet) and provide a unified generalization of CNN architectures on graphs. By designing an attention layer, Veli\u010dkovi\u0107 et al. [21] present Graph Attention Networks (GAT) for semisupervised learning. For spectral methods, they generally define graph convolution operation based on spectral representation of graphs. For example, Bruna et al. [3] propose to define graph convolution in the Fourier domain based on eigen-decomposition of graph Laplacian matrix. Defferrard et al. [4] propose to approximate the spectral filters based on Chebyshev expansion of graph Laplacian to avoid the high computational complexity of eigen-decomposition. Kipf et al. [11] propose a more simple Graph Convolutional Network (GCN) for semi-supervised learning.\n\nThe above graph CNNs have been widely used for supervised or semi-supervised learning tasks. In this paper, we focus on semi-supervised learning. One important aspect of graph CNNs is the graph structure representation of data. In general, the data we provide to graph CNNs either has a known intrinsic graph structure, such as social networks, or we construct a human established graph for it, such as k-nearest neighbor graph with Gaussian kernel. However, it is difficult to evaluate whether the graphs obtained from domain knowledge (e.g., social network) or established by human are optimal for semi-supervised learning in graph C-NNs. Henaff et al. [7] propose to learn a supervised graph with a fully connected network. However, the learned graph is obtained from a separate network which is also not guaranteed to best serve the graph CNNs. Li et al. [19] propose optimal graph CNNs, in which the graph is learned adaptively by using a distance metric learning. However, it use an approximate algorithm to estimate graph Laplacian which may lead to weak local optimal solution.\n\nIn this paper, we propose a novel Graph Learning-Convolutional Network (GLCN) for semi-supervised learning problem. The main idea of GLCN is to learn an optimal graph representation that best serves graph CNNs for semisupervised learning by integrating both graph learning and graph convolution simultaneously in a unified network architecture. The main advantages of the proposed GLCN for semi-supervised learning are summarized as follows. \u2022 In GLCN, both given labels and the estimated labels are incorporated and thus can provide useful 'weakly' supervised information to refine (or learn) the graph construction and to facilitate the graph convolution operation in graph CNN for unknown label estimation.\n\n\u2022 GLCN can be trained via a single optimization manner, which can thus be implemented simply.\n\nTo the best of our knowledge, this is the first attempt to build a unified graph learning-convolutional network architecture for semi-supervised learning. Experimental results demonstrate that GLCN outperforms state-of-the-art graph CNNs on semi-supervised learning tasks.\n\n\n"}, {"paperid": "paper1", "title": "Joint Learning of Graph Representation and Node Features in Graph Convolutional Neural Networks", "abstract": "Graph Convolutional Neural Networks (GCNNs) extend classical CNNs to graph data domain, such as brain networks, social networks and 3D point clouds. It is critical to identify an appropriate graph for the subsequent graph convolution. Existing methods manually construct or learn one fixed graph for all the layers of a GCNN. In order to adapt to the underlying structure of node features in different layers, we propose dynamic learning of graphs and node features jointly in GCNNs. In particular, we cast the graph optimization problem as distance metric learning to capture pairwise similarities of features in each layer. We deploy the Mahalanobis distance metric and further decompose the metric matrix into a low-dimensional matrix, which converts graph learning to the optimization of a low-dimensional matrix for efficient implementation. Extensive experiments on point clouds and citation network datasets demonstrate the superiority of the proposed method in terms of both accuracies and robustness.", "introduction": "\n\nGraph Convolutional Neural Networks (GCNNs) have been receiving increasing attention as a powerful tool for irregularly structured data on graphs, such as citation networks, social networks and 3D point clouds.The construction of an appropriate graph topology plays a critical role in GCNNs for efficient feature learning.In settings where the graph is inaccurate or even not readily available, it is necessary to infer or learn a graph topology from data before it is used for guiding graph convolution in GCNNs.\n\nMost of the previous studies construct underlying graphs from data empirically, such as k-Nearest-Neighbor (k-NN) graphs [1,2], which may lead to sub-optimal solutions.Few methods exploit graph learning for optimized representation [3,4,5,6], which learns a fixed and shared graph for all instances, or an individual graph for each instance, or a combination of shared and individual graphs.However, only one fixed graph is learned and applied to all layers of the entire network, which may not well capture the underlying structure of node features in different layers dynamically.\n\nExtending on these previous studies, we propose a Joint Learning Graph Convolutional Network (JLGCN), which exploits dynamic learning of graphs and node features jointly in GCNNs.In particular, we optimize an underlying graph kernel from data features via distance metric learning that characterizes pairwise similarities of data.We deploy the Mahalanobis distance [7], which takes into account data correlations for intrinsic representation.Given a Kdimensional feature vector f i per node i, f i \u2208 R K , the Mahalanobis distance between the features f i and f j of nodes i and j is defined as: d M (f i , f j ) = (f i \u2212 f j ) M(f i \u2212 f j ), where M \u2208 R K\u00d7K is the Mahalanobis distance metric matrix which reflects feature correlations.Hence, we convert the problem of graph learning to the optimization of M. As M is positive semi-definite (PSD), it is often nontrivial to solve efficiently.Instead, we decompose it as M = RR and learn R for ease of optimization, where R \u2208 R K\u00d7S has a lower dimension S << K to reduce number of parameters for efficient implementation.Given features f , we seek to minimize the Graph Laplacian Regularizer (GLR) [8] f L(R)f by optimizing R, which measures the smoothness of features f with respect to the graph Laplacian L1 .This essentially enforces the graph encoded in L(R) to capture pairwise similarities of f .Hence, we formulate the joint learning of graphs L(R) and node features f as an optimization problem, which minimizes a weighted sum of the GLR and cross-entropy.We set this objective as the loss function of the proposed JLGCN to guide network model optimization, which employs a localized first-order approximation of spectral graph convolution as in [9].Further, the learned graph at the previous layer is added to that of the current layer for multi-level feature learning.The proposed JLGCN can be integrated into any GCNN architecture for applications such as node classification and graph classification.To validate the effectiveness of the proposed JLGCN, we apply it to semi-supervised learning for citation networks and 3D point cloud learning problems.Extensive experimental results demonstrate the superiority and robustness of JLGCN compared with state-of-the-art methods on four datasets even with a small model size.\n\nOur contributions can be summarized as follows:\n\n\u2022 We propose joint learning of underlying graphs and node features at each layer of a GCNN, which captures pairwise similarities of node features dynamically.\u2022 We cast the graph learning problem as distance metric learning with the Mahalanobis distance deployed.We further decompose the distance metric into a low-dimensional matrix for efficient implementation, which is optimized from both the GLR and cross entropy along with node features.\n\n\u2022 Extensive experiments on semi-supervised learning and point cloud classification demonstrate the superiority and robustness of our method.\n\n\n"}, {"paperid": "paper2", "title": "Dynamic Graph CNN for Learning on Point Clouds", "abstract": "Point clouds provide a flexible and scalable geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. Hence, the design of intelligent computational models that act directly on point clouds is critical, especially when efficiency considerations or noise preclude the possibility of expensive denoising and meshing procedures. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds including classification and segmentation. EdgeConv is differentiable and can be plugged into existing architectures. Compared to existing modules operating largely in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked or recurrently applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. Beyond proposing this module, we provide extensive evaluation and analysis revealing that EdgeConv captures and exploits fine-grained geometric properties of point clouds. The proposed approach achieves state-of-the-art performance on standard benchmarks including ModelNet40 and S3DIS.", "introduction": "\n\nPoint clouds, or scattered collections of points in 2D or 3D, are arguably the simplest shape representation; they also comprise the output of 3D sensing technology including LiDAR scanners and stereo reconstruction. With the advent of fast 3D point cloud acquisition, recent pipelines for graphics and vision often process point clouds directly, bypassing expensive mesh reconstruction or denoising due to efficiency considerations or instability of these techniques in the presence of noise. A few of the many recent applications of point cloud processing and analysis include indoor navigation [57], self-driving vehicles [33], robotics [40], and shape synthesis and modeling [14]. Modern applications demand high-level processing of point clouds. Rather than identifying salient geometric features like corners and edges, recent algorithms search for semantic cues and affordances. These features do not fit cleanly into the frameworks of computational or differential geometry and typically require learning-based approaches that derive relevant information through statistical analysis of labeled or unlabeled datasets.\n\nIn this paper, we primarily consider point cloud classification and segmentation, two model tasks in the point cloud processing world. Traditional methods for solving these problems employ handcrafted features to capture geometric properties of point clouds [26,38,39]. More recently, the success of deep neural networks for image processing has motivated a data-driven approach to learning features on point clouds. Deep point cloud processing and analysis methods are developing rapidly and outperform traditional approaches in various tasks [10].\n\nAdaptation of deep learning to point cloud data, however, is far from straightforward. Most critically, standard deep neural network models take as input data with regular structure, while point clouds are fundamentally irregular: Point positions are continuously distributed in the space, and any permutation of their ordering does not change the Figure 1. Point cloud segmentation using the proposed neural network. Bottom: schematic neural network architecture. Top: Structure of the feature spaces produced at different layers of the network, visualized as the distance from the red point to all the rest of the points (shown left-to-right are the input and layers 1-3; rightmost figure shows the resulting segmentation). Observe how the feature space structure in deeper layers captures semantically similar structures such as wings, fuselage, or turbines, despite a large distance between them in the original input space. spatial distribution. One common approach to process point cloud data using deep learning models is to first convert raw point cloud data into a volumetric representation, namely a 3D grid [30,54]. This approach, however, usually introduces quantization artifacts and excessive memory usage, making it difficult to go to capture high-resolution or finegrained features.\n\nState-of-the-art deep neural networks are designed specifically to handle the irregularity of point clouds, directly manipulating raw point cloud data rather than passing to an intermediate regular representation. This approach was pioneered by PointNet [34], which achieves permutation invariance of points by operating on each point independently and subsequently applying a symmetric function to accumulate features. Various extensions of Point-Net consider neighborhoods of points rather than acting on each independently [36,43]; these allow the network to exploit local features, improving upon performance of the basic model. These techniques largely treat points independently at local scale to maintain permutation invariance. This independence, however, neglects the geometric relationships among points, presenting a fundamental limitation that leads to local features missing.\n\nTo address these drawbacks, we propose a novel simple operation, called EdgeConv, which captures local geometric structure while maintaining permutation invariance. Instead of generating points' features directly from their embeddings, EdgeConv generates edge features that describe the relationships between a point and its neighbors. EdgeConv is designed to be invariant to the ordering of neighbors, and thus permutation invariant.\n\nEdgeConv is easy to implement and integrate into existing deep learning models to improve their performance. In our experiments, we integrate EdgeConv into the basic version of PointNet without using any feature transformation. We show performance improvement by a large margin; the resulting network achieves state-of-the-art performance on several datasets, most notably ModelNet40 and S3DIS for classification and segmentation.\n\nKey Contributions. We summarize the key contributions of our work as follows:\n\n\u2022 We present a novel operation for point clouds, Edge-Conv, to better capture local geometric features of point clouds while still maintaining permutation invariance.\n\n\u2022 We show the model can learn to semantically group points by dynamically updating the graph.\n\n\u2022 We demonstrate that EdgeConv can be integrated into multiple existing pipelines for point cloud processing.\n\n\u2022 We present extensive analysis and testing of EdgeConv and show that it achieves state-of-the-art performance on benchmark datasets. Left: An example of computing an edge feature, eij, from a point pair, xi and xj. In this example, h \u0398 () is instantiated using a fully connected layer, and the learnable parameters are its associated weights and bias. Right: Visualize the EdgeConv operation. The output of EdgeConv is calculated by aggregating the edge features associated with all the edges emanating from each connected vertex.\n\n\n"}, {"paperid": "paper3", "title": "Learning Discrete Structures for Graph Neural Networks", "abstract": "Graph neural networks (GNNs) are a popular class of machine learning models whose major advantage is their ability to incorporate a sparse and discrete dependency structure between data points. Unfortunately, GNNs can only be used when such a graph-structure is available. In practice, however, real-world graphs are often noisy and incomplete or might not be available at all. With this work, we propose to jointly learn the graph structure and the parameters of graph convolutional networks (GCNs) by approximately solving a bilevel program that learns a discrete probability distribution on the edges of the graph. This allows one to apply GCNs not only in scenarios where the given graph is incomplete or corrupted but also in those where a graph is not available. We conduct a series of experiments that analyze the behavior of the proposed method and demonstrate that it outperforms related methods by a significant margin.", "introduction": "\n\nRelational learning is concerned with methods that cannot only leverage the attributes of data points but also their relationships. Diagnosing a patient, for example, not only depends on the patient's vitals and demographic information but also on the same information about their relatives, the information about the hospitals they have visited, and so on. Relational learning, therefore, does not make the assumption of independence between data points but models their dependency explicitly. Graphs are a natural way to represent relational information and there is a large number of machine learning algorithms leveraging graph structure. Graph neural networks (GNNs) (Scarselli et al., 2009) are one such class of algorithms that are able to incorporate sparse and discrete dependency structures between data points.\n\nWhile a graph structure is available in some domains, in others it has to be inferred or constructed. A possible approach is to first create a k-nearest neighbor (kNN) graph based on some measure of similarity between data points. This is a common strategy used by several learning methods such as LLE (Roweis & Saul, 2000) and Isomap (Tenenbaum et al., 2000). A major shortcoming of this approach, however, is that the efficacy of the resulting models hinges on the choice of k and, more importantly, on the choice of a suitable similarity measure over the input features. In any case, the graph creation and parameter learning steps are independent and require heuristics and trial and error. Alternatively, one could simply use a kernel matrix to model the similarity of examples implicitly at the cost, however, of introducing a dense dependency structure which may be problematic from a computational point of view.\n\nWith this paper, we follow a different route with the aim of learning discrete and sparse dependencies between data points while simultaneously training the parameters of graph convolutional networks (GCN), a class of GNNs. Intuitively, GCNs learn node representations by passing and aggregating messages between neighboring nodes (Kipf & Welling, 2017;Monti et al., 2017;Gilmer et al., 2017;Hamilton et al., 2017;Duran & Niepert, 2017;Velickovic et al., 2018). We propose to learn a generative probabilistic model for graphs, samples from which are used both during training and at prediction time. Edges are modelled with random variables whose parameters are treated as hyperparameters in a bilevel learning framework (Franceschi et al., 2018). We iteratively sample the structure while minimizing an inner objective (a training error) and optimize the edge distribution parameters by minimizing an outer objective (a validation error).\n\nTo the best of our knowledge, this is the first method that simultaneously learns the graph and the parameters of a GNN for semi-supervised classification. Moreover, and this might be of independent interest, we adapt gradient-based hyperparameter optimization to work for a class of discrete hyperparameters (edges, in this work). The proposed approach makes GNNs applicable to problems where the graph is incomplete or entirely missing. We conduct a series of experiments and show that the proposed method is competitive with and often outperforms existing approaches. We also verify that the resulting graph generative models have meaningful edge probabilities.\n\n\n"}, {"paperid": "paper4", "title": "Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings", "abstract": "In this paper, we propose an end-to-end graph learning framework, namely Iterative Deep Graph Learning (IDGL), for jointly and iteratively learning graph structure and graph embedding. The key rationale of IDGL is to learn a better graph structure based on better node embeddings, and vice versa (i.e., better node embeddings based on a better graph structure). Our iterative method dynamically stops when the learned graph approaches close enough to the graph optimized for the prediction task. In addition, we cast the graph learning problem as a similarity metric learning problem and leverage adaptive graph regularization for controlling the quality of the learned graph. Finally, combining the anchor-based approximation technique, we further propose a scalable version of IDGL, namely IDGL-ANCH, which significantly reduces the time and space complexity of IDGL without compromising the performance. Our extensive experiments on nine benchmarks show that our proposed IDGL models can consistently outperform or match state-of-the-art baselines. Furthermore, IDGL can be more robust to adversarial graphs and cope with both transductive and inductive learning.", "introduction": "\n\nRecent years have seen a significantly growing amount of interest in graph neural networks (GNNs), especially on efforts devoted to developing more effective GNNs for node classification [27,34,16,48], graph classification [55,40] and graph generation [44,35,56]. Despite GNNs' powerful ability in learning expressive node embeddings, unfortunately, they can only be used when graph-structured data is available. Many real-world applications naturally admit network-structured data (e.g., social networks). However, these intrinsic graph-structures are not always optimal for the downstream tasks. This is partially because the raw graphs were constructed from the original feature space, which may not reflect the \"true\" graph topology after feature extraction and transformation. Another potential reason is that real-world graphs are often noisy or even incomplete due to the inevitably error-prone data measurement or collection. Furthermore, many applications such as those in natural language processing [7,53] may only have sequential data or even just the original feature matrix, requiring additional graph construction from the original data matrix.\n\nTo address these limitations, we propose an end-to-end graph learning framework, namely Iterative Deep Graph Learning (IDGL), for jointly and iteratively learning the graph structure and the GNN parameters that are optimized towards the downstream prediction task. The key rationale of our IDGL framework is to learn a better graph structure based on better node embeddings, and at the same time, to learn better node embeddings based on a better graph structure. In particular, IDGL is a novel iterative method that aims to search for a hidden graph structure that augments the initial graph structure (if not available we use a kNN graph) with the goal of optimizing the graph for supervised prediction tasks. The iterative method adjusts when to stop in each mini-batch when the learned graph structure approaches close enough to the graph optimized for the prediction task.\n\nFurthermore, we present a graph learning neural network that uses multi-head self-attention with epsilon-neighborhood sparsification for constructing a graph. Moreover, unlike the work in [23] that directly optimizes an adjacency matrix without considering the downstream task, we learn a graph metric learning function by optimizing a joint loss combining both task-specific prediction loss and graph regularization loss. Finally, we further propose a scalable version of our IDGL framework, namely IDGL-ANCH, by combining the anchor-based approximation technique, which reduces the time and memory complexity from quadratic to linear with respect to the numbers of graph nodes.\n\nIn short, we summarize the main contributions as follows:\n\n\u2022 We propose a novel end-to-end graph learning framework (IDGL) for jointly and iteratively learning the graph structure and graph embedding. IDGL dynamically stops when the learned graph structure approaches the optimized graph (for prediction). To the best of our knowledge, we are the first to introduce the iterative learning for graph structure learning. \u2022 Combining the anchor-based approximation technique, we further propose a scalable version of IDGL, namely IDGL-ANCH, which achieves linear complexity in both computational time and memory consumption with respect to the number of graph nodes. \u2022 Experimental results show that our models consistently outperform or match state-of-the-art baselines on various downstream tasks. More importantly, IDGL can be more robust to adversarial graph examples and can cope with both transductive and inductive learning.\n\n\n"}, {"paperid": "paper5", "title": "Graph-Bert: Only Attention is Needed for Learning Graph Representations", "abstract": "The dominant graph neural networks (GNNs) over-rely on the graph links, several serious performance problems with which have been witnessed already, e.g., suspended animation problem and over-smoothing problem. What's more, the inherently inter-connected nature precludes parallelization within the graph, which becomes critical for large-sized graph, as memory constraints limit batching across the nodes. In this paper, we will introduce a new graph neural network, namely GRAPH-BERT (Graph based BERT), solely based on the attention mechanism without any graph convolution or aggregation operators. Instead of feeding GRAPH-BERT with the complete large input graph, we propose to train GRAPH-BERT with sampled linkless subgraphs within their local contexts. GRAPH-BERT can be learned effectively in a standalone mode. Meanwhile, a pre-trained GRAPH-BERT can also be transferred to other application tasks directly or with necessary fine-tuning if any supervised label information or certain application oriented objective is available. We have tested the effectiveness of GRAPH-BERT on several graph benchmark datasets. Based the pre-trained GRAPH-BERT with the node attribute reconstruction and structure recovery tasks, we further fine-tune GRAPH-BERT on node classification and graph clustering tasks specifically. The experimental results have demonstrated that GRAPH-BERT can out-perform the existing GNNs in both the learning effectiveness and efficiency.", "introduction": "\n\nGraph provides a unified representation for many interconnected data in the real-world, which can model both the diverse attribute information of the node entities and the extensive connections among these nodes. For instance, the human brain imaging data, online social media and bio-medical molecules can all be represented as graphs, i.e., the brain graph , social graph [Ugander et al., 2011] and molecular graph [Jin et al., 2018], respectively. Traditional machine learning models can hardly be applied to the graph data directly, which usually take the feature vectors as the inputs. Viewed in such a perspective, learning the representations of the graph structured data is an important research task.\n\nIn recent years, great efforts have been devoted to designing new graph neural networks (GNNs) for effective graph representation learning. Besides the network embedding models, e.g., node2vec [Grover and Leskovec, 2016] and deepwalk [Perozzi et al., 2014a], the recent graph neural networks, e.g., GCN [Kipf and Welling, 2016], GAT [Veli\u010dkovi\u0107 et al., 2018] and LOOPYNET [Zhang, 2018], are also becoming much more important, which can further refine the learned representations for specific application tasks. Meanwhile, most of these existing graph representation learning models are still based on the graph structures, i.e., the links among the nodes. Via necessary neighborhood information aggregation or convolutional operators along the links, nodes' representations learned by such approaches can preserve the graph structure information.\n\nHowever, several serious learning performance problem, e.g., suspended animation problem  and over-smoothing problem [Li et al., 2018], with the existing GNN models have also been witnessed in recent years. According to , for the GNNs based on the approximated graph convolutional operators [Hammond et al., 2011], as the model architecture goes deeper and reaches certain limit, the model will not respond to the training data and suffers from the suspended animation problem. Meanwhile, the node representations obtained by such deep models tend to be over-smoothed and also become indistinguishable [Li et al., 2018]. Both of these two problems greatly hinder the applications of GNNs for deep graph representation learning tasks. What's more, the inherently interconnected nature precludes parallelization within the graph, which becomes critical for large-sized graph input, as memory constraints limit batching across the nodes.\n\nTo address the above problems, in this paper, we will propose a new graph neural network model, namely GRAPH-BERT (Graph based BERT). Inspired by , model GRAPH-BERT will be trained with sampled nodes together with their context (which are called linkless subgraphs in this paper) from the input large-sized graph data. Distinct from the existing GNN models, in the representation learning process, GRAPH-BERT utilizes no links in such sampled batches, which will be purely based on the attention mechanisms instead [Vaswani et al., 2017;Devlin et al., 2018]. Therefore, GRAPH-BERT can get rid of the aforementioned learning effectiveness and efficiency problems with existing GNN models promisingly.\n\nWhat's more, compared with computer vision [He et al., 2018] and natural language processing [Devlin et al., 2018], graph neural network pre-training and fine-tuning are still not common practice by this context so far. The main obstacles that prevent such operations can be due to the diverse input graph structures and the extensive connections among the nodes. Also the different learning task objectives also prevents the transfer of GNNs across different tasks. Since GRAPH-BERT doesn't really rely on the graph links at all, in this paper, we will investigate the transfer of pre-trained GRAPH-BERT on new learning tasks and other sequential models (with necessary fine-tuning), which will also help construct the functional pipeline of models in graph learning.\n\nWe summarize our contributions of this paper as follows:\n\n\u2022 New GNN Model: In this paper, we introduce a new GNN model GRAPH-BERT for graph data representation learning. GRAPH-BERT doesn't rely on the graph links for representation learning and can effectively address the suspended animation problems aforementioned. Also GRAPH-BERT is trainable with sampled linkless subgraphs (i.e., target node with context), which is more efficient than existing GNNs constructed for the complete input graph. To be more precise, the training cost of GRAPH-BERT is only decided by (1) training instance number, and (2) sampled subgraph size, which is uncorrelated with the input graph size at all.\n\n\u2022 Unsupervised Pre-Training: Given the input unlabeled graph, we will pre-train GRAPH-BERT based on to two common tasks in graph studies, i.e., node attribute reconstruction and graph structure recovery. Node attribute recovery ensures the learned node representations can capture the input attribute information; whereas graph structure recovery can further ensure GRAPH-BERT learned with linkless subgraphs can still maintain both the graph local and global structure properties.\n\n\u2022 Fine-Tuning and Transfer: Depending on the specific application task objectives, the GRAPH-BERT model can be further fine-tuned to adapt the learned representations to specific application requirements, e.g., node classification and graph clustering. Meanwhile, the pretrained GRAPH-BERT can also be transferred and applied to other sequential models, which allows the construction of functional pipelines for graph learning.\n\nThe remaining parts of this paper are organized as follows. We will introduce the related work in Section 2. Detailed information about the GRAPH-BERT model will be introduced in Section 3, whereas the pre-training and finetuning of GRAPH-BERT will be introduced in Section 4 in detail. The effectiveness of GRAPH-BERT will be tested in Section 5. Finally, we will conclude this paper in Section 6.\n\n\n"}, {"paperid": "paper6", "title": "Graph-Revised Convolutional Network", "abstract": "Graph Convolutional Networks (GCNs) have received increasing attention in the machine learning community for effectively leveraging both the content features of nodes and the linkage patterns across graphs in various applications. As real-world graphs are often incomplete and noisy, treating them as ground-truth information, which is a common practice in most GCNs, unavoidably leads to sub-optimal solutions. Existing efforts for addressing this problem either involve an over-parameterized model which is difficult to scale, or simply re-weight observed edges without dealing with the missing-edge issue. This paper proposes a novel framework called Graph-Revised Convolutional Network (GRCN), which avoids both extremes. Specifically, a GCN-based graph revision module is introduced for predicting missing edges and revising edge weights w.r.t. downstream tasks via joint optimization. A theoretical analysis reveals the connection between GRCN and previous work on multigraph belief propagation. Experiments on six benchmark datasets show that GRCN consistently outperforms strong baseline methods by a large margin, especially when the original graphs are severely incomplete or the labeled instances for model training are highly sparse.", "introduction": "\n\nGraph Convolutional Networks (GCNs) have received increasing attention in recent years as they are highly effective in graph-based node feature induction and belief propagation, and widely applicable to many real-world problems, including computer vision (Wang et al. 2018;Landrieu and Simonovsky 2018), natural language processing (Kipf and Welling 2016;Marcheggiani and Titov 2017), recommender systems (Monti et al. 2017;Ying et al. 2018), epidemiological forecasting (Wu et al. 2018), and more.\n\nHowever, the power of GCNs has not been fully exploited as most of the models assume that the given graph perfectly depicts the ground-truth of the relationship between nodes. Such assumptions are bound to yield sub-optimal results as real-world graphs are usually highly noisy, incomplete (with many missing edges), and not necessarily ideal for different downstream tasks. Ignoring these issues is a fundamental weakness of many existing GCN methods.\n\nRecent methods that attempt to modify the original graph can be split into two major streams: 1) Edge reweighting: GAT (Veli\u010dkovi\u0107 et al. 2017) and GLCN (Jiang et al. 2019) use attention mechanism or feature similarity to reweight the existing edges of the given graph. Since the topological structure of the graph is not changed, the model is prone to be affected by noisy data when edges are sparse. 2) Full graph parameterization: LDS (Franceschi et al. 2019), on the other hand, allows every possible node pairs in a graph to be parameterized. Although this design is more flexible, the memory cost is intractable for large datasets, since the number of parameters increases quadratically with the number of nodes. Therefore, finding a balance between model expressiveness and memory consumption remains an open challenge.\n\nTo enable flexible edge editing while maintaining scalability, we develop a GCN-based graph revision module that performs edge addition and edge reweighting. In each iteration, we calculate an adjacency matrix via GCN-based node embeddings, and select the edges with high confidence to be added. Our method permits a gradient-based training of an end-to-end neural model that can predict unseen edges. Our theoretical analysis demonstrates the effectiveness of our model from the perspective of multigraph (Balakrishnan 1997), which allows more than one edges from different sources between a pair of vertices. To the best of our knowledge, we are the first to reveal the connection between graph convolutional networks and multigraph propagation. Our contributions can be summarized as follows:\n\n\u2022 We introduce a novel structure that simultaneously learns both graph revision and node classification through different GCN modules.\n\n\u2022 Through theoretical analysis, we show our model's advantages in the view of multigraph propagation.\n\n\u2022 Comprehensive experiments on six benchmark datasets from different domains show that our proposed model achieves the best or highly competitive results, especially under the scenarios of highly incomplete graphs or sparse training labels. arXiv:1911.07123v1 [cs.\n\nLG] 17 Nov 2019\n\n\n"}, {"paperid": "paper7", "title": "SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks", "abstract": "Graph neural networks (GNNs) work well when the graph structure is provided. However, this structure may not always be available in real-world applications. One solution to this problem is to infer a task-specific latent structure and then apply a GNN to the inferred graph. Unfortunately, the space of possible graph structures grows super-exponentially with the number of nodes and so the task-specific supervision may be insufficient for learning both the structure and the GNN parameters. In this work, we propose the Simultaneous Learning of Adjacency and GNN Parameters with Self-supervision, or SLAPS, a method that provides more supervision for inferring a graph structure through self-supervision. A comprehensive experimental study demonstrates that SLAPS scales to large graphs with hundreds of thousands of nodes and outperforms several models that have been proposed to learn a task-specific graph structure on established benchmarks.", "introduction": "\n\nGraph representation learning has grown rapidly and found applications in domains where a natural graph of the data points is available [4,26]. Graph neural networks (GNNs) [45] have been a key component to the success of the research in this area. Specifically, GNNs have shown promising results for semi-supervised classification when the available graph structure exhibits a high degree of homophily (i.e. connected nodes often belong to the same class) [63].\n\nWe study the applicability of GNNs to (semi-supervised) classification problems where a graph structure is not readily available. The existing approaches for this problem either fix a similarity graph between the nodes or learn the GNN parameters and a graph structure simultaneously (see Related Work). In both cases, one main goal is to construct or learn a graph structure with a high degree of homophily with respect to the labels to aid the GNN classification. The latter approach is sometimes called latent graph learning and often results in higher predictive performance compared to the former approach (see, e.g., [13]).\n\nWe identify a supervision starvation problem in latent graph learning approaches in which the edges between pairs of nodes that are far from labeled nodes receive insufficient supervision; this results in learning poor structures away from labeled nodes and hence poor generalization. We propose a solution for this problem by adopting a multi-task learning framework in which we supplement the classification task with a self-supervised task. The self-supervised task is based on the hypothesis that a graph structure that is suitable for predicting the node features is also suitable for predicting the node labels. It works by masking some input features (or adding noise to them) and training a separate GNN aiming at updating the adjacency matrix in such a way that it can recover the masked (or noisy) features. The task is generic and can be combined with several existing latent graph learning approaches.\n\nWe develop a latent graph learning model, dubbed SLAPS, that adopts the proposed self-supervised task. We provide a comprehensive experimental study on nine datasets (thirteen variations) of various sizes and from various domains and perform thorough analyses to show the merit of SLAPS.\n\nOur main contributions include: 1) identifying a supervision starvation problem for latent graph learning, 2) proposing a solution for the identified problem through self-supervision, 3) developing SLAPS, a latent graph learning model that adopts the self-supervised solution, 4) providing comprehensive experimental results showing SLAPS substantially outperforms existing latent graph learning baselines from various categories on various benchmarks, and 5) providing an implementation for latent graph learning that scales to graphs with hundreds of thousands of nodes.\n\n\n"}, {"paperid": "paper8", "title": "Towards Unsupervised Deep Graph Structure Learning", "abstract": "In recent years, graph neural networks (GNNs) have emerged as a successful tool in a variety of graph-related applications. However, the performance of GNNs can be deteriorated when noisy connections occur in the original graph structures; besides, the dependence on explicit structures prevents GNNs from being applied to general unstructured scenarios. To address these issues, recently emerged deep graph structure learning (GSL) methods propose to jointly optimize the graph structure along with GNN under the supervision of a node classification task. Nonetheless, these methods focus on a supervised learning scenario, which leads to several problems, i.e., the reliance on labels, the bias of edge distribution, and the limitation on application tasks. In this paper, we propose a more practical GSL paradigm, unsupervised graph structure learning, where the learned graph topology is optimized by data itself without any external guidance (i.e., labels). To solve the unsupervised GSL problem, we propose a novel StrUcture Bootstrapping contrastive LearnIng fraMEwork (SUBLIME for abbreviation) with the aid of self-supervised contrastive learning. Specifically, we generate a learning target from the original data as an\"anchor graph\", and use a contrastive loss to maximize the agreement between the anchor graph and the learned graph. To provide persistent guidance, we design a novel bootstrapping mechanism that upgrades the anchor graph with learned structures during model learning. We also design a series of graph learners and post-processing schemes to model the structures to learn. Extensive experiments on eight benchmark datasets demonstrate the significant effectiveness of our proposed SUBLIME and high quality of the optimized graphs.", "introduction": "\n\nRecent years have witnessed the prosperous development of graphbased applications in numerous domains, such as chemistry, bioinformatics and cybersecurity. As a powerful deep learning tool to model graph-structured data, graph neural networks (GNNs) have drawn increasing attention and achieved state-of-the-art performance in various graph analytical tasks, including node classification [22,40], link prediction [21,32], and node clustering [42,55]. GNNs usually follow a message-passing scheme, where node representations are learned by aggregating information from the neighbors on an observed topology (i.e., the original graph structure).\n\nMost GNNs rely on a fundamental assumption that the original structure is credible enough to be viewed as ground-truth information for model training. Such assumption, unfortunately, is usually violated in real-world scenarios, since graph structures are usually extracted from complex interaction systems which inevitably contain uncertain, redundant, wrong and missing connections [45]. Such noisy information in original topology can seriously damage the performance of GNNs. Besides, the reliance on explicit structures hinders GNNs' broad applicability. If GNNs are capable of uncovering the implicit relations between samples, e.g., two images containing the same object, they can be applied to more general domains like vision and language.\n\nTo tackle the aforementioned problems, deep graph structure learning (GSL) is a promising solution that constructs and improves the graph topology with GNNs [7,12,20,58]. Concretely, these methods parameterize the adjacency matrix with a probabilistic model [12,45], full parameterization [20] or metric learning model [7,11,53], and jointly optimize the parameters of the adjacency matrix and GNNs by solving a downstream task (i.e., node classification) [58]. However, existing methods learn graph structures in a supervised scenario, which brings the following issues: (1) The reliance on label information. In supervised GSL methods, humanannotated labels play an important role in providing supervision signal for structure improvement. Such reliance on labels limits the application of supervised GSL on more general cases where annotation is unavailable. (2) The bias of learned edge distribution. Node classification usually follows a semi-supervised setting, where only a small fraction of nodes (e.g., 140/2708 in Cora dataset) are under the supervision of labels. As a result, the connections among these nodes and their neighbors would receive more guidance in arXiv:2201.06367v1 [cs.LG] 17 Jan 2022  structure learning, while the relations between nodes far away from them are rarely discovered by GSL [11]. Such imbalance leads to the bias of edge distribution, affecting the quality of the learned structures.\n\n(3) The limitation on downstream tasks. In existing methods, the structure is specifically learned for node classification, so it may contain more task-specific information rather than general knowledge. Consequently, the refined topology may not benefit other downstream tasks like link prediction or node clustering, indicating the poor generalization ability of the learned structures.\n\nTo address these issues, in this paper, we investigate a novel unsupervised learning paradigm for GSL, namely unsupervised graph structure learning. As compared in Fig. 1, in our learning paradigm, structures are learned by data itself without any external guidance (i.e., labels), and the acquired universal, edge-unbiased topology can be freely applied to various downstream tasks. In this case, one natural question can be raised: how to provide sufficient supervision signal for unsupervised GSL? To answer this, we propose a novel StrUcture Bootstrapping contrastive LearnIng fraMEwork (SUBLIME for abbreviation) to learn graph structures with the aid of self-supervised contrastive learning [25]. Concretely, our method constructs an \"anchor graph\" from the original data to guide structure optimization, with a contrastive loss to maximize the mutual information (MI) between anchor graph and the learned structure. Through maximizing their consistency, informative hidden connections can be discovered, which well respects the node proximity conveyed by the original features and structures. Meanwhile, as we optimize the contrastive loss on the representations of every node, all potential edge candidates will receive the essential supervision, which promotes a balanced edge distribution in the inferred topology. Furthermore, we design a bootstrapping mechanism to update anchor graph with the learned edges, which provides a self-enhanced supervision signal for GSL. Besides, we carefully design multiple graph learners and post-processing schemes to model graph topology for diverse data. In summary, our core contributions are three-fold:\n\n\u2022 Problem. We propose a novel unsupervised learning paradigm for graph structure learning, which is more practical and challenging than the existing supervised counterpart. To the best of our knowledge, this is the first attempt to learn graph structures with GNNs in an unsupervised setting. \u2022 Algorithm. We propose a novel unsupervised GSL method SUBLIME, which guides structure optimization by maximizing the agreement between the learned structure and a crafted self-enhanced learning target with contrastive learning.\n\n\u2022 Evaluations. We perform extensive experiments to corroborate the effectiveness and analyze the properties of SUBLIME via thorough comparisons with state-of-the-art methods on eight benchmark datasets.\n\n\n"}, {"paperid": "paper9", "title": "Graph Structure Learning with Variational Information Bottleneck", "abstract": "Graph Neural Networks (GNNs) have shown promising results on a broad spectrum of applications. Most empirical studies of GNNs directly take the observed graph as input, assuming the observed structure perfectly depicts the accurate and complete relations between nodes. However, graphs in the real world are inevitably noisy or incomplete, which could even exacerbate the quality of graph representations. In this work, we propose a novel Variational Information Bottleneck guided Graph Structure Learning framework, namely VIB-GSL, in the perspective of information theory. VIB-GSL advances the Information Bottleneck (IB) principle for graph structure learning, providing a more elegant and universal framework for mining underlying task-relevant relations. VIB-GSL learns an informative and compressive graph structure to distill the actionable information for specific downstream tasks. VIB-GSL deduces a variational approximation for irregular graph data to form a tractable IB objective function, which facilitates training stability. Extensive experimental results demonstrate that the superior effectiveness and robustness of VIB-GSL.", "introduction": "\n\nRecent years have seen a significant growing amount of interest in graph representation learning (Zhang et al. 2018;Tong et al. 2021), especially in efforts devoted to developing more effective graph neural networks (GNNs) (Zhou et al. 2020). Despite GNNs' powerful ability in learning graph representations, most of them directly take the observed graph as input, assuming the observed structure perfectly depicts the accurate and complete relations between nodes. However, these raw graphs are naturally admitted from network-structure data (e.g., social network) or constructed from the original feature space by some pre-defined rules, which are usually independent of the downstream tasks and lead to the gap between the raw graph and the optimal graph for specific tasks. Moreover, most of graphs in the real-word are noisy or incomplete due to the error-prone data collection (Chen, Wu, and Zaki 2020), which could even exacerbate the quality of representations produced by GNNs (Z\u00fcgner, Akbarnejad, and G\u00fcnnemann 2018;Sun et al. 2018). It's also found that the properties of a graph Copyright \u00a9 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. are mainly determined by some critical structures rather than the whole graph (Sun et al. 2021;Peng et al. 2021). Furthermore, many graph enhanced applications (e.g., text classification  and vision navigation (Gao et al. 2021)) may only have data without graph-structure and require additional graph construction to perform representation learning. The above issues pose a great challenge for applying GNNs to real-world applications, especially in some risk-critical scenarios. Therefore, learning a task-relevant graph structure is a fundamental problem for graph representation learning.\n\nTo adaptively learn graph structures for GNNs, many graph structure learning methods (Zhu et al. 2021;Franceschi et al. 2019;Chen, Wu, and Zaki 2020) are proposed, most of which optimize the adjacency matrix along with the GNN parameters toward downstream tasks with assumptions (e.g., community) or certain constraints (e.g., sparsity, low-rank, and smoothness) on the graphs. However, these assumptions or explicit certain constraints may not be applicable to all datasets and tasks. There is still a lack of a general framework that can mine underlying relations from the essence of representation learning.\n\nRecalling the above problems, the key of structure learning problem is learning the underlying relations invariant to task-irrelevant information. Information Bottleneck (IB) principle (Tishby, Pereira, and Bialek 2000) provides a framework for constraining such task-irrelevant information retained at the output by trading off between prediction and compression. Specifically, the IB principle seeks for a representation Z that is maximally informative about target Y (i.e., maximize mutual information I(Y ; Z)) while being minimally informative about input data X (i.e., minimize mutual information I(X; Z)). Based on the IB principle, the learned representation is naturally more robust to data noise. IB has been applied to representation learning Jeon et al. 2021;Pan et al. 2020;Bao 2021;Dubois et al. 2020) and numerous deep learning tasks such as model ensemble (Sinha et al. 2020), fine-tuning (Mahabadi, Belinkov, and Henderson 2021), salient region discovery (Zhmoginov, Fischer, and Sandler 2020).\n\nIn this paper, we advance the IB principle for graph to solve the graph structure learning problem. We propose a novel Variational Information Bottleneck guided Graph Structure Learning framework, namely VIB-GSL. VIB-GSL employs the irrelevant feature masking and structure learning method to generate a new IB-Graph G IB as a bottleneck to distill the actionable information for the downstream task. VIB-GSL consists of three steps: (1) the IB-Graph generator module learns the IB-graph G IB by masking irrelevant node features and learning a new graph structure based on the masked feature; (2) the GNN module takes the IBgraph G IB as input and learns the distribution of graph representations; (3) the graph representation is sampled from the learned distribution with a reparameterization trick and then used for classification. The overall framework can be trained efficiently with the supervised classification loss and the distribution KL-divergence loss for the IB objective. The main contributions are summarized as follows:\n\n\u2022 VIB-GSL advances the Information Bottleneck principle for graph structure learning, providing an elegant and universal framework in the perspective of information theory. \u2022 VIB-GSL is model-agnostic and has a tractable variational optimization upper bound that is easy and stable to optimize. It is sufficient to plug existing GNNs into the VIB-GSL framework to enhance their performances. \u2022 Extensive experiment results in graph classification and graph denoising demonstrate that the proposed VIB-GSL enjoys superior effectiveness and robustness compared to other strong baselines.\n\n2 Background and Problem Formulation\n\n\n"}]