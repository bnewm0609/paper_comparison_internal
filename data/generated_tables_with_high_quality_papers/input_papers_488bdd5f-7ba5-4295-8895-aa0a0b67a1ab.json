[{"paperid": "paper0", "title": "Early-warning signals for critical transitions", "abstract": "Complex dynamical systems, ranging from ecosystems to financial markets and the climate, can have tipping points at which a sudden shift to a contrasting dynamical regime may occur. Although predicting such critical points before they are reached is extremely difficult, work in different scientific fields is now suggesting the existence of generic early-warning signals that may indicate for a wide class of systems if a critical threshold is approaching.", "introduction": "None"}, {"paperid": "paper1", "title": "Deep learning for early warning signals of tipping points", "abstract": "Significance Early warning signals (EWS) of tipping points are vital to anticipate system collapse or other sudden shifts. However, existing generic early warning indicators designed to work across all systems do not provide information on the state that lies beyond the tipping point. Our results show how deep learning algorithms (artificial intelligence) can provide EWS of tipping points in real-world systems. The algorithm predicts certain qualitative aspects of the new state, and is also more sensitive and generates fewer false positives than generic indicators. We use theory about system behavior near tipping points so that the algorithm does not require data from the study system but instead learns from a universe of possible models.", "introduction": "also their weakness, since these indicators do not tell us which type of bifurcation to expect (16).\n\nThe dominant eigenvalue is derived from a first-order approximation to dynamics near the equilibrium. Higher-order approximations can distinguish between different types of bifurcations. But they are not often used to develop early warning indicators because 1) the first-order approximation dominates dynamics sufficiently close to the equilibrium, causing critical slowing down to generate the strongest signal, and 2) the first-order approximation is more tractable to mathematical analysis of stochastic systems than the higher-order approximations (20). However, as a system gets closer to a bifurcation, it can drift farther from equilibrium due to critical slowing down. As a consequence, the higher-order terms become significant and may be large enough to provide clues about the type of transition that will occur. Statistical measures such as skew and kurtosis reflect the influence of these highest-order terms, for instance (20)(21)(22). Higher-order terms could be associated with features in time series data that are subtle but detectable, if we knew what to look for. Knowing qualitative information about the tipping point (such as whether it will be sudden or gradual) and the state that lies beyond it (such as whether it will oscillate or be stable) based on predicting the bifurcation type could be valuable in a range of applications."}, {"paperid": "paper2", "title": "Using Machine Learning to Anticipate Tipping Points and Extrapolate to Post-Tipping Dynamics of Non-Stationary Dynamical Systems", "abstract": "In this paper we consider the machine learning (ML) task of predicting tipping point transitions and long-term post-tipping-point behavior associated with the time evolution of an unknown (or partially unknown), non-stationary, potentially noisy and chaotic, dynamical system. We focus on the particularly challenging situation where the past dynamical state time series that is available for ML training predominantly lies in a restricted region of the state space, while the behavior to be predicted evolves on a larger state space set not fully observed by the ML model during training. In this situation, it is required that the ML prediction system have the ability to extrapolate to different dynamics past that which is observed during training. We investigate the extent to which ML methods are capable of accomplishing useful results for this task, as well as conditions under which they fail. In general, we found that the ML methods were surprisingly effective even in situations that were extremely challenging, but do (as one would expect) fail when ``too much\"extrapolation is required. For the latter case, we investigate the effectiveness of combining the ML approach with conventional modeling based on scientific knowledge, thus forming a hybrid prediction system which we find can enable useful prediction even when its ML-based and knowledge-based components fail when acting alone. We also found that achieving useful results may require using very carefully selected ML hyperparameters and we propose a hyperparameter optimization strategy to address this problem. The main conclusion of this paper is that ML-based approaches are promising tools for predicting the behavior of non-stationary dynamical systems even in the case where the future evolution (perhaps due to the crossing of a tipping point) includes dynamics on a set outside of that explored by the training data.", "introduction": "\n\nPredicting the time evolution of a dynamical system is a problem at the heart of many fields. While some prediction problems focus on forecasting the evolution of the values of a set of system state observables over a timescale that is on the order of the characteristic time (\u03c4 s ) on which observables vary, in other situations one is concerned with predicting the statistical properties of observables over a timescale (\u03c4 ns ) that is much longer than the time over which the details of system state variation can be usefully forecasted (\u03c4 ns \u03c4 s ). Examples of the former include predicting daily rainfall, wind speed, and temperature (i.e., weather forecasting), while examples of the latter include predicting variations of average patterns associated with rainfall, wind and temperature over years.\n\n(Motivated by the terminology in atmospheric science, we use the term \"climate\" to refer to the long-term characteristics of typical orbits of any dynamical system.) Prediction is often particularly difficult since many systems of interest, such as the terrestrial climate system, can be highly complicated, and knowledge of some of their scientific principles, parameters, and boundary conditions may be incomplete, inaccurate, or unknown. In addition, such systems may have a wide range of spatial and temporal scales that cannot be resolved using conventional numerical methods. The long term statistics of the dynamics of such systems is often heuristically modeled using noisy, nonstationary dynamical systems which themselves may depend on a set of time-dependent parameters. It is well-known that for different fixed parameter settings, a noiseless stationary dynamical system (i.e., a system with no explicit time-dependence of the system itself) can, depending on its (timeindependent) parameters, exhibit a variety of behaviors ranging from periodic to chaotic. We refer to qualitative changes of the attractor orbits of stationary systems occurring with variation of (timeindependent) system parameters as bifurcations. In the case where the system is non-stationary, e.g., due to time-dependent parameters, the basic system dynamics may change with time. Moreover, if, for example, the time-dependent system temporally drifts through a critical parameter region, the state evolution of the non-stationary system can experience rapid change whereby the statistical behavior of its dynamics is qualitatively and quantitatively altered [1,2]. We refer to such changes in the dynamics of non-stationary systems as \"tipping points\".\n\nMachine learning has been widely applied to the problem of determining both the short-term future state evolution [3][4][5][6][7][8][9][10][11][12][13][14][15][16][17] and the long-term \"climate\" [18][19][20][21] of stationary dynamical systems. In this paper, we use the term \"climate\" to denote long-term statistical properties of the evolution of a dynamical system. For stationary systems with ergodic dynamics, this includes, for example, obtaining the distribution of states, Lyapunov exponents, temporal correlation functions, Fourier power spectra, etc. associated with typical long trajectories of the system. However, for nonstationary systems the estimation of local-in-time state distributions, Lyapunov exponents, Fourier power spectra, and temporal correlation functions can often be problematic. We note, however, that a more well-defined generalization of a time varying system state distribution for non-stationary systems is available through the concept of \"snapshot attractors\" (also called \"pullback attractors\"), and we shall make use of this. In particular, a snapshot attractor, at any given time t is obtained by considering an ensemble of states obtained from an ensemble of trajectories initiated from many randomly chosen initial conditions in the far past. See Refs. [22][23][24][25][26][27] for a more detailed discussion. While prediction of stationary systems by machine learning (ML) has received much recent attention, less progress has been made in applying ML to the problem of predicting the time evolution of nonstationary dynamical systems, particularly of their climate and of the tipping points they may experience. Refer to [12,[28][29][30] for recent works which apply machine learning to the problem of predicting the short-term state evolution of non-stationary dynamical systems and to [27,[31][32][33][34] for recent works which aim to address the problem of predicting changing statistical properties of non-stationary dynamical systems (including anticipating tipping points). In previous work [27] we demonstrated that ML provides a promising avenue for predicting the climate of a non-stationary dynamical system using the time series of its past states and knowledge of a non-stationarity-inducing system parameter time dependence. It was shown that a machine learning model can anticipate tipping points in a non-stationary dynamical system and, in some cases, predict post-tipping-point dynamics which are fundamentally different from those it was trained on.\n\nThe goal of this work is to further develop, devise, and test ML techniques for the prediction of non-stationary dynamical systems that undergo a tipping point transition. A main focus of our work is on situations where the observed pre-transition motion is constrained to a smaller restricted subset of the state space region than that on which the post-transition motion evolves.\n\nIn contrast, in previous work on predicting tipping points and the associated post-tipping-point dynamics [27,33,34] ML prediction was considered for cases in which the training data was obtained from orbits that typically explored large state space regions that included all or most of the state space visited by the predicted future orbits. Thus, in this prior work the ML predictor was directly aware of dynamical system information needed for the prediction of the future behavior, e.g., after a predicted tipping point. In some other previous works only the occurrence of a tipping point, but not the post-tipping-point behavior, was predicted. These latter works anticipate the occurrence of a tipping point based on observation of a pre-tipping-point orbit subject to dynamical noise, and use the fact that, as the tipping point is approached, the effect of the noise on the orbit increases. For example, in one work of this type [32] a deep learning technique was developed by training on a library of mathematical models to recognize dynamical response to noise that characterizes a system as it approaches a tipping point. Although quite useful, such techniques yield no information about the post-tipping-point dynamics of the system. In contrast to the above two different cases, in this paper we consider the situation where the ML predictor, although trained on a pre-tipping-point system trajectory which evolves on a smaller state space set contained within the larger set explored by the future post-tipping-point trajectory, is able to anticipate the tipping-point transition and extrapolate its learning from the neighborhood of the pre-tipping-point training data into the larger regions of the system state space not explored, or only sparsely explored, in the training data to predict the post-tipping-point dynamics.\n\nA further contribution of our paper relative to previous related papers using ML for prediction of non-stationary behavior [27,33,34] is that those previous works considered the case where the system non-stationarity was induced by time variation of a parameter of an otherwise unknown system, and this parameter time variation was assumed to be known and was used as an input to the ML prediction system. In this current paper, on the other hand, we consider the case where knowledge of the type described above may not be available.\n\nFurthermore, motivated by our finding that using the standard hyperparameter optimization validation scheme for this type of forecasting did not consistently yield useful results in our test cases, we accordingly introduce a new hyperparameter optimization strategy (which we use in the numerical experiments of this paper) for this purpose. We believe that this hyperparameter determination scheme may be generally beneficial for ML prediction of non-stationary systems.\n\nTipping point transitions between different dynamical states where the pre-transition state dynamics is constrained to a smaller set of the system state space, or to a different region of the system state space, than the post-transition orbits are observed in a wide array of natural systems [1,2]. Such transitions are commonly found in various terrestrial climate models [35][36][37], ecosystem models [38][39][40], epidemics [41,42], and physical and engineering applications (e.g., intermittency [43] and crisis [44] transitions in plasmas [45][46][47][48], lasers [49,50], electrical and power systems [51][52][53][54], thermoacoustic systems [55][56][57], hydrodynamical systems [58,59], and electrochemical systems [60]). Thus, developing methods to predict the climate evolution of non-stationary dynamical systems which may tip into a state characterized by motion of the system that may visit previously unex-plored, or only sparsely explored, regions of its state space is a problem of very general importance. We emphasize, however, that, as is the case in general for methods employing extrapolations, our method has limitations. In particular, extrapolations are more likely to fail as the \"amount\" of the attempted extrapolation from the known case increases. A case illustrating this point is given in Sec. 3.1 where, when considering a situation where the non-stationary drift of the system is too slow, predictive extrapolation of the system behavior fails, but is then found to succeed when dynamical noise is assumed to influence the system evolution. (Evidently, the beneficial role of the dynamical noise in this case is to increase the state space set that is sampled by the training data.) A related example is given in Sec. 3.4 where we begin by reporting a failed attempt to extrapolate and predict behavior through a tipping-point associated with a subcritical (hysteretic) Hopf bifurcation using a purely data-driven ML model. In order to enable prediction in such a case, we then consider a prediction system scheme in which an ML model is combined with a knowledge-based model component. Although the knowledge-based component in the example considered is so inaccurate that it cannot make useful predictions on its own, we show that using it in a combined ML-based/knowledge-based hybrid prediction system enables good predictions of a tipping point transition as well as of the post-tipping-point behavior. Based on the discussion of Sec. 3.4, we hypothesize that the ML prediction of post-tipping climate dynamics purely from pre-tipping training data will usually only be possible for tipping point processes mediated by non-hysteretic stationary system bifurcations.\n\nIn what follows, we use reservoir computing [61][62][63] as the ML platform. Reservoir computing has previously been successfully used to predict the time evolution of dynamical systems [3-5, 7, 11, 18-20, 27], and its training is computationally inexpensive since it can be accomplished via a simple linear regression. This allows us to rapidly test different methodologies and various test system scenarios. We expect other types of machine learning, such as deep learning, to also work well using the methods presented in this paper.\n\nThe rest of the paper is structured as follows. Section II presents a brief introduction to the reservoir computing setup and training, as well as to our hyperparameter optimization scheme for non-stationary systems. In Section III we numerically demonstrate the use of ML to anticipate tipping point transitions and post-tipping behavior from motion in a restricted state space region to motion that explores substantial state space regions not previously visited. The example test systems used in Section III for generating the training data are the three-dimensional Lorenz ' \n\n\n"}, {"paperid": "paper3", "title": "Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces", "abstract": "Tipping points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.", "introduction": "\n\nNon-stationary chaotic dynamics are a prominent part of the world around us. In chaotic systems, small perturbations in the initial condition function significantly affect the long-term trajectory of the dynamics. Non-stationary chaotic systems possess further complexity due to their time-varying nature. For instance, the atmosphere and ocean dynamics that govern Earth's climate are modeled by highly nonlinear partial differential equations (PDEs). They exhibit non-stationary chaotic behavior due to changes in anthropogenic greenhouse gas emissions, insolation, and a myriad of complex internal feedbacks [1,2] (Figure 1a). One of the main areas in scientific computing is understanding such phenomena and providing computational methods to model their dynamics. Numerical methods, e.g., finite element and finite difference methods, have been widely used to solve PDEs. However, numerical methods have enormous computational requirements to capture the fine scales in complex processes. Moreover, they do not provide a manageable way to learn from data to reduce scientific modeling errors.\n\nLearning in non-stationary physical systems. These complexities in modeling complex physical systems make learning the dynamics of their evolution in function spaces notoriously difficult. Prior works proposed various neural networks, such as recurrent neural networks (RNNs) [3] and  Figure 1: (a) Tipping point in cloud fraction as a function of CO 2 concentration, from bulk model of the atmospheric boundary layer developed in [5,6]. 3d cloud cover renderings reproduced from [2].\n\n(b) RNO accurately forecasts tipping point 64 seconds ahead in non-stationary Lorenz-63 system. \"Predicted tipping point\" is the time at which our framework predicts a tipping point will occur, and \"forecast time\" is the time when our framework makes this prediction.\n\n\n"}]