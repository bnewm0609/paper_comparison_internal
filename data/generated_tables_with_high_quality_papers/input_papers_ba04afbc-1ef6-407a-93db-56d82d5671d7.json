[{"paperid": "paper0", "title": "Noise2Void - Learning Denoising From Single Noisy Images", "abstract": "The field of image denoising is currently dominated by discriminative deep learning methods that are trained on pairs of noisy input and clean target images. Recently it has been shown that such methods can also be trained without clean targets. Instead, independent pairs of noisy images can be used, in an approach known as Noise2Noise (N2N). Here, we introduce Noise2Void (N2V), a training scheme that takes this idea one step further. It does not require noisy image pairs, nor clean target images. Consequently, N2V allows us to train directly on the body of data to be denoised and can therefore be applied when other methods cannot. Especially interesting is the application to biomedical image data, where the acquisition of training targets, clean or noisy, is frequently not possible. We compare the performance of N2V to approaches that have either clean target images and/or noisy image pairs available. Intuitively, N2V cannot be expected to outperform methods that have more information available during training. Still, we observe that the denoising performance of Noise2Void drops in moderation and compares favorably to training-free denoising methods.", "introduction": "\n\nImage denoising is the task of inspecting a noisy image x = s + n in order to separate it into two components: its signal s and the signal degrading noise n we would like to remove. Denoising methods typically rely on the assumption that pixel values in s are not statistically independent. In other words, observing the image context of an unobserved pixel might very well allow us to make sensible predictions on the pixel intensity.\n\nA large body of work (e.g. [16,19]) explicitly modeled these interdependencies via Markov Random Fields (MRFs). In recent years, convolutional neural networks (CNNs) have been trained in various ways to predict pixel values from surrounding image patches, i.e. from the recep-noisy clean Traditional Traditional Traditional Traditional Traditional Traditional Traditional Traditional Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional  Traditional Traditional Traditional Traditional Traditional Traditional Traditional Traditional Traditional   Input Input Input Input Input Input Input Input Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input  Input Input Input Input Input Input Input Input Input   noisy  noisy   NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE  NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE NOISE2NOISE   noisy  void   NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID  NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID NOISE2VOID Figure 1: Training schemes for CNN-based denoising. Traditionally, training networks for denoising requires pairs of noisy and clean images. For many practical applications, however, clean target images are not available. NOISE2NOISE (N2N) [12] enables the training of CNNs from independent pairs of noisy images. Still, also noisy image pairs are not usually available. This motivated us to propose NOISE2VOID (N2V), a novel training procedure that does not require noisy image pairs, nor clean target images. By enabling CNNs to be trained directly on a body of noisy images, we open the door to a plethora of new applications, e.g. on biomedical data.\n\ntive field of that pixel [24,11,26,6,23,25,18,14]. Typically, such systems require training pairs (x j , s j ) of noisy input images x j and their respective clean target images s j (ground truth). Network parameters are then tuned to minimize an adequately formulated error metric (loss) between network predictions and known ground truth.\n\nWhenever ground truth images are not available, these methods cannot be trained and are therefore rendered useless for the denoising task at hand. Recent work by Lehtinen et al. [12] offers an elegant solution for this problem. Instead of training a CNN to map noisy inputs to clean ground truth images, their NOISE2NOISE (N2N) train-ing attempts to learn a mapping between pairs of independently degraded versions of the same training image, i.e. (s + n, s + n ), that incorporate the same signal s, but independently drawn noise n and n . Naturally, a neural network cannot learn to perfectly predict one noisy image from another one. However, networks trained on this impossible training task can produce results that converge to the same predictions as traditionally trained networks that do have access to ground truth images [12]. In cases where ground truth data is physically unobtainable, N2N can still enable the training of denoising networks. However, this requires that two images capturing the same content (s) with independent noises (n, n ) can be acquired [3].\n\nDespite these advantages of N2N training, there are at least two shortcomings to this approach: (i) N2N training requires the availability of pairs of noisy images, and (ii) the acquisition of such pairs with (quasi) constant s is only possible for (quasi) static scenes.\n\nHere we present NOISE2VOID (N2V), a novel training scheme that overcomes both limitations. Just as N2N, also N2V leverages on the observation that high quality denoising models can be trained without the availability of clean ground truth data. However, unlike N2N or traditional training, N2V can also be applied to data for which neither noisy image pairs nor clean target images are available, i.e. N2V is a self-supervised training method. In this work we make two simple statistical assumptions: (i) the signal s is not pixel-wise independent, (ii) the noise n is conditionally pixel-wise independent given the signal s.\n\nWe evaluate the performance of N2V on the BSD68 dataset [17] and simulated microscopy data 1 . We then compare our results to the ones obtained by a traditionally trained network [24], a N2N trained network and several self-supervised methods like BM3D [5], non-local means [2], and to mean-and median-filters. While it cannot be expected that our approach outperforms methods that have additional information available during training, we observe that the denoising performance of our results only drops moderately and is still outperforming BM3D.\n\nAdditionally, we apply N2V training and prediction to three biomedical datasets: cryo-TEM images from [3], and two datasets from the Cell Tracking Challenge 2 [20]. For all these examples, the traditional training scheme cannot be applied due to the lack of ground truth data and N2N training is only applicable on the cryo-TEM data. This demonstrates the tremendous practical utility of our method.\n\nIn summary, our main contributions are: \u2022 Introduction of NOISE2VOID, a novel approach for training denoising CNNs that requires only a body of single, noisy images. \u2022 Comparison of our N2V trained denoising results 1 For simulated microscopy data we know the perfect ground truth. 2 http://celltrackingchallenge.net/ to results obtained with existing CNN training schemes [24,12,25] and non-trained methods [18,2]. \u2022 A sound theoretical motivation for our approach as well as a detailed description of an efficient implementation. The remaining manuscript is structured as follows: Section 2 contains a brief overview of related work. In Section 3, we introduce the baseline methods we later compare our own results to. This is followed by a detailed description of our proposed method and its efficient implementation. All experiments and their results are described in Section 4, and our findings are finally discussed in Section 5.\n\n\n"}, {"paperid": "paper1", "title": "Noise2Self: Blind Denoising by Self-Supervision", "abstract": "We propose a general framework for denoising high-dimensional measurements which requires no prior on the signal, no estimate of the noise, and no clean training data. The only assumption is that the noise exhibits statistical independence across different dimensions of the measurement. Moreover, our framework is not restricted to a particular denoising model. We show how it can be used to calibrate any parameterised denoising algorithm, from the single hyperparameter of a median filter to the millions of weights of a deep neural network. We demonstrate this on natural image and microscopy data, where we exploit noise independence between pixels, and on single-cell gene expression data, where we exploit independence between detections of individual molecules. Finally, we prove a theoretical lower bound on the performance of an optimal denoiser. This framework generalizes recent work on training neural nets from noisy images and on cross-validation for matrix factorization.", "introduction": "\n\nWe would often like to reconstruct a signal from highdimensional measurements that are corrupted, undersampled, or otherwise noisy. Devices like high-resolution cameras, electron microscopes, and DNA sequencers are capable of producing measurements in the thousands to millions of feature dimensions. But when these devices are pushed to their limits, taking videos with ultra-fast frame rates at very low-illumination, probing individual molecules with electron microscopes, or sequencing tens of thousands of cells simultaneously, each individual feature can become quite noisy. Nevertheless, the objects being studied are often very structured and the values of different features are highly correlated. Speaking loosely, if the \"latent dimension\" of the space of objects under study is much lower than * Equal contribution 1 Chan-Zuckerberg Biohub. Correspondence to: Joshua Batson <joshua.batson@czbiohub.org>, Loic Royer <loic.royer@czbiohub.org>. the dimension of the measurement, it may be possible to implicitly learn that structure, denoise the measurements, and recover the signal without any prior knowledge of the signal or the noise.\n\nTraditional denoising methods each exploit a property of the noise, such as Gaussianity, or structure in the signal, such as spatiotemporal smoothness, self-similarity, or having low-rank. The performance of these methods is limited by the accuracy of their assumptions. For example, if the data are genuinely not low rank, then a low rank model will fit it poorly. This requires prior knowledge of the signal structure, which limits application to new domains and modalities. These methods also require calibration, as hyperparameters such as the degree of smoothness, the scale of self-similarity, or the rank of a matrix have dramatic impacts on performance.\n\nIn contrast, a data-driven prior, such as pairs (x i , y i ) of noisy and clean measurements of the same target, can be used to set up a supervised learning problem. A neural net trained to predict y i from x i may be used to denoise new noisy measurements (Weigert et al., 2018). As long as the new data are drawn from the same distribution, one can expect performance similar to that observed during training. Lehtinen et al. demonstrated that clean targets are unnecessary (2018). A neural net trained on pairs (x i , x i ) of independent noisy measurements of the same target will, under certain distributional assumptions, learn to predict the clean signal. These supervised approaches extend to image denoising the success of convolutional neural nets, which currently give state-of-the-art performance for a vast range of image-to-image tasks. Both of these methods require an experimental setup in which each target may be measured multiple times, which can be difficult in practice.\n\nIn this paper, we propose a framework for blind denoising based on self-supervision. We use groups of features whose noise is independent conditional on the true signal to predict one another. This allows us to learn denoising functions from single noisy measurements of each target, with performance close to that of supervised methods. The same approach can also be used to calibrate traditional image denoising methods such as median filters and non-local means, and, using a different independence structure, denoise highly under-sampled single-cell gene expression data. d Figure 1. (a) The box represents the dimensions of the measurement x. J is a subset of the dimensions, and f is a J-invariant function: it has the property that the value of f (x) restricted to dimensions in J, f (x)J , does not depend on the value of x restricted to J, xJ . This enables self-supervision when the noise in the data is conditionally independent between sets of dimensions. Here are 3 examples of dimension partitioning: (b) two independent image acquisitions, (c) independent pixels of a single image, (d) independently detected RNA molecules from a single cell.\n\nWe model the signal y and the noisy measurement x as a pair of random variables in R m . If J \u2282 {1, . . . , m} is a subset of the dimensions, we write x J for x restricted to J.\n\nDefinition. Let J be a partition of the dimensions {1, . . . , m} and let J \u2208 J . A function f :\nR m \u2192 R m is J-invariant if f (x) J does not depend on the value of x J . It is J -invariant if it is J-invariant for each J \u2208 J .\nWe propose minimizing the loss\nL(f ) = E f (x) \u2212 x 2 ,(1)\nover J -invariant functions f . Since f has to use information from outside of each subset of dimensions J to predict the values inside of J, it cannot merely be the identity.\n\nSuppose x is an unbiased estimator of y, that is, E[x|y] = y, and the noise in each subset J \u2208 J is independent from the noise in its complement J c , conditional on y. Then we can decompose the loss as\nL(f ) = E f (x) \u2212 y 2 + E x \u2212 y 2 ,(2)\nthe sum of the ordinary supervised loss and the variance of the noise. By minimizing the self-supervised loss L(f ), which we can compute from noisy data alone, we are able to find the actual optimal denoiser among any class of Jinvariant functions.\n\nFor example, if the signal is an image with independent, mean-zero noise on each pixel, we may choose J = {{1}, . . . , {m}} to be the singletons of each coordinate. In \u00a73, we show how to adapt any traditional image denoising function into a J -invariant one, and then calibrate it using this loss. For example, \"donut\" median filters, with a hole in the center, form a class of J -invariant functions. By comparing the value of the loss for different filter radii, we are able to select the optimal radius for denoising the image at hand.\n\nThe donut median filter has just one parameter and therefore limited ability to adapt to the data. At the other extreme, we may search over all J -invariant functions for the global optimum:\nProposition 1. The J -invariant function f * J minimizing (1) satisfies f * J (x) J = E[y J |x J c ] for each subset J \u2208 J .\nThat is, the optimal J -invariant predictor for the dimensions of y in some J \u2208 J is their expected value conditional on observing the dimensions of x outside of J.\n\nIn \u00a74, we use analytical examples to illustrate how the optimal J -invariant denoising function approaches the optimal general denoising function as the amount of correlation between features in the data increases.\n\nIn practice, we may attempt to approximate the optimal denoiser by searching over a very large class of functions, such as deep neural networks with millions of parameters. In \u00a75, we show that a deep convolutional network, modified to become J -invariant using a masking procedure, can achieve state-of-the-art denoising performance on three diverse datasets.\n\nSample code is available on GitHub 1 and deferred proofs are contained in the Supplement.\n\n\n"}, {"paperid": "paper2", "title": "Probabilistic Noise2Void: Unsupervised Content-Aware Denoising", "abstract": "Today, Convolutional Neural Networks (CNNs) are the leading method for image denoising. They are traditionally trained on pairs of images, which are often hard to obtain for practical applications. This motivates self-supervised training methods such as Noise2Void~(N2V) that operate on single noisy images. Self-supervised methods are, unfortunately, not competitive with models trained on image pairs. Here, we present 'Probabilistic Noise2Void' (PN2V), a method to train CNNs to predict per-pixel intensity distributions. Combining these with a suitable description of the noise, we obtain a complete probabilistic model for the noisy observations and true signal in every pixel. We evaluate PN2V on publicly available microscopy datasets, under a broad range of noise regimes, and achieve competitive results with respect to supervised state-of-the-art methods.", "introduction": "\n\nImage restoration is the problem of reconstructing an image from a corrupted version of itself. Recent work shows how CNNs can be used to build powerful content-aware image restoration (CARE) pipelines [11,10,12,13,6,4,1,5]. However, for supervised CARE models, such as [10], pairs of clean and noisy images are required.\n\nFor many application areas, it is impractical or impossible to acquire clean ground-truth images [2]. In such cases, Noise2Noise (N2N) training [6] relaxes the problem, only requiring two noisy instances of the same data. Unfortunately, even the acquisition of two noisy realizations of the same image content is often difficult [2]. Self-supervised training methods, such as Noise2Void (N2V) [4], are a promising alternative, as they operate exclusively on single noisy images [4,1,5]. This is enabled by excluding/masking the center (blind-spot) of the network's receptive fields. Self-supervised training assumes that the noise is pixel-wise independent and that the true intensity of a pixel can be predicted from local image context, excluding before-mentioned blind-spots [4]. For many applications, especially in the context of microscopy images, the first assumption is fulfilled, but the second assumption offers room for improvements [5].\n\nHence, self-supervised models can often not compete with supervised training [4]. In concurrent work, by Laine et al. [5], this problem was elegantly addressed by assuming a Gaussian noise model and predicting Gaussian intensity distributions per pixel. The authors also showed that the same approach an be applied to other noise distributions, which can be approximated as Gaussian, or can be described analytically.\n\nHere, we introduce a new training approach called Probabilistic Noise2Void (PN2V). Similar to [5], PN2V proposes a way to leverage information of the network's blind-spots. However, PN2V is not restricted to Gaussian noise models or Gaussian intensity predictions. More precisely, to compute the posterior distribution of a pixel, we combine (i) a general noise model that can be represented as a histogram (observation likelihood), and (ii) a distribution of possible true pixel intensities (prior), represented by a set of predicted samples.\n\nHaving this complete probabilistic model for each pixel, we are now free to chose which statistical estimator to employ. In this work we use MMSE estimates for our final predictions and show that MMSE-PN2V consistently outperformes other self-supervised methods and, in many cases, leads to results that are competitive even with supervised state-of-the-art CARE networks (see below).\n\n\n"}, {"paperid": "paper3", "title": "Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising", "abstract": "Self-supervised frameworks that learn denoising models with merely individual noisy images have shown strong capability and promising performance in various image denoising tasks. Existing self-supervised denoising frameworks are mostly built upon the same theoretical foundation, where the denoising models are required to be J-invariant. However, our analyses indicate that the current theory and the J-invariance may lead to denoising models with reduced performance. In this work, we introduce Noise2Same, a novel self-supervised denoising framework. In Noise2Same, a new self-supervised loss is proposed by deriving a self-supervised upper bound of the typical supervised loss. In particular, Noise2Same requires neither J-invariance nor extra information about the noise model and can be used in a wider range of denoising applications. We analyze our proposed Noise2Same both theoretically and experimentally. The experimental results show that our Noise2Same remarkably outperforms previous self-supervised denoising methods in terms of denoising performance and training efficiency. Our code is available at https://github.com/divelab/Noise2Same.", "introduction": "\n\nThe quality of deep learning methods for signal reconstruction from noisy images, also known as deep image denoising, has benefited from the advanced neural network architectures such as ResNet [8], U-Net [19] and their variants [29,16,26,31,25,14]. While more powerful deep image denoising models are developed over time, the problem of data availability becomes more critical.\n\nMost deep image denoising algorithms are supervised methods that require matched pairs of noisy and clean images for training [27,29,2,7]. The problem of these supervised methods is that, in many denoising applications, the clean images are hard to obtain due to instrument or cost limitations. To overcome this problem, Noise2Noise [13] explores an alternative training framework, where pairs of noisy images are used for training. Here, each pair of noisy images should correspond to the same but unknown clean image. Note that Noise2Noise is basically still a supervised method, just with noisy supervision.\n\nDespite the success of Noise2Noise, its application scenarios are still limited as pairs of noisy images are not available in some cases and may have registration problems. Recently, various of denoising frameworks that can be trained on individual noisy images [23,17,28,10,1,12] have been developed. These studies can be divided into two categories according to the amount of extra information required. Methods in the first category requires the noise model to be known. For example, the simulation-based methods [17,28] use the noise model to generate simulated noises and make individual noisy images noisier. Then a framework similar to Noise2Noise can be applied to train the model with pairs of noisier image and the original noisy image. The limitation is obvious as the noise model may be too complicated or even not available. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.\n\nOn the other hand, algorithms in the second category target at more general cases where only individual noisy images are available without any extra information [23,10,1,12]. In this category, self-supervised learning [30,6,24] has been widely explored, such as Noise2Void [10], Noise2Self [1], and the convolutional blind-spot neural network [12]. Note that these self-supervised models can be improved as well if information about the noise model is given. For example, Laine et al. [12] and Krull et al. [11] propose the Bayesian post-processing to utilize the noise model. However, with the proposed post-processing, these methods fall into the first category where applicability is limited.\n\nIn this work, we stick to the most general cases where only individual noisy images are provided and focus on the self-supervised framework itself without any post-processing step. We note that all of these existing self-supervised denoising frameworks are built upon the same theoretical background, where the denoising models are required to be J -invariant (Section 2). We perform in-depth analyses on the J -invariance property and argue that it may lead to denoising models with reduced performance. Based on this insight, we propose Noise2Same, a novel self-supervised denoising framework, with a new theoretical foundation. Noise2Same comes with a new self-supervised loss by deriving a self-supervised upper bound of the typical supervised loss. In particular, Noise2Same requires neither J -invariance nor extra information about the noise model. We analyze the effect of the new loss theoretically and conduct thorough experiments to evaluate Noise2Same. Result show that our Noise2Same consistently outperforms previous self-supervised denoising methods.\n\n\n"}, {"paperid": "paper4", "title": "Self2Self With Dropout: Learning Self-Supervised Denoising From Single Image", "abstract": "In last few years, supervised deep learning has emerged as one powerful tool for image denoising, which trains a denoising network over an external dataset of noisy/clean image pairs. However, the requirement on a high-quality training dataset limits the broad applicability of the denoising networks. Recently, there have been a few works that allow training a denoising network on the set of external noisy images only. Taking one step further, this paper proposes a self-supervised learning method which only uses the input noisy image itself for training. In the proposed method, the network is trained with dropout on the pairs of Bernoulli-sampled instances of the input image, and the result is estimated by averaging the predictions generated from multiple instances of the trained model with dropout. The experiments show that the proposed method not only significantly outperforms existing single-image learning or non-learning methods, but also is competitive to the denoising networks trained on external datasets.", "introduction": "\n\nImage denoising is the process to remove measurement noises from noisy images. It not only has great practical value, but also serves as a core module in many image recovery tasks. A noisy image y is usually modeled as\ny = x + n,(1)\nwhere x denotes the clean image (ground truth), and n denotes the measurement noise often assumed to be random. In recent years, deep learning has become a prominent approach for image denoising, which uses a set of training samples to train a deep neural network (NN), denoted by F \u03b8 (\u00b7) with the parameter vector \u03b8, that maps a noisy image to its clean counterpart. Most existing deep-learningbased denoising methods (e.g. [26,31,32]) use many pairs of clean/noisy images, denoted by {x (i) , y (i) } i , as the train-ing samples, and the training is done by solving\nmin \u03b8 i L(F \u03b8 (x (i) ), y (i) ),(2)\nwhere L(\u00b7, \u00b7) measures the distance between two images. The availability of a large number of training samples is one key factor contributing to the performance of these methods. Sometimes, it can be expensive and difficult to collect a large dataset of useful clean/noisy image pairs. Recently, there are some studies on training denoising NNs with only external noisy images. The Noise2Noise (N2N) method [19] showed that a denoising NN model can be trained using many pairs of two noisy images of the same scene. Using a self-prediction loss, together with a so-called blind-spot strategy to avoid learning an identity mapping, the Noise2Void (N2V) method [15] and the Noise2Self (N2S) method [3] showed the possibility to learn a denoising NN with good performance on a set of unorganized external noisy images. Yet, to achieve good performance, the external images used for training should be highly related to the noisy image being processed, in terms of image content and noise statistics. The collection of such external images can be costly or challenging in practice.\n\nIt is of great value to develop a powerful denoising NN that has no prerequisite on training samples. That is, the denoising NN is learned only on the input image itself. So far, there has been very little work along this line. Based on the deep image prior (DIP), Ulyanov et al. [25] proposed a single-image deep learning model for image recovery. The aforementioned dataset-based N2V and N2S methods can also be trained using only a noisy image. However, the performance of these methods is not competitive to existing non-local methods, e.g. BM3D [10]. To summarize, there is no satisfactory solution on how to train a denoising NN with good performance, given only the input noisy image.\n\n\n"}, {"paperid": "paper5", "title": "Blind2Unblind: Self-Supervised Image Denoising with Visible Blind Spots", "abstract": "Real noisy-clean pairs on a large scale are costly and difficult to obtain. Meanwhile, supervised denoisers trained on synthetic data perform poorly in practice. Self-supervised denoisers, which learn only from single noisy images, solve the data collection problem. However, self-supervised denoising methods, especially blindspot-driven ones, suffer sizable information loss during input or network design. The absence of valuable information dramatically reduces the upper bound of denoising performance. In this paper, we propose a simple yet efficient approach called Blind2Unblind to overcome the information loss in blindspot-driven denoising methods. First, we introduce a global-aware mask mapper that enables global perception and accelerates training. The mask mapper samples all pixels at blind spots on denoised volumes and maps them to the same channel, allowing the loss function to optimize all blind spots at once. Second, we propose a re-visible loss to train the denoising network and make blind spots visible. The denoiser can learn directly from raw noise images without losing information or being trapped in identity mapping. We also theoretically analyze the convergence of the re-visible loss. Extensive experiments on synthetic and real-world datasets demonstrate the superior performance of our approach compared to previous work. Code is available at https://github.com/demonsjin/Blind2Unblind.", "introduction": "\n\nImage denoising, an essential task of low-level image processing, aims to remove noise and restore a clean image. In vision applications, the quality of denoising significantly affects the performance of downstream tasks, such as superresolution [16], semantic segmentation [22], and object detection [31]. In addition, the denoiser can significantly improve the quality of images captured by mobile phones and other devices, reflecting a broad demand in imaging fields.\n\n\n"}]