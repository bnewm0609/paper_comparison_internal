[{"paperid": "paper0", "title": "Ensemble Distillation for Robust Model Fusion in Federated Learning", "abstract": "Federated Learning (FL) is a machine learning setting where many devices collaboratively train a machine learning model while keeping the training data decentralized. In most of the current training schemes the central model is refined by averaging the parameters of the server model and the updated parameters from the client side. However, directly averaging model parameters is only possible if all models have the same structure and size, which could be a restrictive constraint in many scenarios. In this work we investigate more powerful and more flexible aggregation schemes for FL. Specifically, we propose ensemble distillation for model fusion, i.e. training the central classifier through unlabeled data on the outputs of the models from the clients. This knowledge distillation technique mitigates privacy risk and cost to the same extent as the baseline FL algorithms, but allows flexible aggregation over heterogeneous client models that can differ e.g. in size, numerical precision or structure. We show in extensive empirical experiments on various CV/NLP datasets (CIFAR-10/100, ImageNet, AG News, SST2) and settings (heterogeneous models/data) that the server model can be trained much faster, requiring fewer communication rounds than any existing FL technique so far.", "introduction": "\n\nFederated Learning (FL) has emerged as an important machine learning paradigm in which a federation of clients participate in collaborative training of a centralized model (Shokri & Shmatikov, 2015;McMahan et al., 2016;Smith et al., 2017;Caldas et al., 2018;Bonawitz et al., 2019;Li et al., 2019;Kairouz et al., 2019). The clients send their model parameters to the server but never their private training datasets, thereby ensuring a basic level of privacy. Among the key challenges in federated training are communication overheads and delays (one would like to train the central model with as few communication rounds as possible), and client heterogeneity: the training data (non-i.i.d.-ness), as well as hardware and computing resources, can change drastically among clients, for instance when training on commodity mobile devices.\n\nClassic training algorithms in FL, such as federated averaging (FEDAVG) (McMahan et al., 2016) and its recent adaptations (Mohri et al., 2019;Li et al., 2020;Hsu et al., 2019;Karimireddy et al., 2019;Hsu et al., 2020;Reddi et al., 2020), are all based on directly averaging of the participating client's parameters and can hence only be applied if all client's models have the same size and structure. In contrast, ensemble learning methods (You et al., 2017;Furlanello et al., 2018;Anil et al., 2018;Dvornik et al., 2019;Park & Kwak, 2019;Liu et al., 2019;Wu et al., 2019) allow to combine multiple heterogeneous weak classifiers by averaging the predictions of the individual models instead. However, applying ensemble learning techniques directly in FL is infeasible in practice due to the large number of participating clients. Storing a different model per client on the server is not only impossible due to memory constraints, but also renders training and inference inefficient, and hinders knowledge transfer between clients.\n\nTo enable federated learning in more realistic settings, we propose to use ensemble distillation (Bucilu\u01ce et al., 2006;Hinton et al., 2015) for robust model fusion (FedDF). Our scheme leverages unlabeled data or artificially generated examples (e.g. by a GAN's generator (Goodfellow et al., 2014)) to aggregate knowledge from all received (heterogeneous) client models. We demonstrate with thorough empirical results that our ensemble distillation approach not only addresses the existing quality loss issue (Hsieh et al., 2019) of Batch Normalization (BN) (Ioffe & Szegedy, 2015) for networks in a homogeneous FL system, but can also break the knowledge barriers among heterogeneous client models. Our main contributions are:\n\n\u2022 We propose a distillation framework for robust federated model fusion, which allows for heterogeneous client models and data, and is robust to the choices of neural architectures. \u2022 We show in extensive numerical experiments on various CV/NLP datasets (CIFAR-10/100, Ima-geNet, AG News, SST2) and settings (heterogeneous models and/or data) that the server model can be trained much faster, requiring fewer communication rounds than any existing FL technique.\n\nWe further provide insights on when FedDF can outperform FEDAVG (see also Fig. 1 that highlights an intrinsic limitation of parameter averaging based approaches) and what factors influence FedDF.  (2019); Wang et al. (2020) propose to use optimal transport and other alignment schemes to first align or match individual neurons of the neural nets layer-wise before averaging the parameters. However, these layer-based alignment schemes necessitate client models with the same number of layers and structure, which is restrictive in heterogeneous systems in practice. Another line of work aims to improve local client training, i.e., client-drift problem caused by the heterogeneity of local data (Li et al., 2018;Karimireddy et al., 2019). For example, FEDPROX (Li et al., 2018) incorporates a proximal term for the local training. Other techniques like acceleration, recently appear in preprints (Hsu et al., 2019;2020;Reddi et al., 2020).\n\n\n"}, {"paperid": "paper1", "title": "Resource-aware Federated Learning using Knowledge Extraction and Multi-model Fusion", "abstract": "With increasing concern about user data privacy, federated learning (FL) has been developed as a unique training paradigm for training machine learning models on edge devices without access to sensitive data. Traditional FL and existing methods directly employ aggregation methods on all edges of the same models and training devices for a cloud server. Although these methods protect data privacy, they are not capable of model heterogeneity, even ignore the heterogeneous computing power, and incur steep communication costs. In this paper, we purpose a resource-aware FL to aggregate an ensemble of local knowledge extracted from edge models, instead of aggregating the weights of each local model, which is then distilled into a robust global knowledge as the server model through knowledge distillation. The local model and the global knowledge are extracted into a tiny size knowledge network by deep mutual learning. Such knowledge extraction allows the edge client to deploy a resource-aware model and perform multi-model knowledge fusion while maintaining communication ef\ufb01ciency and model heterogeneity. Empirical results show that our approach has sig-ni\ufb01cantly improved over existing FL algorithms in terms of communication cost and generalization performance in heterogeneous data and models. Our approach reduces the communication cost of VGG-11 by up to 102 \u00d7 and ResNet-32 by up to 30 \u00d7 when training ResNet-20 as the knowledge network.", "introduction": "\n\nFederated learning (FL) has emerged as a novel machine learning paradigm for distributed clients to participate in the collaborative training of a centralized model.FL brings model asynchronous training on edge, where devices (e.g., mobile phones and IoT devices) extract the knowledge on the private-sensitive training data and then upload the learned models to the cloud for aggregation.FL stores user data locally and restricts direct access to it from cloud servers; thereby, this paradigm not only enhances privacypreserving but also introduces several inherent advantages, including model accuracy, cost efficiency, and diversity.With the massive demand for data in today's machine learning models and the social considerations of artificial intelligence (e.g., privacy and security (Yang et al. 2019;Curzon et al. 2021)), federated learning has great potential and role in counterpoising this trade-off.\n\nFederated learning has already shown its potential in practical applications, including health care (Sheller et al. 2020), environment protection (Hu et al. 2018), electrical vehicles (Saputra et al. 2019), and etc. Google, Apple, and NVIDIA are using FL for their applications nowadays (e.g., Google Keyboard (Yang et al. 2018;Chen et al. 2019), Apple Siri (Freudiger 2019;Paulik et al. 2021), NVIDIA medical imaging (Li et al. 2019)).In consequence, designing efficient FL models and deploying them effectively and fairly on edge devices is crucial for improving the performance of edge computing in the future.\n\nTraditional FL, represented by FedAvg (McMahan et al. 2017) in Figure 1 (b), broadcasts global model parameters to selected edge devices, performs a weighted average of the trained local model parameters based on their local data and updates the global model.This process is then iterated through many communication rounds to achieve good performance across all edge devices.From the framework of traditional FL, we observe the following limitations: First, iterative model weights sharing between network edges and the servers introduces excessive communication overhead.Second, the ever-increasing computational and memory requirements of AI models (e.g., deep neural networks -DNNs) and the heterogeneous computing power of edge devices make deploying the same models on resource-constrained edge devices problematic.For example, it is infeasible to deploy a large model on a resourcelimited edge device.In addition, local data from the realworld is typically imbalance/non-independent identically distributed (non-IID), which can easily lead to training failure in a decentralized situation (Michieli and Ozay 2021).Deep learning models are generally over-parameterized, and when local data are heterogeneous, aggregating local models tends to cause over-fitting, leading to high variance in learning and prediction (Jiang et al. 2019;Nishio and Yonetani 2019).Therefore, performing weight-average aggregating of local models, or even deploying the same model on devices with different computing power, as employed by most existing FL methods, may produce an unfair, ineffective global model and fail to deploy it efficiently.\n\nTo overcome the above limitations of previous FL methods, we came up with the idea of performing resource-aware federated learning using knowledge extraction and multimodel fusion (FedKEMF), as illustrated in Figure 1 (a).The benefits of our approach FedKEMF are: i) It distills the client's knowledge before aggregating it to the server, which prevents such large edge models from being over-parameterized while reducing the resource constraints of edge devices.ii) It effectively reduces communication costs by exchanging distilled tiny size neural networks between edges and clouds instead of the original large models.iii) Ensembling knowledge from edges efficiently robust the global model, reducing the risk of over-fitting and variance, and achieving better generalization performance in FL.Furthermore, our purposed approach is aware of resourceconstraint and applies multi-model fusion to break the limitations of model structure, deploy models fairly on edge devices, and enable federated learning in a more realistic setting.\n\nWe conduct extensive experiments on non-IID data settings and heterogeneous client models to validate the performance of the purposed approach and compare it with existing FL methods.Our results show that, when optimizing a small neural network as the knowledge network, FedKEMF significantly reduces communication cost and achieves better performance using fewer communication rounds.Another line in FL is personalized FL, which focuses on the problem of statistical heterogeneity.Personalized FL aims to personalize the global model for each client in FL and find how to develop improved personalized models that can benefit a large majority of clients (Kulkarni, Kulkarni, and Pant 2020).Although we have the same consideration of device heterogeneity (memory storage and computation power), data heterogeneity (non-IID data), and model heterogeneity (model structure and size), we focus on how to extract knowledge from different types of models and their corresponding training devices to build robust global knowledge.\n\n\n"}, {"paperid": "paper2", "title": "Learn from Others and Be Yourself in Heterogeneous Federated Learning", "abstract": "Federated learning has emerged as an important distributed learning paradigm, which normally involves collaborative updating with others and local updating on private data. However, heterogeneity problem and catastrophic forgetting bring distinctive challenges. First, due to non-i.i.d (identically and independently distributed) data and heterogeneous architectures, models suffer performance degradation on other domains and communication barrier with participants models. Second, in local updating, model is separately optimized on private data, which is prone to overfit current data distribution and forgets previously acquired knowledge, resulting in catastrophic forgetting. In this work, we propose FCCL (Federated CrossCorrelation and Continual Learning). For heterogeneity problem, FCCL leverages unlabeled public data for communication and construct cross-correlation matrix to learn a generalizable representation under domain shift. Mean- while, for catastrophic forgetting, FCCL utilizes knowledge distillation in local updating, providing inter and intra domain information without leaking privacy. Empirical results on various image classification tasks demonstrate the effectiveness of our method and the efficiency of modules.", "introduction": "\n\nDeep learning algorithms have achieved remarkable progress, owing to the availability of large-scale data [8,51,69]. However, in the real world, data are commonly dispersed over different participants (e.g., mobile devices, organizations). Due to growing privacy concerns and strict data protection regulations [84], participants cannot integrate data together to train a model. Driven by such realistic issues, federated learning [33,34,58,59,89] provides a privacy-preserving paradigm, where participants collabo- Figure 1. Problem illustration of heterogeneous federated learning. (a) In collaborative updating, how to handle communication problem of heterogeneous models and learn a generalizable representation under heterogeneous data (domain shift)? (b) In local updating, how to alleviate catastrophic forgetting to present stable and satisfactory performance in both inter and intra domains? ratively learn a model without leaking private data. It has been an active and challenging research topic and shows promising results in real-world setting [17,19,29,52,54].\n\nAlong with its pilot progress, researches on federated learning are baffled by some key challenges [30,42]. An inevitable and practical challenge is heterogeneity problem. On the one hand, distributed data might be non-i.i.d (identically and independently distributed), leading to data heterogeneity [30,39,95]. A myriad of methods [43,46,73,77] incorporate extra proximal terms to handle the data in label distribution skew (prior probability shift) [30], neglecting the fact that there exists domain shift (same label, different features) [60,64,66]. In particular, private model suffers severe performance degradation on other domains with no-ticeably different distribution. As a result, learning a generalizable representation under domain shift is technically challenging. On the other hand, due to different design criteria, distinct hardware capabilities [20,86] and intellectual property rights [56], participants require to customize models, which poses a practical challenge: model heterogeneity. Preceding methods are developed under the assumption that local models share parameters or gradients, which cannot work on heterogeneous models. In order to solve this problem, a main stream of subsequent effort leverages knowledge transfer through labeled data [38,74], shared model [48,72,92] or group operation [21,50]. But these methods have different limitations. Specifically, labeled data require server to collect data with similar distributions to private data, which causes costly human efforts and needs special domain expertise. For shared model, it raises computational cost and necessitates additional model structure in participant side. Group operation leverages unlabeled public data to measure distribution divergence. However, these methods mainly focus on label distribution skew and consider the performance on one domain. Simultaneously considering data and model heterogeneity, an essential issue has long been overlooked: (a) How to learn a generalizable representation in heterogeneous federated learning?\n\nBesides heterogeneity problem, another impediment for federated learning steams from its paradigm. Generally, federated learning could be viewed as a two-step cyclic process: collaborative updating and local updating [58,89]. In collaborative updating, participants learn from others. In local updating, model is optimized on private data, which is prone to overfit current knowledge and forget previous knowledge, resulting in catastrophic forgetting [57]. To tackle this challenge, one type of methods typically performs fine-tuning for several rounds [38,50,58,74,88]. However, carefully configuring hyper-parameters to achieve satisfactory performance is time-consuming and cannot tackle this problem systematically. Current popular solutions [41,43,73,77] focus on calculating parameter stiffness to regulate models, which can not explicitly depict the degree of effect from different participants. Consequently, a natural question arises: (b) How to balance multiple knowledge to reduce catastrophic forgetting? We further explain heterogeneity problem and catastrophic forgetting in Fig. 1.\n\nFor the heterogeneity problem, we take inspiration from the self-supervised learning [5,6,11,13,18,25,49,91,94]. In particular, self-supervised learning aims to learn a generalizable representation through rich and diverse data for downstream tasks and unseen classes. Intuitively, we expect that the models would present similar logits output for the same classes in different domains. This motivates us to leverage unlabeled public data for Federated Cross-Correlation Learning, which is diverse and easy to obtain. Specifically, we try to maximize the similarity between log-its output and minimize the redundancy within logits output on unlabeled public data. Through correlating same dimensions and decorrelating different dimensions on logits output, models would learn class invariance and encourage the diversity of different classes. Thus, our method handles the communication problem in heterogeneous models and learns a generalizable representation under domain shift.\n\nTo handle catastrophic forgetting, we develop Federated Continual Learning via knowledge distillation [2,24] in local updating to continually learn from inter and intra domains. To avoid forgetting inter domain information in local updating stage, we propose to distill the knowledge of intradomain (local) model learned in previous rounds, where it captured the inter domain information after communication with other participants. In addition, for intra domain forgetting problem, we leverage the initially pretrained local model (without knowledge learned from others) to constrain the later local updating for each participant. Therefore, balancing knowledge through distillation with these two models is reasonable to handle the catastrophic forgetting.\n\nIn this work, we propose a novel federated learning method, dubbed FCCL (Federated Cross-Correlation and Continual Learning). The overview of FCCL is illustrated in Fig. 2. In a nutshell, our contributions are three-fold:\n\n\u2022 We formulate a simple and effective method for heterogeneous federated learning. Through leveraging unlabeled public data and adopting self-supervised learning, heterogeneous models achieve communication and learn a generalizable representation.\n\n\u2022 We explore to alleviate catastrophic forgetting in federated learning. Through inter and intra domain knowledge distillation with updated and pretrained models, it balances knowledge from others and itself.\n\n\u2022 We conduct extensive experiments on two image classification tasks (e.g., Digits [27,37,62,68] and Office-Home [82]) with unlabeled public data [35,69,87]. FCCL achieves superior inter and intra domain performance over related methods. Ablation study on core module validates its efficacy and indispensability.\n\n\n"}, {"paperid": "paper3", "title": "FedMD: Heterogenous Federated Learning via Model Distillation", "abstract": "Federated learning enables the creation of a powerful centralized model without compromising data privacy of multiple participants. While successful, it does not incorporate the case where each participant independently designs its own model. Due to intellectual property concerns and heterogeneous nature of tasks and data, this is a widespread requirement in applications of federated learning to areas such as health care and AI as a service. In this work, we use transfer learning and knowledge distillation to develop a universal framework that enables federated learning when each agent owns not only their private data, but also uniquely designed models. We test our framework on the MNIST/FEMNIST dataset and the CIFAR10/CIFAR100 dataset and observe fast improvement across all participating models. With 10 distinct participants, the final test accuracy of each model on average receives a 20% gain on top of what's possible without collaboration and is only a few percent lower than the performance each model would have obtained if all private datasets were pooled and made directly available for all participants.", "introduction": "\n\nDeep learning has provided a potentially powerful framework to automate perception and inference. However, large datasets are required to fully realize this potential. In areas like health care, it is often difficult and costly to curate large datasets. For instance, typical hospitals in the US may have only dozens of MRI images of a particular disease that needs to be annotated by human experts and must be protected from potential privacy breaches. Federated learning and similar ideas [1,2] rise to this challenge and effectively train a centralized model while keeping users' sensitive data on device. In particular, federated learning [1,3,4] is optimized for faster communication and is uniquely capable of handling a large number of users.\n\nFederated learning faces many challenges [5], among which, of particular importance is the heterogeneity that appear in all aspects of the learning process. There is system heterogeneity when each participant has a different amount of bandwidth and computational power; this was partly resolved by the native asynchronous scheme of federated learning, which was further refined e.g. to enable active sampling [6,7] and improve fault tolerance [8]. There is also statistical heterogneity (the non i.i.d. problem) where clients have a varying amount of data coming from distinct distributions [9,10,11,12,13,14].\n\nIn this work, we focus on a different type of heterogeneity: the differences of local models. In the original federated framework, all users have to agree on the particular architecture of a centralized model. This is a reasonable assumption when the participants are millions of low capacity devices such as cell phones. In this work, we instead explore extensions to the federated framework that is realistic in a business facing setting, where each participant has capacity and desire to design their 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada. own unique model. This arise in areas like health care, finance, supply chain and AI services. For example, when several medical institutions collaborate without sharing private data, they may need to craft their own model to meet distinct specifications. They may not be willing to share details of their models due to privacy and intellectual property concerns. Another example is AI as a service. A typical AI vendor of, e.g. customer service chat bots, may have dozens of client companies. Each client's model is distinct and solves different tasks. The standard practice is to train a client's model with only its own data. It would be immensely beneficial if data from other clients can be utilized without compromising privacy or independency. How can one perform federated learning when each participant has a different model that is a blackbox to others? This is the central question that we will answer in this work.\n\nThis question is intimately related to the non-i.i.d. challenge of federated learning because a natural way to tackle statistical heterogeneity is to have individualized models for each user. Indeed, existing frameworks result in sightly different models. For example, [10] provides a framework for multitask learning if the problem is convex. Approaches based on frameworks such as Bayesian [11], meta-learning [12] and transfer learning [14] also achieve good performance on non-i.i.d. data while allowing a certain amount of model customization. However, to our knowledge, all existing frameworks require a centralized control over the design of local models. Full model independency, while related to the non-i.i.d. problem, is an important new research direction in its own right.\n\nThe key to full model heterogeneity is communication. In particular, there must be a translation protocol enabling a deep network to understand the knowledge of others without sharing data or model architecture. This question touches on fundamental issues in deep learning, such as interpretability and emergent communication protocols. In principle, machines should be able to learn the best communication protocol that is adaptive to any specific use case. As a first step in this direction, we employ a more transparent framework based on knowledge distillation that solves the problem.\n\nTransfer learning is another major framework addressing the scarcity of private data. In this work, our private datasets can be as small as a few samples per class. Therefore using transfer learning from a large public dataset is imperative in addition to federated learning. We leverage the power of transfer learning in two ways. First, before entering the collaboration, each model is fully trained first on the public data and then on its own private data. Second, and more importantly, the blackbox models communicate based on their output class scores on samples from the public dataset. This is realized through knowledge distillation [15], which has been capable of transmitting learned information in a model agnostic way.\n\n\n"}, {"paperid": "paper4", "title": "FedGH: Heterogeneous Federated Learning with Generalized Global Header", "abstract": "Federated learning (FL) is an emerging machine learning paradigm that allows multiple parties to train a shared model collaboratively in a privacy-preserving manner. Existing horizontal FL methods generally assume that the FL server and clients hold the same model structure. However, due to system heterogeneity and the need for personalization, enabling clients to hold models with diverse structures has become an important direction. Existing model-heterogeneous FL approaches often require publicly available datasets and incur high communication and/or computational costs, which limit their performances. To address these limitations, we propose a simple but effective Federated Global prediction Header (FedGH) approach. It is a communication and computation-efficient model-heterogeneous FL framework which trains a shared generalized global prediction header with representations extracted by heterogeneous extractors for clients' models at the FL server. The trained generalized global prediction header learns from different clients. The acquired global knowledge is then transferred to clients to substitute each client's local prediction header. We derive the non-convex convergence rate of FedGH. Extensive experiments on two real-world datasets demonstrate that FedGH achieves significantly more advantageous performance in both model-homogeneous and -heterogeneous FL scenarios compared to seven state-of-the-art personalized FL models, beating the best-performing baseline by up to 8.87% (for model-homogeneous FL) and 1.83% (for model-heterogeneous FL) in terms of average test accuracy, while saving up to 85.53% of communication overhead.", "introduction": "\n\nFederated learning (FL) [39] has become a widely adopted approach for collaborative model training involving multiple participants with decentralized data under the premise of privacy preservation. Horizontal FL methods, such as FedAvg [27], generally involve a central FL server coordinating multiple FL clients. In each round of distributed model training, the server broadcasts the global model to selected clients. The clients then train the received global model on their respective local datasets and send the updated local models back to the server. The server then updates the global model by aggregating the received local models. The above steps are iteratively executed until the global model converges. Since only the model parameters are transmitted between the server and clients without exposing the raw data, privacy protection is enhanced. Nevertheless, the above paradigm requires all clients to train models with the same structures (i.e., model homogeneity) in order to work.\n\nHowever, in practical cross-device FL scenarios, the clients participating in FL are mostly mobile edge devices with heterogeneous and constrained system resources (e.g., computing power, network bandwidth, memory, storage, and battery capacity) [35,36,40,42,[44][45][46]. This is also referred to as system heterogeneity in FL. Modelhomogeneous FL methods face three limitations in this scenario:\n\n\u2022 Device: when training a large global model, some low-end clients may never be able to join in FL since their limited arXiv:2303.13137v2 [cs.\n\nLG] 1 Aug 2023 system resources preclude them from training large models. As a result, the accuracy of the final global model may be degraded due to the lack of information from these clients. \u2022 Data: the data held by different devices are often not identically and independently distributed (Non-IID), also known as statistical heterogeneity in FL [24,34]. \u2022 Model: if all clients join FL, the capacity of the trained homogeneous models must match the weakest client's system configurations. Unfortunately, training models with a small capacity not only reduces their performance but also wastes high-end clients' system resources due to long idle time.\n\nAlthough model-heterogeneous FL approaches have emerged to address the aforementioned challenges facing model-homogeneous FL, they still have the following limitations. During learning, the high-level design intuition is to separate the training of the homogeneous portion and the heterogeneous portion of the FL model structure into unrelated processes. This not only results in limited performance improvement but also incurs high computation and communication costs [21,33,38]. In addition, some approaches even rely on the availability of suitable public datasets closely related to the learning task in order to leverage knowledge distillation to achieve model-heterogeneous FL [19,22]. However, this is not always viable in practice. Therefore, enabling FL clients to train heterogeneous FL models with the capacity adaptive to system resource limitations and diverse data distributions in an efficient manner remains open.\n\nTo bridge the aforementioned gaps in the model-heterogeneous FL literature, we propose the Federated Global prediction Header (FedGH) approach. It is a novel model-heterogeneous FL framework capable of achieving low communication and computation costs. Under FedGH, each client's local model consists of a heterogeneous feature extractor and a homogeneous prediction header. It leverages the representations extracted by clients' feature extractors to train a global generalized prediction header at the server for all clients to share. The updated global header captures all-class knowledge among multiple clients. The generalized global prediction header replaces each client's local prediction header to transfer global knowledge to clients. In this way, FedGH enables information interaction across heterogeneous clients' models through a shared generalized global prediction header.\n\nBy communicating only the representations and the global prediction header's parameters between clients and the server, FedGH reduces communication costs. By computing local class-averaged representations on FL clients, it reduces computational costs to a level tolerable for mobile edge devices. By not relying on a public dataset, its operation is not limited by the availability of such datasets. By only sending representations which are high-level abstractions of local data, it protects data privacy. We prove the nonconvex convergence rate of FedGH. Extensive experiments on two real-world datasets demonstrate that FedGH achieves significantly more advantageous performance in both model-homogeneous and -heterogeneous FL scenarios compared to seven state-of-the-art personalized FL models, beating the best-performing baseline by up to 8.87% (for model-homogeneous FL) and 1.83% (for modelheterogeneous FL) in terms of average test accuracy, while saving up to 85.53% of communication overhead.\n\n\n"}, {"paperid": "paper5", "title": "Towards Personalized Federated Learning via Heterogeneous Model Reassembly", "abstract": "This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner.", "introduction": "\n\nFederated learning (FL) aims to enable collaborative machine learning without the need to share clients' data with others, thereby upholding data privacy [1][2][3].However, traditional federated learning approaches [2,[4][5][6][7][8][9][10][11][12] typically enforce the use of an identical model structure for all clients during training.This constraint poses challenges in achieving personalized learning within the FL framework.In real-world scenarios, clients such as data centers, institutes, or companies often possess their own distinct models, which may have varying structures.Training on top of their original models should be a better solution than deploying new ones for collaborative purposes.Therefore, a practical solution lies in fostering heterogeneous model cooperation within FL, while preserving individual model structures.Only a few studies have attempted to address the challenging problem of heterogeneous model cooperation in FL [13][14][15][16][17], and most of them incorporate the use of a public dataset to facilitate both cooperation and personalization [14][15][16][17].However, these approaches still face several key issues:\n\n\u2022 Undermining personalization through consensus: Existing methods often generate consensual side information, such as class information [14], logits [15,18], and label-wise representations [19], using public data.This information is then exchanged and used to conduct average operations on the server, resulting in a consensus representation.However, this approach poses privacy and security concerns due to the exchange of side information [20].Furthermore, the averaging process \u2022 Excessive reliance on prior knowledge for distillation-based approaches: Distillation-based techniques, such as knowledge distillation (KD), are commonly employed for heterogeneous model aggregation in FL [16,17,21].However, these techniques necessitate the predefinition of a shared model structure based on prior knowledge [17].This shared model is then downloaded to clients to guide their training process.Consequently, handcrafted models can heavily influence local model personalization.Additionally, a fixed shared model structure may be insufficient for effectively guiding personalized learning when dealing with a large number of clients with non-IID data.Thus, it is crucial to explore methods that can automatically and dynamically generate client-specific personalized models as guidance.\n\n\u2022 Sensitivity to the choice of public datasets: Most existing approaches use public data to obtain guidance information, such as logits [15,18] or a shared model [17], for local model personalization.\n\nThe design of these approaches makes public data and model personalization tightly bound together.Thus, they usually choose the public data with the same distribution as the client data.Therefore, using public data with different distributions from client data will cause a significant performance drop in existing models.Figure 1 illustrates the performance variations of different models trained on the SVHN dataset with different public datasets (detailed experimental information can be found in Section 4.4).The figure demonstrates a significant performance drop when using alternative public datasets.Consequently, mitigating the adverse impact of employing diverse public data remains a critical yet practical research challenge in FL.\n\nMotivation & Challenges.In fact, both consensus-based and distillation-based approaches aim to learn aggregated and shared information used as guidance in personalized local model training, which is not an optimal way to achieve personalization.An ideal solution is to generate a personalized model for the corresponding client, which is significantly challenging since the assessable information on the server side can only include the uploaded client models and the public data.To avoid the issue of public data sensitivity, only client models can be used.These constraints motivate us to employ the model reassembly technique [22] to generate models first and then select the most matchable personalized model for a specific client from the generations.\n\nTo this end, we will face several new challenges.(C1) Applying the model reassembly technique will result in many candidates.Thus, the first challenge is how to get the optimal candidates.(C2) The layers of the generated candidates are usually from different client models, and the output dimension size of the first layer may not align with the input dimension size of the second layer, which leads to the necessity of network layer stitching.However, the parameters of the stitched layers are unknown.Therefore, the second challenge is how to learn those unknown parameters in the stitched models.(C3) Even with well-trained stitched models, digging out the best match between a client model and a stitched model remains a big challenge.\n\nOur Approach.To simultaneously tackle all the aforementioned challenges, we present a novel framework called pFedHR, which aims to achieve personalized federated learning and address the issue of heterogeneous model cooperation (as depicted in Figure 2).The pFedHR framework comprises two key updates: the server update and the client update.In particular, to tackle C3, we approach the issue of heterogeneous model personalization from a model-matching optimization perspective on the server side (see Section 3.1.1).To solve this problem, we introduce a novel heterogeneous model reassembly technique in Section 3.1.2to assemble models uploaded from clients, i.e., {w  and diverse model candidates using clustering results.Importantly, all layers in each candidate are derived from the uploaded client models.\n\nPrior to matching the client model with candidates, we perform network layer stitching while maximizing the retention of information from the original client models (Section 3.1.3).To tackle C2, we introduce public data D p to help the finetuning of the stitched candidates, i.e., {c 1 t , \u2022 \u2022 \u2022 , cM t }, where M is the number of generated candidates.Specifically, we employ labeled OR unlabeled public data to fine-tune the stitched and client models and then calculate similarities based on model outputs.Intuitively, if two models are highly related to each other, their outputs should also be similar.Therefore, we select the candidate with the highest similarity as the personalized model of the corresponding client, which results in matched pairs 2. In the client update (Section 3.2), we treat the matched personalized model as a guidance mechanism for client parameter learning using knowledge distillation 3 .\n{{w 1 t , ci t }, \u2022 \u2022 \u2022 , {w B t , cm t }} in Figure\nIt is worth noting that we minimally use public data during our model learning to reduce their adverse impact.In our model design, the public data are used for clustering layers, fine-tuning the stitched candidates, and guiding model matching.Clustering and matching stages use public data to obtain the feedforward outputs as guidance and do not involve model parameter updates.Only in the fine-tuning stage, the stitched models' parameters will be updated based on public data.To reduce its impact as much as possible, we limit the number of finetuning epochs during the model implementation.Although we cannot thoroughly break the tie between model training and public data, such a design at least greatly alleviates the problem of public data sensitivity in FL.\n\nContributions.Our work makes the following key contributions: (1) We introduce the first personalized federated learning framework based on model reassembly, specifically designed to address the challenges of heterogeneous model cooperation.(2) The proposed pFedHR framework demonstrates the ability to automatically and dynamically generate personalized candidates that are both informative and diverse, requiring minimal human intervention.(3) We present a novel heterogeneous model reassembly technique, which effectively mitigates the adverse impact caused by using public data with distributions different from client data.( 4) Experimental results show that the pFedHR framework achieves state-of-the-art performance on three datasets, exhibiting superior performance under both IID and Non-IID settings when compared to baselines employing labeled and unlabeled public datasets.\n\n\n"}]