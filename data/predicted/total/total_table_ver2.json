{
    "gold": [
        {
            "id": 0,
            "tab_id": "b42af37c-c83f-4cc0-8cc8-e7221c6a8d0f",
            "table": {
                "Dataset": {
                    "9136312": [
                        "KoNViD-1k "
                    ],
                    "52285071": [
                        "LIVE-VQC "
                    ],
                    "119309258": [
                        "YouTube-UGC "
                    ],
                    "227210156": [
                        "LSVQ "
                    ],
                    "234788066": [
                        "KoNViD-150k "
                    ],
                    "206592218": [
                        "Sports-1M "
                    ],
                    "27300853": [
                        "Kinetics-400 "
                    ]
                },
                "Task": {
                    "9136312": [
                        "VQA"
                    ],
                    "52285071": [
                        "VQA"
                    ],
                    "119309258": [
                        "VQA"
                    ],
                    "227210156": [
                        "VQA"
                    ],
                    "234788066": [
                        "VQA"
                    ],
                    "206592218": [
                        "classification"
                    ],
                    "27300853": [
                        "classification"
                    ]
                },
                "Size": {
                    "9136312": [
                        "1,200"
                    ],
                    "52285071": [
                        "585"
                    ],
                    "119309258": [
                        "1,380"
                    ],
                    "227210156": [
                        "39,075"
                    ],
                    "234788066": [
                        "153,841"
                    ],
                    "206592218": [
                        "1,133,158"
                    ],
                    "27300853": [
                        "306,245"
                    ]
                },
                "Annotations": {
                    "9136312": [
                        "114"
                    ],
                    "52285071": [
                        "240"
                    ],
                    "119309258": [
                        "123"
                    ],
                    "227210156": [
                        "35"
                    ],
                    "234788066": [
                        "5"
                    ],
                    "206592218": [
                        "- (auto.)"
                    ],
                    "27300853": [
                        "3-5"
                    ]
                }
            }
        },
        {
            "id": 1,
            "tab_id": "da17cb75-5655-4f95-bffc-c918a7ecb473",
            "table": {
                "Attack": {
                    "233481695": [
                        "IPatch "
                    ],
                    "237048246": [
                        "SSAttack "
                    ]
                },
                "Attacker's Knowledge": {
                    "233481695": [
                        "White-box"
                    ],
                    "237048246": [
                        "White-box"
                    ]
                },
                "Robustness Technique": {
                    "233481695": [
                        "EOT"
                    ],
                    "237048246": [
                        "EOT"
                    ]
                },
                "Stealthiness Technique": {
                    "233481695": [
                        "-"
                    ],
                    "237048246": [
                        "-"
                    ]
                },
                "Physical test type": {
                    "233481695": [
                        "Static"
                    ],
                    "237048246": [
                        "Static"
                    ]
                },
                "Space": {
                    "233481695": [
                        "2D"
                    ],
                    "237048246": [
                        "2D"
                    ]
                }
            }
        },
        {
            "id": 2,
            "tab_id": "361b11db-c0a0-4286-9b88-15e2b801a181",
            "table": {
                "Methods": {
                    "246705967": [
                        "InPairs"
                    ],
                    "252519173": [
                        "PROMPTAGATOR"
                    ],
                    "257405222": [
                        "TQGen"
                    ],
                    "257279774": [
                        "UDAPDR"
                    ],
                    "259937100": [
                        "SPTAR"
                    ],
                    "249926985": [
                        "ART"
                    ]
                },
                "# Examples": {
                    "246705967": [
                        "3"
                    ],
                    "252519173": [
                        "0-8"
                    ],
                    "257405222": [
                        "0"
                    ],
                    "257279774": [
                        "0-3"
                    ],
                    "259937100": [
                        "1-2"
                    ],
                    "249926985": [
                        "0"
                    ]
                },
                "Generator": {
                    "246705967": [
                        "Curie"
                    ],
                    "252519173": [
                        "FLAN"
                    ],
                    "257405222": [
                        "T0"
                    ],
                    "257279774": [
                        "GPT3 & FLAN-T5-XXL"
                    ],
                    "259937100": [
                        "LLaMA-7B & Vicuna-7B"
                    ],
                    "249926985": [
                        "T5-XL & T5-XXL"
                    ]
                },
                "Synthetic Data": {
                    "246705967": [
                        "Relevant query"
                    ],
                    "252519173": [
                        "Relevant query"
                    ],
                    "257405222": [
                        "Relevant query"
                    ],
                    "257279774": [
                        "Relevant query"
                    ],
                    "259937100": [
                        "Relevant query"
                    ],
                    "249926985": [
                        "Soft relevance labels"
                    ]
                },
                "Filter Method": {
                    "246705967": [
                        "Generation probability"
                    ],
                    "252519173": [
                        "Round-trip filtering"
                    ],
                    "257405222": [
                        "Generation probability"
                    ],
                    "257279774": [
                        "Round-trip filtering"
                    ],
                    "259937100": [
                        "BM25 filtering"
                    ],
                    "249926985": [
                        "-"
                    ]
                },
                "LLMs' tuning": {
                    "246705967": [
                        "Fixed"
                    ],
                    "252519173": [
                        "Fixed"
                    ],
                    "257405222": [
                        "Fixed"
                    ],
                    "257279774": [
                        "Fixed"
                    ],
                    "259937100": [
                        "Soft Prompt tuning"
                    ],
                    "249926985": [
                        "Fixed"
                    ]
                }
            }
        },
        {
            "id": 3,
            "tab_id": "ff0a2460-7c6f-409b-8f91-30d45d25268d",
            "table": {
                "Methods": {
                    "246275593": [
                        "cpt-text "
                    ],
                    "245144556": [
                        "GTR "
                    ],
                    "253581733": [
                        "TART "
                    ],
                    "246863488": [
                        "DSI "
                    ],
                    "258714822": [
                        "LLM-URL "
                    ]
                },
                "Backbone": {
                    "246275593": [
                        "cpt-text"
                    ],
                    "245144556": [
                        "T5"
                    ],
                    "253581733": [
                        "T5"
                    ],
                    "246863488": [
                        "T5"
                    ],
                    "258714822": [
                        "GPT-3"
                    ]
                },
                "Architecture": {
                    "246275593": [
                        "Encoder-based"
                    ],
                    "245144556": [
                        "Encoder-based"
                    ],
                    "253581733": [
                        "Encoder-based"
                    ],
                    "246863488": [
                        "Generative"
                    ],
                    "258714822": [
                        "Generative"
                    ]
                },
                "LLM's tuning": {
                    "246275593": [
                        "Training from scratch"
                    ],
                    "245144556": [
                        "Fine-tuning"
                    ],
                    "253581733": [
                        "Fine-tuning & Prompting"
                    ],
                    "246863488": [
                        "Fine-tuning"
                    ],
                    "258714822": [
                        "Prompting"
                    ]
                }
            }
        },
        {
            "id": 4,
            "tab_id": "f83bb26c-2ea8-4a4f-b121-f69e4ebe9619",
            "table": {
                "Methods": {
                    "211204736": [
                        "REALM"
                    ],
                    "218869575": [
                        "RAG"
                    ],
                    "256389797": [
                        "REPLUG"
                    ],
                    "251371732": [
                        "Atlas"
                    ],
                    "247362809": [
                        "-"
                    ],
                    "255372320": [
                        "-"
                    ],
                    "259108339": [
                        "RETA-LLM"
                    ],
                    "256459451": [
                        "RALM"
                    ],
                    "244954723": [
                        "RETRO"
                    ],
                    "254877499": [
                        "IRCoT"
                    ],
                    "258615731": [
                        "FLARE"
                    ]
                },
                "Backbone models": {
                    "211204736": [
                        "BERT"
                    ],
                    "218869575": [
                        "BART"
                    ],
                    "256389797": [
                        "GPT"
                    ],
                    "251371732": [
                        "T5"
                    ],
                    "247362809": [
                        "Gopher"
                    ],
                    "255372320": [
                        "GPT"
                    ],
                    "259108339": [
                        "LLaMA & GLM & GPT"
                    ],
                    "256459451": [
                        "LLaMA & OPT & GPT"
                    ],
                    "244954723": [
                        "Transformer"
                    ],
                    "254877499": [
                        "Flan-T5 & GPT"
                    ],
                    "258615731": [
                        "GPT"
                    ]
                },
                "Where to incorporate retrieval": {
                    "211204736": [
                        "Input layer"
                    ],
                    "218869575": [
                        "Input layer"
                    ],
                    "256389797": [
                        "Input layer"
                    ],
                    "251371732": [
                        "Input layer"
                    ],
                    "247362809": [
                        "Input layer"
                    ],
                    "255372320": [
                        "Input layer"
                    ],
                    "259108339": [
                        "Input layer"
                    ],
                    "256459451": [
                        "Input layer"
                    ],
                    "244954723": [
                        "Attention layer"
                    ],
                    "254877499": [
                        "Input layer"
                    ],
                    "258615731": [
                        "Input layer"
                    ]
                },
                "When to retrieve": {
                    "211204736": [
                        "In the beginning"
                    ],
                    "218869575": [
                        "In the beginning"
                    ],
                    "256389797": [
                        "In the beginning"
                    ],
                    "251371732": [
                        "In the beginning"
                    ],
                    "247362809": [
                        "In the beginning"
                    ],
                    "255372320": [
                        "In the beginning"
                    ],
                    "259108339": [
                        "In the beginning"
                    ],
                    "256459451": [
                        "During generation (every n tokens)"
                    ],
                    "244954723": [
                        "During generation (every n tokens)"
                    ],
                    "254877499": [
                        "During generation (every sentence)"
                    ],
                    "258615731": [
                        "During generation (aperiodic)"
                    ]
                },
                "How to use LLMs": {
                    "211204736": [
                        "Fine-tuning"
                    ],
                    "218869575": [
                        "Fine-tuning"
                    ],
                    "256389797": [
                        "Fine-tuning"
                    ],
                    "251371732": [
                        "Fine-tuning"
                    ],
                    "247362809": [
                        "Prompting"
                    ],
                    "255372320": [
                        "Prompting"
                    ],
                    "259108339": [
                        "Prompting"
                    ],
                    "256459451": [
                        "Prompting"
                    ],
                    "244954723": [
                        "Training from scratch"
                    ],
                    "254877499": [
                        "Prompting"
                    ],
                    "258615731": [
                        "Prompting"
                    ]
                }
            }
        },
        {
            "id": 5,
            "tab_id": "d63d3952-e30a-4a05-8415-b13226eff27e",
            "table": {
                "Benchmark": {
                    "208617407": [
                        "Alfred"
                    ],
                    "212644876": [
                        "MQA"
                    ],
                    "244908821": [
                        "Calvin"
                    ],
                    "227232796": [
                        "M-EQA"
                    ],
                    "225076003": [
                        "Ravens"
                    ],
                    "249848175": [
                        "Vlmbench"
                    ],
                    "251903958": [
                        "CH-MARL"
                    ],
                    "109933186": [
                        "TBP "
                    ],
                    "248941435": [
                        "EMATP"
                    ],
                    "260378734": [
                        "LEMMA"
                    ]
                },
                "Language": {
                    "208617407": [
                        "\u2713"
                    ],
                    "212644876": [
                        "\u2713"
                    ],
                    "244908821": [
                        "\u2713"
                    ],
                    "227232796": [
                        "\u2713"
                    ],
                    "225076003": [
                        "\u2717"
                    ],
                    "249848175": [
                        "\u2713"
                    ],
                    "251903958": [
                        "\u2713"
                    ],
                    "109933186": [
                        "\u2717"
                    ],
                    "248941435": [
                        "\u2713"
                    ],
                    "260378734": [
                        "\u2713"
                    ]
                },
                "Multi-task": {
                    "208617407": [
                        "\u2713"
                    ],
                    "212644876": [
                        "\u2713"
                    ],
                    "244908821": [
                        "\u2713"
                    ],
                    "227232796": [
                        "\u2713"
                    ],
                    "225076003": [
                        "\u2717"
                    ],
                    "249848175": [
                        "\u2717"
                    ],
                    "251903958": [
                        "\u2717"
                    ],
                    "109933186": [
                        "\u2717"
                    ],
                    "248941435": [
                        "\u2713"
                    ],
                    "260378734": [
                        "\u2713"
                    ]
                },
                "Manipulation": {
                    "208617407": [
                        "\u2717"
                    ],
                    "212644876": [
                        "\u2713"
                    ],
                    "244908821": [
                        "\u2713"
                    ],
                    "227232796": [
                        "\u2717"
                    ],
                    "225076003": [
                        "\u2713"
                    ],
                    "249848175": [
                        "\u2713"
                    ],
                    "251903958": [
                        "\u2717"
                    ],
                    "109933186": [
                        "\u2717"
                    ],
                    "248941435": [
                        "\u2717"
                    ],
                    "260378734": [
                        "\u2713"
                    ]
                },
                "Multi-agent": {
                    "208617407": [
                        "\u2717"
                    ],
                    "212644876": [
                        "\u2717"
                    ],
                    "244908821": [
                        "\u2717"
                    ],
                    "227232796": [
                        "\u2713"
                    ],
                    "225076003": [
                        "\u2717"
                    ],
                    "249848175": [
                        "\u2717"
                    ],
                    "251903958": [
                        "\u2713"
                    ],
                    "109933186": [
                        "\u2713"
                    ],
                    "248941435": [
                        "\u2713"
                    ],
                    "260378734": [
                        "\u2713"
                    ]
                },
                "Tool Use": {
                    "208617407": [
                        "\u2713"
                    ],
                    "212644876": [
                        "\u2717"
                    ],
                    "244908821": [
                        "\u2717"
                    ],
                    "227232796": [
                        "\u2717"
                    ],
                    "225076003": [
                        "\u2717"
                    ],
                    "249848175": [
                        "\u2717"
                    ],
                    "251903958": [
                        "\u2717"
                    ],
                    "109933186": [
                        "\u2717"
                    ],
                    "248941435": [
                        "\u2713"
                    ],
                    "260378734": [
                        "\u2713"
                    ]
                },
                "Temporal Dep.": {
                    "208617407": [
                        "\u2713"
                    ],
                    "212644876": [
                        "\u2717"
                    ],
                    "244908821": [
                        "\u2717"
                    ],
                    "227232796": [
                        "\u2717"
                    ],
                    "225076003": [
                        "\u2717"
                    ],
                    "249848175": [
                        "\u2717"
                    ],
                    "251903958": [
                        "\u2717"
                    ],
                    "109933186": [
                        "\u2717"
                    ],
                    "248941435": [
                        "\u2713"
                    ],
                    "260378734": [
                        "\u2713"
                    ]
                }
            }
        },
        {
            "id": 6,
            "tab_id": "d3b56d4e-6535-4c7e-a634-dae53c7aa8f5",
            "table": {
                "Year": {
                    "218772411": [
                        "2020"
                    ],
                    "221912722": [
                        "2020"
                    ],
                    "232333726": [
                        "2021"
                    ],
                    "237556679": [
                        "2021"
                    ],
                    "232055058": [
                        "2021"
                    ],
                    "235333227": [
                        "2021"
                    ]
                },
                "Problem-Task": {
                    "218772411": [
                        "AMR"
                    ],
                    "221912722": [
                        "mortality"
                    ],
                    "232333726": [
                        "COVID-19 severity"
                    ],
                    "237556679": [
                        "phenotyping"
                    ],
                    "232055058": [
                        "macular degeneration"
                    ],
                    "235333227": [
                        "mortality"
                    ]
                },
                "Problem-Model": {
                    "218772411": [
                        "regression"
                    ],
                    "221912722": [
                        "neural network"
                    ],
                    "232333726": [
                        "regression"
                    ],
                    "237556679": [
                        "neural network"
                    ],
                    "232055058": [
                        "neural network"
                    ],
                    "235333227": [
                        "neural network"
                    ]
                },
                "Dataset-Size": {
                    "218772411": [
                        "1,595"
                    ],
                    "221912722": [
                        "7,803"
                    ],
                    "232333726": [
                        "12,965"
                    ],
                    "237556679": [
                        "11,214"
                    ],
                    "232055058": [
                        "32,215"
                    ],
                    "235333227": [
                        "3,431"
                    ]
                },
                "XAI-Method": {
                    "218772411": [
                        "inherent"
                    ],
                    "221912722": [
                        "LIME"
                    ],
                    "232333726": [
                        "inherent"
                    ],
                    "237556679": [
                        "inherent"
                    ],
                    "232055058": [
                        "LIME"
                    ],
                    "235333227": [
                        "inherent"
                    ]
                },
                "XAI-C.V.": {
                    "218772411": [
                        "\u2713"
                    ],
                    "221912722": [
                        "\u2717"
                    ],
                    "232333726": [
                        "\u2713"
                    ],
                    "237556679": [
                        "\u2717"
                    ],
                    "232055058": [
                        "\u2717"
                    ],
                    "235333227": [
                        "\u2717"
                    ]
                },
                "XAI-Q.E.": {
                    "218772411": [
                        "\u2713"
                    ],
                    "221912722": [
                        "\u2713"
                    ],
                    "232333726": [
                        "\u2713"
                    ],
                    "237556679": [
                        "\u2717"
                    ],
                    "232055058": [
                        "\u2717"
                    ],
                    "235333227": [
                        "\u2717"
                    ]
                },
                "XAI-O.A.": {
                    "218772411": [
                        "\u2713"
                    ],
                    "221912722": [
                        "\u2717"
                    ],
                    "232333726": [
                        "\u2717"
                    ],
                    "237556679": [
                        "\u2713"
                    ],
                    "232055058": [
                        "\u2713"
                    ],
                    "235333227": [
                        "\u2713"
                    ]
                }
            }
        },
        {
            "id": 7,
            "tab_id": "b9e280ca-7a97-4486-b953-059737120e77",
            "table": {
                "Framework": {
                    "233444275": [
                        "MQM "
                    ],
                    "233407441": [
                        "FRANK "
                    ],
                    "248887364": [
                        "SNaC "
                    ],
                    "247315430": [
                        "Scarecrow "
                    ],
                    "258865481": [
                        "SALSA "
                    ],
                    "12122749": [
                        "ERRANT "
                    ],
                    "259064099": [
                        "FG-RLHF "
                    ],
                    "252762392": [
                        "MultiPIT "
                    ],
                    "218974555": [
                        "CWZCC "
                    ],
                    "202788575": [
                        "Propaganda "
                    ],
                    "253157749": [
                        "arXivEdits "
                    ]
                },
                "Task": {
                    "233444275": [
                        "Translation"
                    ],
                    "233407441": [
                        "Summarization"
                    ],
                    "248887364": [
                        "Narrative Summarization"
                    ],
                    "247315430": [
                        "Open-ended Generation"
                    ],
                    "258865481": [
                        "Simplification"
                    ],
                    "12122749": [
                        "Grammar Error Correction"
                    ],
                    "259064099": [
                        "Fine-Grained RLHF"
                    ],
                    "252762392": [
                        "Paraphrase Generation"
                    ],
                    "218974555": [
                        "Zamboanga Chavacano Spell Checking"
                    ],
                    "202788575": [
                        "Propaganda Analysis"
                    ],
                    "253157749": [
                        "Scientific Text Revision"
                    ]
                },
                "Released": {
                    "233444275": [
                        "\u2713"
                    ],
                    "233407441": [
                        "\u2713"
                    ],
                    "248887364": [
                        "\u2713"
                    ],
                    "247315430": [
                        "\u2713"
                    ],
                    "258865481": [
                        "\u2713"
                    ],
                    "12122749": [
                        "\u2717"
                    ],
                    "259064099": [
                        "\u2713"
                    ],
                    "252762392": [
                        "\u2717"
                    ],
                    "218974555": [
                        "\u2717"
                    ],
                    "202788575": [
                        "\u2713"
                    ],
                    "253157749": [
                        "\u2713"
                    ]
                },
                "Link": {
                    "233444275": [
                        "thresh.tools/mqm"
                    ],
                    "233407441": [
                        "thresh.tools/frank"
                    ],
                    "248887364": [
                        "thresh.tools/snac"
                    ],
                    "247315430": [
                        "thresh.tools/scarecrow"
                    ],
                    "258865481": [
                        "thresh.tools/salsa"
                    ],
                    "12122749": [
                        "thresh.tools/errant"
                    ],
                    "259064099": [
                        "thresh.tools/fg-rlhf"
                    ],
                    "252762392": [
                        "thresh.tools/multipit"
                    ],
                    "218974555": [
                        "thresh.tools/cwzcc"
                    ],
                    "202788575": [
                        "thresh.tools/propaganda"
                    ],
                    "253157749": [
                        "thresh.tools/arxivedits"
                    ]
                }
            }
        },
        {
            "id": 8,
            "tab_id": "d94c8049-6696-4812-b3dc-1da0df7ffaee",
            "table": {
                "Dataset": {
                    "218862749": [
                        "Lenove "
                    ],
                    "216867120": [
                        "Reddit "
                    ],
                    "61955135": [
                        "ABSA "
                    ],
                    "221703022": [
                        "MEPAVE "
                    ],
                    "247292113": [
                        "Multi-CPR "
                    ],
                    "260887693": [
                        "OpenBG https://github.com/OpenBGBenchmark"
                    ]
                },
                "Lang.": {
                    "218862749": [
                        "EN"
                    ],
                    "216867120": [
                        "EN"
                    ],
                    "61955135": [
                        "EN"
                    ],
                    "221703022": [
                        "ZH"
                    ],
                    "247292113": [
                        "ZH"
                    ],
                    "260887693": [
                        "ZH"
                    ]
                },
                "Task": {
                    "218862749": [
                        "Named Entity Recognization",
                        "Entity Span Detection"
                    ],
                    "216867120": [
                        "Extractive QA"
                    ],
                    "61955135": [
                        "Review Topic Classification"
                    ],
                    "221703022": [
                        "Attribute Value Recognization",
                        "Attribute Value Detection"
                    ],
                    "247292113": [
                        "Product Select"
                    ],
                    "260887693": [
                        "Product Align",
                        "Title Attritube Matching",
                        "Fine-grain Product Classify",
                        "Coarse-grain Product Classify",
                        "Title Generate"
                    ]
                },
                "Metric": {
                    "218862749": [
                        "F1, Rouge",
                        "Rouge"
                    ],
                    "216867120": [
                        "Rouge"
                    ],
                    "61955135": [
                        "F1, Rouge"
                    ],
                    "221703022": [
                        "F1, Rouge",
                        "Rouge"
                    ],
                    "247292113": [
                        "Rouge"
                    ],
                    "260887693": [
                        "F1, Rouge",
                        "F1, Rouge",
                        "F1, Rouge",
                        "F1, Rouge",
                        "Rouge"
                    ]
                }
            }
        },
        {
            "id": 9,
            "tab_id": "3f8046c8-4fd5-40aa-a10f-b06c1fdfb796",
            "table": {
                "Dataset": {
                    "258987676": [
                        "StylePrompt "
                    ],
                    "256416291": [
                        "NLSpeech "
                    ],
                    "253761189": [
                        "PromptSpeech "
                    ],
                    "261242529": [
                        "TextrolSpeech"
                    ]
                },
                "Open source": {
                    "258987676": [
                        "no"
                    ],
                    "256416291": [
                        "no"
                    ],
                    "253761189": [
                        "yes (part)"
                    ],
                    "261242529": [
                        "yes"
                    ]
                },
                "Hours": {
                    "258987676": [
                        "12"
                    ],
                    "256416291": [
                        "44"
                    ],
                    "253761189": [
                        "-"
                    ],
                    "261242529": [
                        "330"
                    ]
                },
                "Text items": {
                    "258987676": [
                        "-"
                    ],
                    "256416291": [
                        "32000"
                    ],
                    "253761189": [
                        "27893"
                    ],
                    "261242529": [
                        "236220"
                    ]
                },
                "Prompt diversity": {
                    "258987676": [
                        "-"
                    ],
                    "256416291": [
                        "-"
                    ],
                    "253761189": [
                        "5"
                    ],
                    "261242529": [
                        "500"
                    ]
                },
                "Speaker": {
                    "258987676": [
                        "8"
                    ],
                    "256416291": [
                        "7"
                    ],
                    "253761189": [
                        "-"
                    ],
                    "261242529": [
                        "1324"
                    ]
                },
                "Emotion": {
                    "258987676": [
                        "-"
                    ],
                    "256416291": [
                        "yes"
                    ],
                    "253761189": [
                        "no"
                    ],
                    "261242529": [
                        "yes"
                    ]
                }
            }
        },
        {
            "id": 10,
            "tab_id": "8b29f176-220d-4c3a-aecd-3ec67a6fb864",
            "table": {
                "Method": {
                    "227209266": [
                        "NP"
                    ],
                    "252735231": [
                        "CAP"
                    ],
                    "261242415": [
                        "Ours"
                    ]
                },
                "Open surface": {
                    "227209266": [
                        "No"
                    ],
                    "252735231": [
                        "Yes"
                    ],
                    "261242415": [
                        "Yes"
                    ]
                },
                "Inference Time": {
                    "227209266": [
                        "29min22s"
                    ],
                    "252735231": [
                        "21min56s"
                    ],
                    "261242415": [
                        "9s"
                    ]
                },
                "Sparse Input": {
                    "227209266": [
                        "Hard"
                    ],
                    "252735231": [
                        "Hard"
                    ],
                    "261242415": [
                        "Easy"
                    ]
                }
            }
        },
        {
            "id": 11,
            "tab_id": "5ac6483b-03ae-448e-a80a-b453d252023b",
            "table": {
                "Technology": {
                    "257801039": [
                        "IRS-assisted V2I"
                    ],
                    "255658077": [
                        "General applications"
                    ],
                    "255080909": [
                        "IRS-assisted ISAC MISO"
                    ]
                },
                "AI technique": {
                    "257801039": [
                        "DL"
                    ],
                    "255658077": [
                        "DL"
                    ],
                    "255080909": [
                        "DL"
                    ]
                },
                "Criteria": {
                    "257801039": [
                        "CAP-Net (conv layers and LSTM)"
                    ],
                    "255658077": [
                        "CNN (Trained as a denoiser)"
                    ],
                    "255080909": [
                        "1.Direct estimation CNN (DE-CNN)2.Reflected estimation CNN (RE-CNN)"
                    ]
                },
                "Input": {
                    "257801039": [
                        "Historical covariance of the received echo"
                    ],
                    "255658077": [
                        "Channel estimated by LS method"
                    ],
                    "255080909": [
                        "1.Received direct signals2.Total received signals and DE-CNN estimation"
                    ]
                },
                "Output": {
                    "257801039": [
                        "AoAs"
                    ],
                    "255658077": [
                        "Channel estimation"
                    ],
                    "255080909": [
                        "Direct (DE-CNN) and reflected (RE-CNN) sensing and communication channels"
                    ]
                }
            }
        },
        {
            "id": 12,
            "tab_id": "488bdd5f-7ba5-4295-8895-aa0a0b67a1ab",
            "table": {
                "Method": {
                    "4001553": [
                        "EWS "
                    ],
                    "237583501": [
                        "Bury et al. "
                    ],
                    "250243662": [
                        "Patel and Ott "
                    ],
                    "261030871": [
                        "Ours"
                    ]
                },
                "Generality": {
                    "4001553": [
                        "\u2718"
                    ],
                    "237583501": [
                        "\u2718"
                    ],
                    "250243662": [
                        "\u2714"
                    ],
                    "261030871": [
                        "\u2714"
                    ]
                },
                "Function space": {
                    "4001553": [
                        "\u2718"
                    ],
                    "237583501": [
                        "\u2718"
                    ],
                    "250243662": [
                        "\u2718"
                    ],
                    "261030871": [
                        "\u2714"
                    ]
                },
                "Partial physics": {
                    "4001553": [
                        "-"
                    ],
                    "237583501": [
                        "-"
                    ],
                    "250243662": [
                        "-"
                    ],
                    "261030871": [
                        "\u2714"
                    ]
                },
                "Speed": {
                    "4001553": [
                        "\u2714"
                    ],
                    "237583501": [
                        "\u2714"
                    ],
                    "250243662": [
                        "\u2714"
                    ],
                    "261030871": [
                        "\u2714"
                    ]
                },
                "Pre-tip data": {
                    "4001553": [
                        "\u2714"
                    ],
                    "237583501": [
                        "\u2718"
                    ],
                    "250243662": [
                        "\u2718"
                    ],
                    "261030871": [
                        "\u2714"
                    ]
                }
            }
        },
        {
            "id": 13,
            "tab_id": "8b1d0c59-2fa6-45b3-9b45-291056ee3725",
            "table": {
                "Reference": {
                    "16944951": [
                        "[c]Openmili "
                    ],
                    "211198441": [
                        "[c]M 3  "
                    ],
                    "218569273": [
                        "[c]mm-Flex "
                    ],
                    "53095465": [
                        "[c]"
                    ],
                    "6601027": [
                        "[c]Soli "
                    ]
                },
                "Baseband BW": {
                    "16944951": [
                        "1 GHz"
                    ],
                    "211198441": [
                        "4 GHz"
                    ],
                    "218569273": [
                        "2 GHz"
                    ],
                    "53095465": [
                        "450 MHz"
                    ],
                    "6601027": [
                        "7 GHz"
                    ]
                },
                "Carries Freq.": {
                    "16944951": [
                        "57 \u223c 64 GHz"
                    ],
                    "211198441": [
                        "60 GHz"
                    ],
                    "218569273": [
                        "60 GHz"
                    ],
                    "53095465": [
                        "24 GHz"
                    ],
                    "6601027": [
                        "60 GHz"
                    ]
                },
                "Antenna": {
                    "16944951": [
                        "Horn/Phased-array"
                    ],
                    "211198441": [
                        "Phased-array"
                    ],
                    "218569273": [
                        "Phased-antenna"
                    ],
                    "53095465": [
                        "Array"
                    ],
                    "6601027": [
                        "Array"
                    ]
                },
                "Cost": {
                    "16944951": [
                        "$15K"
                    ],
                    "211198441": [
                        "below $15K"
                    ],
                    "218569273": [
                        "$40K"
                    ],
                    "53095465": [
                        "below $100"
                    ],
                    "6601027": [
                        "-"
                    ]
                }
            }
        },
        {
            "id": 14,
            "tab_id": "20317c3b-01c9-4813-9868-1b7139fc7c74",
            "table": {
                "Method": {
                    "54475412": [
                        "SiamMask "
                    ],
                    "208175650": [
                        "D3S "
                    ],
                    "208512936": [
                        "SiamR-CNN "
                    ],
                    "235732286": [
                        "UniTrack "
                    ],
                    "250526428": [
                        "Unicorn "
                    ],
                    "247593925": [
                        "RTS "
                    ],
                    "261214723": [
                        "MITS (Ours)"
                    ]
                },
                "Initialization-Box": {
                    "54475412": [
                        "\u2713"
                    ],
                    "208175650": [
                        "\u2713"
                    ],
                    "208512936": [
                        "\u2713"
                    ],
                    "235732286": [
                        "\u2713"
                    ],
                    "250526428": [
                        "\u2713"
                    ],
                    "247593925": [
                        "\u2717"
                    ],
                    "261214723": [
                        "\u2713"
                    ]
                },
                "Initialization-Mask": {
                    "54475412": [
                        "\u2717"
                    ],
                    "208175650": [
                        "\u2713"
                    ],
                    "208512936": [
                        "\u2717"
                    ],
                    "235732286": [
                        "\u2713"
                    ],
                    "250526428": [
                        "\u2713"
                    ],
                    "247593925": [
                        "\u2713"
                    ],
                    "261214723": [
                        "\u2713"
                    ]
                },
                "Prediction-Box": {
                    "54475412": [
                        "\u2713"
                    ],
                    "208175650": [
                        "\u2717"
                    ],
                    "208512936": [
                        "\u2713"
                    ],
                    "235732286": [
                        "\u2713"
                    ],
                    "250526428": [
                        "\u2713"
                    ],
                    "247593925": [
                        "\u2717"
                    ],
                    "261214723": [
                        "\u2713"
                    ]
                },
                "Prediction-Mask": {
                    "54475412": [
                        "\u2713"
                    ],
                    "208175650": [
                        "\u2713"
                    ],
                    "208512936": [
                        "\u2717"
                    ],
                    "235732286": [
                        "\u2713"
                    ],
                    "250526428": [
                        "\u2713"
                    ],
                    "247593925": [
                        "\u2713"
                    ],
                    "261214723": [
                        "\u2713"
                    ]
                },
                "Extra Model": {
                    "54475412": [
                        "-"
                    ],
                    "208175650": [
                        "-"
                    ],
                    "208512936": [
                        "Box2Seg {{cite:4dd3024}}"
                    ],
                    "235732286": [
                        "-"
                    ],
                    "250526428": [
                        "-"
                    ],
                    "247593925": [
                        "STA {{cite:9e8cd2a}}"
                    ],
                    "261214723": [
                        "-"
                    ]
                },
                "Multi-Object": {
                    "54475412": [
                        "\u2717"
                    ],
                    "208175650": [
                        "\u2717"
                    ],
                    "208512936": [
                        "\u2717"
                    ],
                    "235732286": [
                        "\u2717"
                    ],
                    "250526428": [
                        "\u2717"
                    ],
                    "247593925": [
                        "\u2717"
                    ],
                    "261214723": [
                        "\u2713"
                    ]
                }
            }
        },
        {
            "id": 15,
            "tab_id": "a9d669ae-0620-464b-addf-d5c677d93c1e",
            "table": {
                "Approach": {
                    "219636007": [
                        "FedDF"
                    ],
                    "263869520": [
                        "FedKEMF"
                    ],
                    "250210682": [
                        "FCCL "
                    ],
                    "203951869": [
                        "FedMD"
                    ],
                    "257687494": [
                        "FedGH "
                    ],
                    "261031130": [
                        "pFedHR"
                    ]
                },
                "Public Dataset-W. Label": {
                    "219636007": [
                        "\u2717"
                    ],
                    "263869520": [
                        "\u2717"
                    ],
                    "250210682": [
                        "\u2717"
                    ],
                    "203951869": [
                        "\u2713"
                    ],
                    "257687494": [
                        "\u2713"
                    ],
                    "261031130": [
                        "\u2713"
                    ]
                },
                "Public Dataset-W.o. Label": {
                    "219636007": [
                        "\u2713"
                    ],
                    "263869520": [
                        "\u2713"
                    ],
                    "250210682": [
                        "\u2713"
                    ],
                    "203951869": [
                        "\u2717"
                    ],
                    "257687494": [
                        "\u2717"
                    ],
                    "261031130": [
                        "\u2713"
                    ]
                },
                "Model Characteristics-Upload and Download": {
                    "219636007": [
                        "parameters"
                    ],
                    "263869520": [
                        "parameters"
                    ],
                    "250210682": [
                        "logits"
                    ],
                    "203951869": [
                        "class scores"
                    ],
                    "257687494": [
                        "label-wise representations"
                    ],
                    "261031130": [
                        "parameters"
                    ]
                },
                "Model Characteristics-Aggregation": {
                    "219636007": [
                        "ensemble distillation"
                    ],
                    "263869520": [
                        "mutual learning"
                    ],
                    "250210682": [
                        "average"
                    ],
                    "203951869": [
                        "average"
                    ],
                    "257687494": [
                        "average"
                    ],
                    "261031130": [
                        "model reassembly"
                    ]
                },
                "Model Characteristics-Personalization": {
                    "219636007": [
                        "\u2717"
                    ],
                    "263869520": [
                        "\u2713"
                    ],
                    "250210682": [
                        "\u2713"
                    ],
                    "203951869": [
                        "\u2713"
                    ],
                    "257687494": [
                        "\u2713"
                    ],
                    "261031130": [
                        "\u2713"
                    ]
                }
            }
        },
        {
            "id": 16,
            "tab_id": "6840a3c6-7ae9-412f-bed3-78e666859dcf",
            "table": {
                "Dataset": {
                    "202540963": [
                        "FVG "
                    ],
                    "1815453": [
                        "CASIA-B "
                    ],
                    "4633086": [
                        "OU-ISIR "
                    ],
                    "247996921": [
                        "Gait3D "
                    ],
                    "244906176": [
                        "GREW "
                    ],
                    "252263212": [
                        "DenseGait "
                    ],
                    "261049754": [
                        "PsyMo (ours)"
                    ]
                },
                "Type": {
                    "202540963": [
                        "Controlled"
                    ],
                    "1815453": [
                        "Controlled"
                    ],
                    "4633086": [
                        "Controlled"
                    ],
                    "247996921": [
                        "In the Wild"
                    ],
                    "244906176": [
                        "In the Wild"
                    ],
                    "252263212": [
                        "In the Wild"
                    ],
                    "261049754": [
                        "Controlled"
                    ]
                },
                "# IDs": {
                    "202540963": [
                        "226"
                    ],
                    "1815453": [
                        "124"
                    ],
                    "4633086": [
                        "10,307"
                    ],
                    "247996921": [
                        "4,000"
                    ],
                    "244906176": [
                        "26,000"
                    ],
                    "252263212": [
                        "217,954"
                    ],
                    "261049754": [
                        "312"
                    ]
                },
                "# Seq.": {
                    "202540963": [
                        "2,857"
                    ],
                    "1815453": [
                        "13,640"
                    ],
                    "4633086": [
                        "144,298"
                    ],
                    "247996921": [
                        "25,309"
                    ],
                    "244906176": [
                        "128,000"
                    ],
                    "252263212": [
                        "217,954"
                    ],
                    "261049754": [
                        "14,976"
                    ]
                },
                "Variations": {
                    "202540963": [
                        "NM, CL, BG, WS, CBG"
                    ],
                    "1815453": [
                        "NM, CL, BG"
                    ],
                    "4633086": [
                        "-"
                    ],
                    "247996921": [
                        "-"
                    ],
                    "244906176": [
                        "-"
                    ],
                    "252263212": [
                        "-"
                    ],
                    "261049754": [
                        "NM, CL, BG, WSS, WSF, TXT, PH"
                    ]
                },
                "Views": {
                    "202540963": [
                        "3"
                    ],
                    "1815453": [
                        "11"
                    ],
                    "4633086": [
                        "14"
                    ],
                    "247996921": [
                        "-"
                    ],
                    "244906176": [
                        "-"
                    ],
                    "252263212": [
                        "-"
                    ],
                    "261049754": [
                        "6"
                    ]
                },
                "Env.": {
                    "202540963": [
                        "Outdoor"
                    ],
                    "1815453": [
                        "Indoor"
                    ],
                    "4633086": [
                        "Indoor"
                    ],
                    "247996921": [
                        "Indoor"
                    ],
                    "244906176": [
                        "Outdoor"
                    ],
                    "252263212": [
                        "Outdoor"
                    ],
                    "261049754": [
                        "Indoor"
                    ]
                },
                "Demogr.": {
                    "202540963": [
                        "\u2717"
                    ],
                    "1815453": [
                        "\u2717"
                    ],
                    "4633086": [
                        "\u2713"
                    ],
                    "247996921": [
                        "\u2717"
                    ],
                    "244906176": [
                        "\u2713"
                    ],
                    "252263212": [
                        "\u2717"
                    ],
                    "261049754": [
                        "\u2713"
                    ]
                },
                "BMI": {
                    "202540963": [
                        "\u2717"
                    ],
                    "1815453": [
                        "\u2717"
                    ],
                    "4633086": [
                        "\u2717"
                    ],
                    "247996921": [
                        "\u2717"
                    ],
                    "244906176": [
                        "\u2717"
                    ],
                    "252263212": [
                        "\u2717"
                    ],
                    "261049754": [
                        "\u2713"
                    ]
                },
                "Particularity": {
                    "202540963": [
                        "time difference"
                    ],
                    "1815453": [
                        "\u2013"
                    ],
                    "4633086": [
                        "treadmill"
                    ],
                    "247996921": [
                        "collected in a supermarket"
                    ],
                    "244906176": [
                        "\u2013"
                    ],
                    "252263212": [
                        "auto labelled with 42 attributes"
                    ],
                    "261049754": [
                        "17 psychological traits"
                    ]
                }
            }
        },
        {
            "id": 17,
            "tab_id": "e816c01a-4fb4-4c23-ac5d-15b0242c82e4",
            "table": {
                "Approach": {
                    "246411621": [
                        "CoT "
                    ],
                    "252762395": [
                        "ReAct "
                    ],
                    "257900871": [
                        "Self-refine "
                    ],
                    "258865812": [
                        "RAP "
                    ],
                    "258833055": [
                        "Reflexion "
                    ],
                    "260611249": [
                        "Retroformer (our method)"
                    ]
                },
                "Gradient learning": {
                    "246411621": [
                        "\u2717"
                    ],
                    "252762395": [
                        "\u2717"
                    ],
                    "257900871": [
                        "\u2717"
                    ],
                    "258865812": [
                        "\u2717"
                    ],
                    "258833055": [
                        "\u2717"
                    ],
                    "260611249": [
                        "\u2713"
                    ]
                },
                "Arbitrary reward": {
                    "246411621": [
                        "\u2717"
                    ],
                    "252762395": [
                        "\u2717"
                    ],
                    "257900871": [
                        "\u2717"
                    ],
                    "258865812": [
                        "\u2717"
                    ],
                    "258833055": [
                        "\u2717"
                    ],
                    "260611249": [
                        "\u2713"
                    ]
                },
                "Iterative refinement": {
                    "246411621": [
                        "\u2717"
                    ],
                    "252762395": [
                        "\u2717"
                    ],
                    "257900871": [
                        "\u2713"
                    ],
                    "258865812": [
                        "\u2713"
                    ],
                    "258833055": [
                        "\u2713"
                    ],
                    "260611249": [
                        "\u2713"
                    ]
                },
                "Hidden constraints": {
                    "246411621": [
                        "\u2717"
                    ],
                    "252762395": [
                        "\u2713"
                    ],
                    "257900871": [
                        "\u2717"
                    ],
                    "258865812": [
                        "\u2713"
                    ],
                    "258833055": [
                        "\u2713"
                    ],
                    "260611249": [
                        "\u2713"
                    ]
                },
                "Decision making": {
                    "246411621": [
                        "\u2717"
                    ],
                    "252762395": [
                        "\u2713"
                    ],
                    "257900871": [
                        "\u2717"
                    ],
                    "258865812": [
                        "\u2713"
                    ],
                    "258833055": [
                        "\u2713"
                    ],
                    "260611249": [
                        "\u2713"
                    ]
                },
                "Memory": {
                    "246411621": [
                        "\u2717"
                    ],
                    "252762395": [
                        "\u2713"
                    ],
                    "257900871": [
                        "\u2717"
                    ],
                    "258865812": [
                        "\u2713"
                    ],
                    "258833055": [
                        "\u2713"
                    ],
                    "260611249": [
                        "\u2713"
                    ]
                }
            }
        },
        {
            "id": 18,
            "tab_id": "254278b5-ee90-4d52-88e1-fadc9531e8a0",
            "table": {
                "Method": {
                    "222177159": [
                        "Adversarial patch "
                    ],
                    "250426022": [
                        "AOP "
                    ],
                    "257279866": [
                        "APARATE "
                    ],
                    "260682704": [
                        "SAAM (ours)"
                    ]
                },
                "Attack goal": {
                    "222177159": [
                        "M"
                    ],
                    "250426022": [
                        "M"
                    ],
                    "257279866": [
                        "M, H"
                    ],
                    "260682704": [
                        "M, H"
                    ]
                },
                "Attacker's Knowledge": {
                    "222177159": [
                        "White-box"
                    ],
                    "250426022": [
                        "White-box"
                    ],
                    "257279866": [
                        "White-box"
                    ],
                    "260682704": [
                        "White-box"
                    ]
                },
                "Stealthy": {
                    "222177159": [
                        "\u00d7"
                    ],
                    "250426022": [
                        "-"
                    ],
                    "257279866": [
                        "\u00d7"
                    ],
                    "260682704": [
                        "-"
                    ]
                },
                "Placement": {
                    "222177159": [
                        "A"
                    ],
                    "250426022": [
                        "O"
                    ],
                    "257279866": [
                        "O"
                    ],
                    "260682704": [
                        "O, A"
                    ]
                },
                "Setting": {
                    "222177159": [
                        "Outdoor"
                    ],
                    "250426022": [
                        "Outdoor"
                    ],
                    "257279866": [
                        "Outdoor"
                    ],
                    "260682704": [
                        "Indoor"
                    ]
                }
            }
        },
        {
            "id": 19,
            "tab_id": "ba04afbc-1ef6-407a-93db-56d82d5671d7",
            "table": {
                "Method": {
                    "53751136": [
                        "N2V"
                    ],
                    "59523708": [
                        "N2S"
                    ],
                    "173990717": [
                        "PN2V "
                    ],
                    "225062070": [
                        "Noise2Same "
                    ],
                    "219619080": [
                        "S2S "
                    ],
                    "247447122": [
                        "B2UB"
                    ]
                },
                "Other needs": {
                    "53751136": [
                        "-"
                    ],
                    "59523708": [
                        "-"
                    ],
                    "173990717": [
                        "An arbitrary noise model"
                    ],
                    "225062070": [
                        "-"
                    ],
                    "219619080": [
                        "-"
                    ],
                    "247447122": [
                        "-"
                    ]
                },
                "Applications (denoising type)": {
                    "53751136": [
                        "Gaussian noise and some biomedical image noise denoising."
                    ],
                    "59523708": [
                        "Blind Gaussian noise denoising"
                    ],
                    "173990717": [
                        "Microscopy and low-light condition image noise denoising"
                    ],
                    "225062070": [
                        "Gaussian noise denoising."
                    ],
                    "219619080": [
                        "Blind Gaussian, salt-and-pepper and real-world sRGB image noise denoising"
                    ],
                    "247447122": [
                        "FMDD, Gaussian, Poisson and real-world rawRGB image noise denoising"
                    ]
                },
                "Key words (remarks)": {
                    "53751136": [
                        "Pixel-wise independent noise, randomly select several pixel to mask in the input images."
                    ],
                    "59523708": [
                        "J -invariant function determines the mask distribution, and replaces the pixels at J with random numbers."
                    ],
                    "173990717": [
                        "Mask input images, probabilistic model, predict per-pixel intensity distributions."
                    ],
                    "225062070": [
                        "J-invariant function determines the mask distribution, and replaces the pixels at J with local averages."
                    ],
                    "219619080": [
                        "Bernoulli-sampled instances of the input image results on noisy pairs"
                    ],
                    "247447122": [
                        "Gobal-aware mask mapper, re-visible loss."
                    ]
                }
            }
        },
        {
            "id": 20,
            "tab_id": "d3a4840b-f497-4bfb-9c6a-7d2e5c7c7b0a",
            "table": {
                "Method": {
                    "247996703": [
                        "Text2LIVE"
                    ],
                    "254974187": [
                        "Tune-A-Video"
                    ],
                    "261031087": [
                        "StableVideo (ours)"
                    ]
                },
                "Video Training": {
                    "247996703": [
                        "\u223c 10 hr"
                    ],
                    "254974187": [
                        "\u223c -"
                    ],
                    "261031087": [
                        "\u223c 10 hr"
                    ]
                },
                "Edit Training": {
                    "247996703": [
                        "\u223c 1 hours"
                    ],
                    "254974187": [
                        "30 min"
                    ],
                    "261031087": [
                        "-"
                    ]
                },
                "Edit Inference": {
                    "247996703": [
                        "\u223c 10 sec"
                    ],
                    "254974187": [
                        "\u223c 4 min"
                    ],
                    "261031087": [
                        "\u223c 30 sec"
                    ]
                }
            }
        },
        {
            "id": 21,
            "tab_id": "e0bdb237-b51f-4c8a-af12-aa5107284905",
            "table": {
                "Dataset": {
                    "7319196": [
                        "Recipe1M+ "
                    ],
                    "234470115": [
                        "FoodSeg103 "
                    ],
                    "206822288": [
                        "UPMC Food-101 "
                    ],
                    "14915460": [
                        "UEC Food256 "
                    ],
                    "207240186": [
                        "VIREO Food-172 "
                    ],
                    "211117398": [
                        "Sushi-50 "
                    ],
                    "37105431": [
                        "ChineseFoodNet "
                    ],
                    "3914807": [
                        "Yummly-66k "
                    ],
                    "221112548": [
                        "ISIA Food-500 "
                    ],
                    "260681484": [
                        "Food-500 Cap"
                    ]
                },
                "Image Number": {
                    "7319196": [
                        "13M"
                    ],
                    "234470115": [
                        "7,118"
                    ],
                    "206822288": [
                        "90,840"
                    ],
                    "14915460": [
                        "25,088"
                    ],
                    "207240186": [
                        "110,241"
                    ],
                    "211117398": [
                        "3,963"
                    ],
                    "37105431": [
                        "185,628"
                    ],
                    "3914807": [
                        "66,615"
                    ],
                    "221112548": [
                        "399,726"
                    ],
                    "260681484": [
                        "24,700"
                    ]
                },
                "Category-Number": {
                    "7319196": [
                        "-"
                    ],
                    "234470115": [
                        "103"
                    ],
                    "206822288": [
                        "101"
                    ],
                    "14915460": [
                        "256"
                    ],
                    "207240186": [
                        "172"
                    ],
                    "211117398": [
                        "50"
                    ],
                    "37105431": [
                        "208"
                    ],
                    "3914807": [
                        "-"
                    ],
                    "221112548": [
                        "500"
                    ],
                    "260681484": [
                        "494"
                    ]
                },
                "Category-Coverage": {
                    "7319196": [
                        "-"
                    ],
                    "234470115": [
                        "Worldwide"
                    ],
                    "206822288": [
                        "Western"
                    ],
                    "14915460": [
                        "Japanese"
                    ],
                    "207240186": [
                        "Chinese"
                    ],
                    "211117398": [
                        "Japanese"
                    ],
                    "37105431": [
                        "Chinese"
                    ],
                    "3914807": [
                        "-"
                    ],
                    "221112548": [
                        "Worldwide"
                    ],
                    "260681484": [
                        "Worldwide"
                    ]
                },
                "Annotation-type": {
                    "7319196": [
                        "Ingredients & Cooking instructions"
                    ],
                    "234470115": [
                        "Ingredients"
                    ],
                    "206822288": [
                        "Related web text"
                    ],
                    "14915460": [
                        "-"
                    ],
                    "207240186": [
                        "Ingredients & Cooking instructions"
                    ],
                    "211117398": [
                        "-"
                    ],
                    "37105431": [
                        "-"
                    ],
                    "3914807": [
                        "Course & ingredients & region"
                    ],
                    "221112548": [
                        "-"
                    ],
                    "260681484": [
                        "Image Captions & region"
                    ]
                },
                "Annotation-source": {
                    "7319196": [
                        "Web"
                    ],
                    "234470115": [
                        "Manual"
                    ],
                    "206822288": [
                        "Web"
                    ],
                    "14915460": [
                        "-"
                    ],
                    "207240186": [
                        "Web"
                    ],
                    "211117398": [
                        "-"
                    ],
                    "37105431": [
                        "-"
                    ],
                    "3914807": [
                        "Web"
                    ],
                    "221112548": [
                        "-"
                    ],
                    "260681484": [
                        "Manual"
                    ]
                }
            }
        },
        {
            "id": 22,
            "tab_id": "9a34d702-e100-4c93-b280-35b662fc1cbe",
            "table": {
                "Defense Method": {
                    "23714201": [
                        "CutOut "
                    ],
                    "3162051": [
                        "MixUp "
                    ],
                    "152282661": [
                        "CutMix "
                    ],
                    "256416324": [
                        "JPEG (used in )"
                    ],
                    "257532941": [
                        "AVATAR "
                    ],
                    "257766788": [
                        "U-Max "
                    ],
                    "3488815": [
                        "AT "
                    ],
                    "260680386": [
                        "Standard"
                    ]
                },
                "Type": {
                    "23714201": [
                        "Data augmentations"
                    ],
                    "3162051": [
                        "Data augmentations"
                    ],
                    "152282661": [
                        "Data augmentations"
                    ],
                    "256416324": [
                        "Data preprocessing"
                    ],
                    "257532941": [
                        "Data preprocessing"
                    ],
                    "257766788": [
                        "Training-phase defense"
                    ],
                    "3488815": [
                        "Training-phase defense"
                    ],
                    "260680386": [
                        "Data augmentations"
                    ]
                },
                "Time Cost": {
                    "23714201": [
                        "Low"
                    ],
                    "3162051": [
                        "Low"
                    ],
                    "152282661": [
                        "Low"
                    ],
                    "256416324": [
                        "Low"
                    ],
                    "257532941": [
                        "High"
                    ],
                    "257766788": [
                        "High"
                    ],
                    "3488815": [
                        "High"
                    ],
                    "260680386": [
                        "Low"
                    ]
                },
                "Description": {
                    "23714201": [
                        "Random image erasing"
                    ],
                    "3162051": [
                        "Random image blending"
                    ],
                    "152282661": [
                        "Random image cutting and stitching"
                    ],
                    "256416324": [
                        "Image compression"
                    ],
                    "257532941": [
                        "Image corruption and restoration"
                    ],
                    "257766788": [
                        "Adversarial augmentations"
                    ],
                    "3488815": [
                        "Adversarial training"
                    ],
                    "260680386": [
                        "Random image cropping and flipping"
                    ]
                }
            }
        },
        {
            "id": 23,
            "tab_id": "a4751f48-857a-4785-ad8a-e690dd719028",
            "table": {
                "Model": {
                    "195497272": [
                        "GLCN"
                    ],
                    "202558560": [
                        "JLGCN"
                    ],
                    "94822": [
                        "DGCNN"
                    ],
                    "85543335": [
                        "LDS"
                    ],
                    "214003631": [
                        "IDGL"
                    ],
                    "210698881": [
                        "Graph-Bert"
                    ],
                    "208139383": [
                        "GRCN"
                    ],
                    "231855665": [
                        "SLAPS"
                    ],
                    "246015780": [
                        "SUBLIME"
                    ],
                    "245219275": [
                        "VIB-GSL"
                    ]
                },
                "Input": {
                    "195497272": [
                        "features"
                    ],
                    "202558560": [
                        "features"
                    ],
                    "94822": [
                        "features"
                    ],
                    "85543335": [
                        "features"
                    ],
                    "214003631": [
                        "features"
                    ],
                    "210698881": [
                        "features, WL and spectral"
                    ],
                    "208139383": [
                        "features"
                    ],
                    "231855665": [
                        "features"
                    ],
                    "246015780": [
                        "features"
                    ],
                    "245219275": [
                        "features"
                    ]
                },
                "Edge scorer": {
                    "195497272": [
                        "MLP"
                    ],
                    "202558560": [
                        "MLP"
                    ],
                    "94822": [
                        "MLP"
                    ],
                    "85543335": [
                        "FP"
                    ],
                    "214003631": [
                        "ATT"
                    ],
                    "210698881": [
                        "MLP"
                    ],
                    "208139383": [
                        "MLP"
                    ],
                    "231855665": [
                        "FP, MLP, ATT"
                    ],
                    "246015780": [
                        "FP, MLP, ATT"
                    ],
                    "245219275": [
                        "MLP"
                    ]
                },
                "Sparsifier": {
                    "195497272": [
                        "none"
                    ],
                    "202558560": [
                        "none"
                    ],
                    "94822": [
                        "kNN"
                    ],
                    "85543335": [
                        "Bernoulli"
                    ],
                    "214003631": [
                        "\u03f5NN"
                    ],
                    "210698881": [
                        "none"
                    ],
                    "208139383": [
                        "kNN"
                    ],
                    "231855665": [
                        "kNN"
                    ],
                    "246015780": [
                        "kNN"
                    ],
                    "245219275": [
                        "Bernoulli"
                    ]
                },
                "Processor": {
                    "195497272": [
                        "activation"
                    ],
                    "202558560": [
                        "activation"
                    ],
                    "94822": [
                        "activation"
                    ],
                    "85543335": [
                        "none"
                    ],
                    "214003631": [
                        "activation"
                    ],
                    "210698881": [
                        "activation"
                    ],
                    "208139383": [
                        "none"
                    ],
                    "231855665": [
                        "activation-sym"
                    ],
                    "246015780": [
                        "activation-sym"
                    ],
                    "245219275": [
                        "none"
                    ]
                },
                "Regularizers": {
                    "195497272": [
                        "sparse-connect, closeness, log-barrier"
                    ],
                    "202558560": [
                        "smoothness"
                    ],
                    "94822": [
                        "none"
                    ],
                    "85543335": [
                        "none"
                    ],
                    "214003631": [
                        "sparse-connect, log-barrier"
                    ],
                    "210698881": [
                        "none"
                    ],
                    "208139383": [
                        "none"
                    ],
                    "231855665": [
                        "none"
                    ],
                    "246015780": [
                        "none"
                    ],
                    "245219275": [
                        "none"
                    ]
                },
                "Unsupervised Losses": {
                    "195497272": [
                        "none"
                    ],
                    "202558560": [
                        "none"
                    ],
                    "94822": [
                        "none"
                    ],
                    "85543335": [
                        "none"
                    ],
                    "214003631": [
                        "none"
                    ],
                    "210698881": [
                        "none"
                    ],
                    "208139383": [
                        "none"
                    ],
                    "231855665": [
                        "denoising"
                    ],
                    "246015780": [
                        "contrastive"
                    ],
                    "245219275": [
                        "denoising"
                    ]
                }
            }
        },
        {
            "id": 24,
            "tab_id": "199fe872-0610-48fc-a187-4394add0d91f",
            "table": {
                "Method": {
                    "254926784": [
                        "MultiInstruct "
                    ],
                    "258352455": [
                        "Owl "
                    ],
                    "258615266": [
                        "InstructBLIP"
                    ],
                    "259095896": [
                        "M 3 IT "
                    ],
                    "259165040": [
                        "LVLM"
                    ],
                    "263860779": [
                        "GAVIE"
                    ],
                    "260887670": [
                        "VisIT-Bench"
                    ]
                },
                "Number of Models": {
                    "254926784": [
                        "1"
                    ],
                    "258352455": [
                        "5"
                    ],
                    "258615266": [
                        "3"
                    ],
                    "259095896": [
                        "4"
                    ],
                    "259165040": [
                        "8"
                    ],
                    "263860779": [
                        "5"
                    ],
                    "260887670": [
                        "10"
                    ]
                },
                "Number of Skills Tested": {
                    "254926784": [
                        "9"
                    ],
                    "258352455": [
                        "6"
                    ],
                    "258615266": [
                        "13"
                    ],
                    "259095896": [
                        "13"
                    ],
                    "259165040": [
                        "47"
                    ],
                    "263860779": [
                        "16"
                    ],
                    "260887670": [
                        "70"
                    ]
                },
                "Multiple-Images": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2717"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                },
                "Video": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2717"
                    ],
                    "258615266": [
                        "\u2713"
                    ],
                    "259095896": [
                        "\u2713"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2717"
                    ]
                },
                "Multi-Turn Conversations": {
                    "254926784": [
                        "\u2713"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2713"
                    ],
                    "259095896": [
                        "\u2713"
                    ],
                    "259165040": [
                        "\u2713"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2717"
                    ]
                },
                "Multilingual Conversations": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2713"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2717"
                    ]
                },
                "Instruction-conditioned Captions": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2717"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2717"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                },
                "Chatbot-style Responses": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2717"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2717"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                },
                "Dataset-specific Evaluation": {
                    "254926784": [
                        "\u2713"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2713"
                    ],
                    "259095896": [
                        "\u2713"
                    ],
                    "259165040": [
                        "\u2713"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2717"
                    ]
                },
                "Human Evaluation": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2717"
                    ],
                    "259165040": [
                        "\u2713"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                },
                "Auto/GPT-4 Evaluation": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2713"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2713"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                },
                "Win-rates*": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2713"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2713"
                    ],
                    "259165040": [
                        "\u2717"
                    ],
                    "263860779": [
                        "\u2713"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                },
                "Elo Rating": {
                    "254926784": [
                        "\u2717"
                    ],
                    "258352455": [
                        "\u2717"
                    ],
                    "258615266": [
                        "\u2717"
                    ],
                    "259095896": [
                        "\u2717"
                    ],
                    "259165040": [
                        "\u2713"
                    ],
                    "263860779": [
                        "\u2717"
                    ],
                    "260887670": [
                        "\u2713"
                    ]
                }
            }
        },
        {
            "id": 25,
            "tab_id": "01fcc1e8-bb38-4360-851a-3ba035d3b355",
            "table": {
                "Dataset": {
                    "8945673": [
                        "NIH Chest X-Ray "
                    ],
                    "53759905": [
                        "Fast MRI "
                    ],
                    "218865062": [
                        "PTB Dataset "
                    ],
                    "33285731": [
                        "MIMIC II "
                    ]
                },
                "Data Type": {
                    "8945673": [
                        "Adult X-Ray Images"
                    ],
                    "53759905": [
                        "Brain Tissue Scans"
                    ],
                    "218865062": [
                        "ECG Waveforms"
                    ],
                    "33285731": [
                        "Clinical and Vital Signs"
                    ]
                },
                "Format": {
                    "8945673": [
                        "PNG"
                    ],
                    "53759905": [
                        "3D Arrays"
                    ],
                    "218865062": [
                        "Signal"
                    ],
                    "33285731": [
                        "Tabular, Signal"
                    ]
                },
                "No. Classes": {
                    "8945673": [
                        "13"
                    ],
                    "53759905": [
                        "2"
                    ],
                    "218865062": [
                        "10"
                    ],
                    "33285731": [
                        "59"
                    ]
                },
                "Size": {
                    "8945673": [
                        "25k"
                    ],
                    "53759905": [
                        "8k"
                    ],
                    "218865062": [
                        "<1k"
                    ],
                    "33285731": [
                        "30k"
                    ]
                },
                "Base Model": {
                    "8945673": [
                        "ResNet-34"
                    ],
                    "53759905": [
                        "U-Net"
                    ],
                    "218865062": [
                        "ResNet-18"
                    ],
                    "33285731": [
                        "XGBoost"
                    ]
                }
            }
        },
        {
            "id": 26,
            "tab_id": "ca93e9fc-b206-43af-957e-5f635558fde0",
            "table": {
                "Works": {
                    "14093453": [
                        "RLBL"
                    ],
                    "32370905": [
                        "RIB"
                    ],
                    "50768534": [
                        "BINN"
                    ],
                    "51609715": [
                        "CBS"
                    ],
                    "196171043": [
                        "DIPN"
                    ],
                    "210883769": [
                        "HUP"
                    ],
                    "235571722": [
                        "IARS"
                    ],
                    "235324699": [
                        "DeepRec"
                    ],
                    "247398476": [
                        "MBN"
                    ]
                },
                "Data Perspective": {
                    "14093453": [
                        "A sequence of (item, behavior) pairs"
                    ],
                    "32370905": [
                        "A sequence of (item, behavior) pairs"
                    ],
                    "50768534": [
                        "A sequence of (item, behavior) pairs"
                    ],
                    "51609715": [
                        "Some behavior-specific subsequences of items"
                    ],
                    "196171043": [
                        "Some behavior-specific subsequences of items"
                    ],
                    "210883769": [
                        "A sequence of (item, behavior) pairs"
                    ],
                    "235571722": [
                        "A sequence of (item, behavior) pairs"
                    ],
                    "235324699": [
                        "Some behavior-specific subsequences of items"
                    ],
                    "247398476": [
                        "Some behavior-specific subsequences of items"
                    ]
                },
                "Model Perspective": {
                    "14093453": [
                        "Local"
                    ],
                    "32370905": [
                        "Local"
                    ],
                    "50768534": [
                        "Local"
                    ],
                    "51609715": [
                        "Local"
                    ],
                    "196171043": [
                        "Local"
                    ],
                    "210883769": [
                        "Local"
                    ],
                    "235571722": [
                        "Local"
                    ],
                    "235324699": [
                        "Local + Global"
                    ],
                    "247398476": [
                        "Local"
                    ]
                },
                "Features": {
                    "14093453": [
                        "Capture the influence of heterogeneous behaviors by utilizing a behavior transition matrix."
                    ],
                    "32370905": [
                        "Leverage GRU and attention mechanism simultaneously."
                    ],
                    "50768534": [
                        "Design the CLSTM and the Bi-CLSTM, where the behavior vector is as context in LSTM."
                    ],
                    "51609715": [
                        "Design of models with and without shared parameters for behaviors simultaneously; towards the next-basket recommendation."
                    ],
                    "196171043": [
                        "Leverage GRU and attention mechanism simultaneously; behaviors are specific, including swipe, touch and browse interactive behavior."
                    ],
                    "210883769": [
                        "Design the Behavior-LSTM where adds behavior gate and time gate to the LSTM; leverage attention mechanism; take into account the category of the items."
                    ],
                    "235571722": [
                        "Propose Soft-MGRU (a multi-behavior gated recurrent unit) with sharing parameters between behaviors; leverage attention mechanism; take into account the category of the items."
                    ],
                    "235324699": [
                        "Utilizing multi-behavior sequence data to make privacy-preserving recommendation."
                    ],
                    "247398476": [
                        "The overall Meta-RNN and the separate Behavior-RNN share the learned potential representations by gathering and then scattering; towards the next-basket recommendation."
                    ]
                }
            }
        },
        {
            "id": 27,
            "tab_id": "d5efb5c3-ff9c-4944-b60d-c70574c8ed7c",
            "table": {
                "Method": {
                    "59523656": [
                        "EDA "
                    ],
                    "15600925": [
                        "Back-Translation "
                    ],
                    "249062776": [
                        "SeemSeek "
                    ],
                    "248863311": [
                        "Dialog Inpainting "
                    ],
                    "259370708": [
                        "AutoConv (Ours)"
                    ]
                },
                "DG": {
                    "59523656": [
                        "\u2717"
                    ],
                    "15600925": [
                        "\u2717"
                    ],
                    "249062776": [
                        "\u2714"
                    ],
                    "248863311": [
                        "\u2714"
                    ],
                    "259370708": [
                        "\u2714"
                    ]
                },
                "Data Needs": {
                    "59523656": [
                        "-"
                    ],
                    "15600925": [
                        "-"
                    ],
                    "249062776": [
                        "Large"
                    ],
                    "248863311": [
                        "Large"
                    ],
                    "259370708": [
                        "Few"
                    ]
                }
            }
        },
        {
            "id": 28,
            "tab_id": "7efdbf19-1e0e-4e51-830a-df5830384bc7",
            "table": {
                "Works": {
                    "211171550": [
                        "MGNN-SPred"
                    ],
                    "235358755": [
                        "DMBGN"
                    ],
                    "252216587": [
                        "GPG4HSR"
                    ],
                    "255894127": [
                        "BGNN"
                    ],
                    "256832144": [
                        "BA-GNN"
                    ]
                },
                "Data Perspective": {
                    "211171550": [
                        "Some behavior-specific subsequences of items"
                    ],
                    "235358755": [
                        "Some behavior-specific subsequences of items"
                    ],
                    "252216587": [
                        "A sequence of (item, behavior) pairs"
                    ],
                    "255894127": [
                        "Some behavior-specific subsequences of items"
                    ],
                    "256832144": [
                        "Some behavior-specific subsequence of items"
                    ]
                },
                "Model Perspective": {
                    "211171550": [
                        "Global"
                    ],
                    "235358755": [
                        "Global"
                    ],
                    "252216587": [
                        "Local + Global"
                    ],
                    "255894127": [
                        "Global"
                    ],
                    "256832144": [
                        "Global"
                    ]
                },
                "Features": {
                    "211171550": [
                        "Modeling behavior from behavior transition relations, containing homogeneous behavior transitions intra each kind of behavior-specific subsequences."
                    ],
                    "235358755": [
                        "Focus on the task of voucher redemption rate prediction and model the relationship between multiple behaviors and vouchers effectively."
                    ],
                    "252216587": [
                        "Learn various behavior transition relations from the global graph and the personalized graph, respectively."
                    ],
                    "255894127": [
                        "Construct directed graphs for different behavior transition (homogeneous and heterogeneous) information."
                    ],
                    "256832144": [
                        "Construct directed graphs for different behavior-specific sequences respectively."
                    ]
                }
            }
        },
        {
            "id": 29,
            "tab_id": "99ae82e7-1829-4360-825b-1c668277bc86",
            "table": {
                "Tr. scorer": {
                    "202782600": [
                        "H-Score"
                    ],
                    "201303557": [
                        "NCE"
                    ],
                    "211572839": [
                        "LEEP"
                    ],
                    "227126796": [
                        "N-LEEP"
                    ],
                    "231985863": [
                        "LogME"
                    ],
                    "238744475": [
                        "Regularized H-Score"
                    ],
                    "244709516": [
                        "GBC"
                    ]
                },
                "Cat.": {
                    "202782600": [
                        "fb"
                    ],
                    "201303557": [
                        "lb"
                    ],
                    "211572839": [
                        "lb"
                    ],
                    "227126796": [
                        "fb"
                    ],
                    "231985863": [
                        "fb"
                    ],
                    "238744475": [
                        "fb"
                    ],
                    "244709516": [
                        "fb"
                    ]
                },
                "Scorer input": {
                    "202782600": [
                        "source feature extractor & labels"
                    ],
                    "201303557": [
                        "source classification head & labels"
                    ],
                    "211572839": [
                        "source classification head & labels"
                    ],
                    "227126796": [
                        "source feature extractor & labels"
                    ],
                    "231985863": [
                        "source feature extractor & labels"
                    ],
                    "238744475": [
                        "source feature extractor & labels"
                    ],
                    "244709516": [
                        "source feature extractor & labels"
                    ]
                },
                "Details": {
                    "202782600": [
                        "transferability correlates to inter-class variance and feature redundancy"
                    ],
                    "201303557": [
                        "negative conditional entropy between source and target labels"
                    ],
                    "211572839": [
                        "log-likelihood between target labels and source model predictions"
                    ],
                    "227126796": [
                        "log-likelihood between target labels and Gaussian mixture model fit to target extracted features"
                    ],
                    "231985863": [
                        "probability of target labels conditioned on target image embeddings"
                    ],
                    "238744475": [
                        "shrinkage estimators for stable covariance"
                    ],
                    "244709516": [
                        "Bhattacharyya coeff. between multivariate Gaussians fit to each class\u2019 feature estimating overlap with target task classes"
                    ]
                }
            }
        },
        {
            "id": 30,
            "tab_id": "8d85c51b-a012-4dfc-b2c7-c7930c473701",
            "table": {
                "Operations": {
                    "202775981": [
                        "CondConv "
                    ],
                    "2097418": [
                        "DynamicFilter "
                    ],
                    "233444201": [
                        "DDF "
                    ],
                    "218630285": [
                        "TAM "
                    ],
                    "260866000": [
                        "midgreyTAdaConv(V2)"
                    ]
                },
                "Temporal modeling": {
                    "202775981": [
                        "\u2717"
                    ],
                    "2097418": [
                        "\u2717"
                    ],
                    "233444201": [
                        "\u2717"
                    ],
                    "218630285": [
                        "\u2713"
                    ],
                    "260866000": [
                        "\u2713"
                    ]
                },
                "Location adaptive": {
                    "202775981": [
                        "\u2717"
                    ],
                    "2097418": [
                        "\u2717"
                    ],
                    "233444201": [
                        "\u2713"
                    ],
                    "218630285": [
                        "\u2717"
                    ],
                    "260866000": [
                        "\u2713"
                    ]
                },
                "Pretrained weights": {
                    "202775981": [
                        "\u2717"
                    ],
                    "2097418": [
                        "\u2717"
                    ],
                    "233444201": [
                        "\u2717"
                    ],
                    "218630285": [
                        "\u2717"
                    ],
                    "260866000": [
                        "\u2713"
                    ]
                }
            }
        }
    ],
    "pred": {
        "hard": {
            "baseline": {
                "mistral": [
                    {
                        "id": 0,
                        "tab_id": "b42af37c-c83f-4cc0-8cc8-e7221c6a8d0f",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 1,
                        "tab_id": "da17cb75-5655-4f95-bffc-c918a7ecb473",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 2,
                        "tab_id": "361b11db-c0a0-4286-9b88-15e2b801a181",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 3,
                        "tab_id": "ff0a2460-7c6f-409b-8f91-30d45d25268d",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 4,
                        "tab_id": "f83bb26c-2ea8-4a4f-b121-f69e4ebe9619",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 5,
                        "tab_id": "d63d3952-e30a-4a05-8415-b13226eff27e",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 6,
                        "tab_id": "d3b56d4e-6535-4c7e-a634-dae53c7aa8f5",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 7,
                        "tab_id": "b9e280ca-7a97-4486-b953-059737120e77",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 8,
                        "tab_id": "d94c8049-6696-4812-b3dc-1da0df7ffaee",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 9,
                        "tab_id": "3f8046c8-4fd5-40aa-a10f-b06c1fdfb796",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 10,
                        "tab_id": "8b29f176-220d-4c3a-aecd-3ec67a6fb864",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 11,
                        "tab_id": "5ac6483b-03ae-448e-a80a-b453d252023b",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 12,
                        "tab_id": "488bdd5f-7ba5-4295-8895-aa0a0b67a1ab",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 13,
                        "tab_id": "8b1d0c59-2fa6-45b3-9b45-291056ee3725",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 14,
                        "tab_id": "20317c3b-01c9-4813-9868-1b7139fc7c74",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 15,
                        "tab_id": "a9d669ae-0620-464b-addf-d5c677d93c1e",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 16,
                        "tab_id": "6840a3c6-7ae9-412f-bed3-78e666859dcf",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 17,
                        "tab_id": "e816c01a-4fb4-4c23-ac5d-15b0242c82e4",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 18,
                        "tab_id": "254278b5-ee90-4d52-88e1-fadc9531e8a0",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 19,
                        "tab_id": "ba04afbc-1ef6-407a-93db-56d82d5671d7",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 20,
                        "tab_id": "d3a4840b-f497-4bfb-9c6a-7d2e5c7c7b0a",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 21,
                        "tab_id": "e0bdb237-b51f-4c8a-af12-aa5107284905",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 22,
                        "tab_id": "9a34d702-e100-4c93-b280-35b662fc1cbe",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 23,
                        "tab_id": "a4751f48-857a-4785-ad8a-e690dd719028",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 24,
                        "tab_id": "199fe872-0610-48fc-a187-4394add0d91f",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 25,
                        "tab_id": "01fcc1e8-bb38-4360-851a-3ba035d3b355",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 26,
                        "tab_id": "ca93e9fc-b206-43af-957e-5f635558fde0",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 27,
                        "tab_id": "d5efb5c3-ff9c-4944-b60d-c70574c8ed7c",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 28,
                        "tab_id": "7efdbf19-1e0e-4e51-830a-df5830384bc7",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 29,
                        "tab_id": "99ae82e7-1829-4360-825b-1c668277bc86",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 30,
                        "tab_id": "8d85c51b-a012-4dfc-b2c7-c7930c473701",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    }
                ],
                "gpt4": [
                    {
                        "id": 0,
                        "tab_id": "b42af37c-c83f-4cc0-8cc8-e7221c6a8d0f",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 1,
                        "tab_id": "da17cb75-5655-4f95-bffc-c918a7ecb473",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 2,
                        "tab_id": "361b11db-c0a0-4286-9b88-15e2b801a181",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 3,
                        "tab_id": "ff0a2460-7c6f-409b-8f91-30d45d25268d",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 4,
                        "tab_id": "f83bb26c-2ea8-4a4f-b121-f69e4ebe9619",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 5,
                        "tab_id": "d63d3952-e30a-4a05-8415-b13226eff27e",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 6,
                        "tab_id": "d3b56d4e-6535-4c7e-a634-dae53c7aa8f5",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 7,
                        "tab_id": "b9e280ca-7a97-4486-b953-059737120e77",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 8,
                        "tab_id": "d94c8049-6696-4812-b3dc-1da0df7ffaee",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 9,
                        "tab_id": "3f8046c8-4fd5-40aa-a10f-b06c1fdfb796",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 10,
                        "tab_id": "8b29f176-220d-4c3a-aecd-3ec67a6fb864",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 11,
                        "tab_id": "5ac6483b-03ae-448e-a80a-b453d252023b",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 12,
                        "tab_id": "488bdd5f-7ba5-4295-8895-aa0a0b67a1ab",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 13,
                        "tab_id": "8b1d0c59-2fa6-45b3-9b45-291056ee3725",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 14,
                        "tab_id": "20317c3b-01c9-4813-9868-1b7139fc7c74",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 15,
                        "tab_id": "a9d669ae-0620-464b-addf-d5c677d93c1e",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 16,
                        "tab_id": "6840a3c6-7ae9-412f-bed3-78e666859dcf",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 17,
                        "tab_id": "e816c01a-4fb4-4c23-ac5d-15b0242c82e4",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 18,
                        "tab_id": "254278b5-ee90-4d52-88e1-fadc9531e8a0",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 19,
                        "tab_id": "ba04afbc-1ef6-407a-93db-56d82d5671d7",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 20,
                        "tab_id": "d3a4840b-f497-4bfb-9c6a-7d2e5c7c7b0a",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 21,
                        "tab_id": "e0bdb237-b51f-4c8a-af12-aa5107284905",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 22,
                        "tab_id": "9a34d702-e100-4c93-b280-35b662fc1cbe",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 23,
                        "tab_id": "a4751f48-857a-4785-ad8a-e690dd719028",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 24,
                        "tab_id": "199fe872-0610-48fc-a187-4394add0d91f",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 25,
                        "tab_id": "01fcc1e8-bb38-4360-851a-3ba035d3b355",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 26,
                        "tab_id": "ca93e9fc-b206-43af-957e-5f635558fde0",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 27,
                        "tab_id": "d5efb5c3-ff9c-4944-b60d-c70574c8ed7c",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 28,
                        "tab_id": "7efdbf19-1e0e-4e51-830a-df5830384bc7",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 29,
                        "tab_id": "99ae82e7-1829-4360-825b-1c668277bc86",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 30,
                        "tab_id": "8d85c51b-a012-4dfc-b2c7-c7930c473701",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    }
                ]
            },
            "ours": {
                "mistral": [
                    {
                        "id": 0,
                        "tab_id": "b42af37c-c83f-4cc0-8cc8-e7221c6a8d0f",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 1,
                        "tab_id": "da17cb75-5655-4f95-bffc-c918a7ecb473",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 2,
                        "tab_id": "361b11db-c0a0-4286-9b88-15e2b801a181",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 3,
                        "tab_id": "ff0a2460-7c6f-409b-8f91-30d45d25268d",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 4,
                        "tab_id": "f83bb26c-2ea8-4a4f-b121-f69e4ebe9619",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 5,
                        "tab_id": "d63d3952-e30a-4a05-8415-b13226eff27e",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 6,
                        "tab_id": "d3b56d4e-6535-4c7e-a634-dae53c7aa8f5",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 7,
                        "tab_id": "b9e280ca-7a97-4486-b953-059737120e77",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 8,
                        "tab_id": "d94c8049-6696-4812-b3dc-1da0df7ffaee",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 9,
                        "tab_id": "3f8046c8-4fd5-40aa-a10f-b06c1fdfb796",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 10,
                        "tab_id": "8b29f176-220d-4c3a-aecd-3ec67a6fb864",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 11,
                        "tab_id": "5ac6483b-03ae-448e-a80a-b453d252023b",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 12,
                        "tab_id": "488bdd5f-7ba5-4295-8895-aa0a0b67a1ab",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 13,
                        "tab_id": "8b1d0c59-2fa6-45b3-9b45-291056ee3725",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 14,
                        "tab_id": "20317c3b-01c9-4813-9868-1b7139fc7c74",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 15,
                        "tab_id": "a9d669ae-0620-464b-addf-d5c677d93c1e",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 16,
                        "tab_id": "6840a3c6-7ae9-412f-bed3-78e666859dcf",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 17,
                        "tab_id": "e816c01a-4fb4-4c23-ac5d-15b0242c82e4",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 18,
                        "tab_id": "254278b5-ee90-4d52-88e1-fadc9531e8a0",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 19,
                        "tab_id": "ba04afbc-1ef6-407a-93db-56d82d5671d7",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 20,
                        "tab_id": "d3a4840b-f497-4bfb-9c6a-7d2e5c7c7b0a",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 21,
                        "tab_id": "e0bdb237-b51f-4c8a-af12-aa5107284905",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 22,
                        "tab_id": "9a34d702-e100-4c93-b280-35b662fc1cbe",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 23,
                        "tab_id": "a4751f48-857a-4785-ad8a-e690dd719028",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 24,
                        "tab_id": "199fe872-0610-48fc-a187-4394add0d91f",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 25,
                        "tab_id": "01fcc1e8-bb38-4360-851a-3ba035d3b355",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 26,
                        "tab_id": "ca93e9fc-b206-43af-957e-5f635558fde0",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 27,
                        "tab_id": "d5efb5c3-ff9c-4944-b60d-c70574c8ed7c",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 28,
                        "tab_id": "7efdbf19-1e0e-4e51-830a-df5830384bc7",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 29,
                        "tab_id": "99ae82e7-1829-4360-825b-1c668277bc86",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 30,
                        "tab_id": "8d85c51b-a012-4dfc-b2c7-c7930c473701",
                        "table": {
                            "try_0": [
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with five quality ratings each and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Scope of Content": {
                                        "Paper 1": [
                                            "Real-world video sequences with authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Real-world videos captured by a large number of users with wide ranges of distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional videos commonly known as User Generated Content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, distorted videos and video patches"
                                        ],
                                        "Paper 5": [
                                            "In-the-wild videos with quality ratings"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Subjective quality assessment for natural video databases"
                                        ],
                                        "Paper 2": [
                                            "Improving No-Reference video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC compression research"
                                        ],
                                        "Paper 4": [
                                            "Advancing No-Reference VQA using the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "No-Reference VQA for real-world UGC"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification using Convolutional Neural Networks"
                                        ],
                                        "Paper 7": [
                                            "Human action video classification using Convolutional Neural Networks"
                                        ]
                                    },
                                    "Method": {
                                        "Paper 1": [
                                            "Subjective video quality annotation using public-domain video sequences"
                                        ],
                                        "Paper 2": [
                                            "Creation of a large-scale video quality assessment database, crowdsourcing of subjective video quality scores"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a large-scale UGC dataset with a novel sampling method and no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large subjective video quality dataset and two unique NR-VQA models"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a large in-the-wild VQA dataset and proposed efficient VQA approaches (MLSP-VQA)"
                                        ],
                                        "Paper 6": [
                                            "Evaluation of CNNs on large-scale video classification, multiresolution, foveated architecture"
                                        ],
                                        "Paper 7": [
                                            "Description of the DeepMind Kinetics human action video dataset and neural network architectures for human action classification"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 real-world distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos with 5 quality ratings each"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes, with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Type of Distortions": {
                                        "Paper 1": [
                                            "Real-world, authentic distortions"
                                        ],
                                        "Paper 2": [
                                            "Unique content, fixed resolutions, commingled distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC)"
                                        ],
                                        "Paper 4": [
                                            "Real-world, in-the-wild distortions"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "Large-scale video classification dataset"
                                        ],
                                        "Paper 7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Primary Focus": {
                                        "Paper 1": [
                                            "Subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "No-reference (NR) video quality prediction"
                                        ],
                                        "Paper 3": [
                                            "UGC video compression and evaluation"
                                        ],
                                        "Paper 4": [
                                            "No-reference (NR) perceptual video quality assessment (VQA)"
                                        ],
                                        "Paper 5": [
                                            "No-reference video quality assessment"
                                        ],
                                        "Paper 6": [
                                            "Convolutional Neural Networks (CNNs) for video classification"
                                        ],
                                        "Paper 7": [
                                            "Kinetics human action video dataset"
                                        ]
                                    },
                                    "Data Collection Method": {
                                        "Paper 1": [
                                            "Fairly sampled from a large public video dataset, YFCC100m"
                                        ],
                                        "Paper 2": [
                                            "Constructed a large-scale video quality assessment database containing 585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "A large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos"
                                        ],
                                        "Paper 4": [
                                            "Created the largest (by far) subjective video quality dataset"
                                        ],
                                        "Paper 5": [
                                            "A new in-the-wild VQA dataset"
                                        ],
                                        "Paper 6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Collected by downloading videos from YouTube"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "Paper 1": [
                                            "1,200 video sequences"
                                        ],
                                        "Paper 2": [
                                            "585 videos of unique content"
                                        ],
                                        "Paper 3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "Paper 4": [
                                            "39,000 distorted videos and 117,000 v-patches"
                                        ],
                                        "Paper 5": [
                                            "153,841 videos coarsely annotated and 1,596 videos with detailed annotations"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos"
                                        ],
                                        "Paper 7": [
                                            "400 human action classes with at least 400 video clips for each action"
                                        ]
                                    },
                                    "Purpose": {
                                        "Paper 1": [
                                            "Creation of a dataset for subjective video quality assessment (VQA)"
                                        ],
                                        "Paper 2": [
                                            "Construction of a large-scale video quality assessment database for no-reference (NR) video quality predictors"
                                        ],
                                        "Paper 3": [
                                            "Introduction of a dataset for research in UGC compression and quality assessment"
                                        ],
                                        "Paper 4": [
                                            "Creation of a large dataset and prediction models for no-reference (NR) VQA on real-world UGC video data"
                                        ],
                                        "Paper 5": [
                                            "Introduction of a no-reference in-the-wild VQA dataset and deep learning approaches for training at scale"
                                        ],
                                        "Paper 6": [
                                            "Extensive empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "Paper 7": [
                                            "Description of a large-scale human action video dataset and baseline performance figures for neural network architectures"
                                        ]
                                    },
                                    " distortion type": {
                                        "Paper 1": [
                                            "Real-world video sequences with corresponding subjective mean opinion scores"
                                        ],
                                        "Paper 2": [
                                            "Unique content with wide ranges of levels of complex, authentic distortions"
                                        ],
                                        "Paper 3": [
                                            "Non-professional, user-generated content (UGC) with various degradations"
                                        ],
                                        "Paper 4": [
                                            "Real-world distorted videos and space-time localized video patches"
                                        ],
                                        "Paper 5": [
                                            "Authentically distorted UGC videos in-the-wild"
                                        ],
                                        "Paper 6": [
                                            "1 million YouTube videos from 487 classes"
                                        ],
                                        "Paper 7": [
                                            "Human-focussed actions captured from YouTube videos, with different human-object and human-human interactions"
                                        ]
                                    },
                                    "Annotations and Ratings": {
                                        "Paper 1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "Paper 2": [
                                            "Large number of subjective video quality scores via crowdsourcing"
                                        ],
                                        "Paper 3": [
                                            "Video clips with no-reference objective quality metrics"
                                        ],
                                        "Paper 4": [
                                            "5.5M human perceptual quality annotations"
                                        ],
                                        "Paper 5": [
                                            "Quality ratings for UGC videos"
                                        ],
                                        "Paper 6": [
                                            "Top layers retrained on the UCF-101 Action Recognition dataset"
                                        ],
                                        "Paper 7": [
                                            "Neural network architectures trained and tested for human action classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    }
                ],
                "gpt4": [
                    {
                        "id": 0,
                        "tab_id": "b42af37c-c83f-4cc0-8cc8-e7221c6a8d0f",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 1,
                        "tab_id": "da17cb75-5655-4f95-bffc-c918a7ecb473",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 2,
                        "tab_id": "361b11db-c0a0-4286-9b88-15e2b801a181",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 3,
                        "tab_id": "ff0a2460-7c6f-409b-8f91-30d45d25268d",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 4,
                        "tab_id": "f83bb26c-2ea8-4a4f-b121-f69e4ebe9619",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 5,
                        "tab_id": "d63d3952-e30a-4a05-8415-b13226eff27e",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 6,
                        "tab_id": "d3b56d4e-6535-4c7e-a634-dae53c7aa8f5",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 7,
                        "tab_id": "b9e280ca-7a97-4486-b953-059737120e77",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 8,
                        "tab_id": "d94c8049-6696-4812-b3dc-1da0df7ffaee",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 9,
                        "tab_id": "3f8046c8-4fd5-40aa-a10f-b06c1fdfb796",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 10,
                        "tab_id": "8b29f176-220d-4c3a-aecd-3ec67a6fb864",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 11,
                        "tab_id": "5ac6483b-03ae-448e-a80a-b453d252023b",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 12,
                        "tab_id": "488bdd5f-7ba5-4295-8895-aa0a0b67a1ab",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 13,
                        "tab_id": "8b1d0c59-2fa6-45b3-9b45-291056ee3725",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 14,
                        "tab_id": "20317c3b-01c9-4813-9868-1b7139fc7c74",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 15,
                        "tab_id": "a9d669ae-0620-464b-addf-d5c677d93c1e",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 16,
                        "tab_id": "6840a3c6-7ae9-412f-bed3-78e666859dcf",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 17,
                        "tab_id": "e816c01a-4fb4-4c23-ac5d-15b0242c82e4",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 18,
                        "tab_id": "254278b5-ee90-4d52-88e1-fadc9531e8a0",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 19,
                        "tab_id": "ba04afbc-1ef6-407a-93db-56d82d5671d7",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 20,
                        "tab_id": "d3a4840b-f497-4bfb-9c6a-7d2e5c7c7b0a",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 21,
                        "tab_id": "e0bdb237-b51f-4c8a-af12-aa5107284905",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 22,
                        "tab_id": "9a34d702-e100-4c93-b280-35b662fc1cbe",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 23,
                        "tab_id": "a4751f48-857a-4785-ad8a-e690dd719028",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 24,
                        "tab_id": "199fe872-0610-48fc-a187-4394add0d91f",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 25,
                        "tab_id": "01fcc1e8-bb38-4360-851a-3ba035d3b355",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 26,
                        "tab_id": "ca93e9fc-b206-43af-957e-5f635558fde0",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 27,
                        "tab_id": "d5efb5c3-ff9c-4944-b60d-c70574c8ed7c",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 28,
                        "tab_id": "7efdbf19-1e0e-4e51-830a-df5830384bc7",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 29,
                        "tab_id": "99ae82e7-1829-4360-825b-1c668277bc86",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    },
                    {
                        "id": 30,
                        "tab_id": "8d85c51b-a012-4dfc-b2c7-c7930c473701",
                        "table": {
                            "try_0": [
                                {
                                    "Research Focus": {
                                        "paper_1": [
                                            "Subjective video quality assessment (VQA) with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective VQA study with diverse content and authentic distortions"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for video compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference VQA using local-to-global region-based approaches and perceptual distortion mapping"
                                        ],
                                        "paper_5": [
                                            "In-the-wild VQA dataset creation and deep feature-based VQA methods"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification using CNNs and spatio-temporal information"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset for classification with a focus on human-object and human-human interactions"
                                        ]
                                    },
                                    "Methodology": {
                                        "paper_1": [
                                            "Creation of a subjective VQA database (KoNViD-1k) from a public video dataset"
                                        ],
                                        "paper_2": [
                                            "Construction of LIVE Video Quality Challenge Database (LIVE-VQC) and conducting comparison of NR VQA predictors"
                                        ],
                                        "paper_3": [
                                            "Introduction of a large scale UGC dataset sampled from YouTube videos for research"
                                        ],
                                        "paper_4": [
                                            "Creation of the largest subjective VQA dataset and development of NR-VQA models"
                                        ],
                                        "paper_5": [
                                            "Creation of KonVid-150k dataset and proposal of MLSP-VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification using a new dataset of YouTube videos"
                                        ],
                                        "paper_7": [
                                            "Compilation of the Kinetics human action video dataset with a wide range of human-focused action classes"
                                        ]
                                    },
                                    "Dataset Size and Diversity": {
                                        "paper_1": [
                                            "1,200 video sequences representing a variety of content and distortions"
                                        ],
                                        "paper_2": [
                                            "585 videos with 205,000 opinion scores from 4,776 participants"
                                        ],
                                        "paper_3": [
                                            "1,500 20-sec video clips covering various categories and features"
                                        ],
                                        "paper_4": [
                                            "39,000 distorted videos, 117,000 video patches, and 5.5M annotations"
                                        ],
                                        "paper_5": [
                                            "153,841 videos with five quality ratings each, and 1,596 videos with a minimum of 89 ratings each"
                                        ],
                                        "paper_6": [
                                            "A new dataset of 1 million YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "A dataset containing at least 400 video clips for each of the 400 human action classes"
                                        ]
                                    },
                                    "Evaluation and Performance": {
                                        "paper_1": [
                                            "Challenges in creating a database for general-purpose VQA"
                                        ],
                                        "paper_2": [
                                            "Comparison and evaluation of leading NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "UGC compression and quality evaluation discussions, along with evaluation with NR metrics"
                                        ],
                                        "paper_4": [
                                            "State-of-the-art performance on 3 UGC datasets with region-based NR VQA"
                                        ],
                                        "paper_5": [
                                            "Benchmarking on KoNViD-1k dataset, showing improvements using MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Performance improvements in video classification, foveated architecture and analysis on UCF-101 dataset"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for trained classifiers and analysis on dataset imbalance and bias"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1,500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 video patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each of 400 actions"
                                        ]
                                    },
                                    "Content Type": {
                                        "paper_1": [
                                            "Real-world video sequences with 'in the wild' authentic distortions"
                                        ],
                                        "paper_2": [
                                            "Real-world videos with a wide range of authentic distortions"
                                        ],
                                        "paper_3": [
                                            "User Generated Content (UGC) with popular categories"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted 'in-the-wild' UGC videos"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated in-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "Videos from 487 classes for extensive video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video dataset with human-object and human-human interactions"
                                        ]
                                    },
                                    "Purpose/Objective": {
                                        "paper_1": [
                                            "VQA database intended for deep learning purposes"
                                        ],
                                        "paper_2": [
                                            "Advance NR video quality prediction and facilitate a large-scale subjective study"
                                        ],
                                        "paper_3": [
                                            "Address challenges for UGC compression and quality evaluation"
                                        ],
                                        "paper_4": [
                                            "Improve NR-VQA models on 'in-the-wild' UGC data"
                                        ],
                                        "paper_5": [
                                            "Provide a larger and diverse dataset for in-the-wild VQA and propose new VQA approaches"
                                        ],
                                        "paper_6": [
                                            "Empirical evaluation of CNNs on large-scale video classification"
                                        ],
                                        "paper_7": [
                                            "Human action video classification and analysis of data imbalance on classifier bias"
                                        ]
                                    },
                                    "Evaluation Metric / Approach": {
                                        "paper_1": [
                                            "Subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Crowdsourced subjective video quality scores, comparison of NR video quality predictors"
                                        ],
                                        "paper_3": [
                                            "Evaluation with no-reference objective quality metrics (Noise, Banding, SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Space-time localized video quality assessment with human annotations"
                                        ],
                                        "paper_5": [
                                            "Spearman rank-order correlation coefficient (SRCC) on quality ratings"
                                        ],
                                        "paper_6": [
                                            "Performance improvements measured against feature-based baselines and single-frame models"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for neural network architectures, analysis of bias due to dataset imbalance"
                                        ]
                                    }
                                },
                                {
                                    "Dataset Size": {
                                        "paper_1": [
                                            "1,200 video sequences"
                                        ],
                                        "paper_2": [
                                            "585 videos"
                                        ],
                                        "paper_3": [
                                            "1500 20 sec video clips"
                                        ],
                                        "paper_4": [
                                            "39,000 videos and 117,000 v-patches"
                                        ],
                                        "paper_5": [
                                            "153,841 videos"
                                        ],
                                        "paper_6": [
                                            "1 million YouTube videos"
                                        ],
                                        "paper_7": [
                                            "At least 400 clips for each 400 actions"
                                        ]
                                    },
                                    "Content Source": {
                                        "paper_1": [
                                            "Public-domain video sequences from YFCC100m"
                                        ],
                                        "paper_2": [
                                            "User captured videos with authentic distortions"
                                        ],
                                        "paper_3": [
                                            "YouTube videos"
                                        ],
                                        "paper_4": [
                                            "Real-world distorted UGC videos"
                                        ],
                                        "paper_5": [
                                            "In-the-wild videos"
                                        ],
                                        "paper_6": [
                                            "YouTube videos belonging to 487 classes"
                                        ],
                                        "paper_7": [
                                            "Different YouTube videos"
                                        ]
                                    },
                                    "Primary Task": {
                                        "paper_1": [
                                            "Video Quality Assessment (VQA) with subjective mean opinion scores (MOS)"
                                        ],
                                        "paper_2": [
                                            "Large-scale subjective video quality study"
                                        ],
                                        "paper_3": [
                                            "UGC dataset for compression and quality assessment research"
                                        ],
                                        "paper_4": [
                                            "No-reference Video Quality Assessment (NR VQA) with quality mapping"
                                        ],
                                        "paper_5": [
                                            "No-Reference Video Quality Assessment using deep features"
                                        ],
                                        "paper_6": [
                                            "Large-scale video classification with CNNs"
                                        ],
                                        "paper_7": [
                                            "Human action classification dataset"
                                        ]
                                    },
                                    "Quality Assessment Method": {
                                        "paper_1": [
                                            "Subjectively annotated with MOS"
                                        ],
                                        "paper_2": [
                                            "Subjective scores via crowdsourcing"
                                        ],
                                        "paper_3": [
                                            "No-reference objective quality metrics (Noise, Banding, and SLEEQ)"
                                        ],
                                        "paper_4": [
                                            "Subjective dataset and no-reference prediction models"
                                        ],
                                        "paper_5": [
                                            "Coarsely annotated sets, proposed MLSP-VQA models"
                                        ],
                                        "paper_6": [
                                            "Baseline models comparison"
                                        ],
                                        "paper_7": [
                                            "Baseline performance figures for classification"
                                        ]
                                    }
                                }
                            ]
                        },
                        "caption": {
                            "try_0": [
                                "N/A",
                                "N/A",
                                "N/A"
                            ]
                        }
                    }
                ]
            }
        },
        "medium": {
            "baseline": {
                "mistral": [],
                "gpt4": []
            },
            "ours": {
                "mistral": [],
                "gpt4": []
            }
        },
        "easiest": {}
    }
}