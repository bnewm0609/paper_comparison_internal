{
    "extract_presupposition": {
        "prompt": "Identify a presupposition of the given question as many as possible.\n\nQuestion: What is the problem with instructional videos online for online learners this paper tackles?\nPresupposition: This paper tackles the problem with instructional videos online for online learners.\n\nQuestion: What kind of human-AI collaboration is involved in this paper?\nPresupposition: Human-AI collaboration is involved in this paper.\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "evaluate_presupposition":{
        "prompt": "Identify whether a given paper satisfies a given presupposition based on a given title and abstract.\n\nPresupposition: This paper tackles the problem with instructional videos online for online learners.\nPaper title: Promptiverse: Scalable Generation of Scaffolding Prompts Through Human-AI Hybrid Knowledge Graph Annotation\nPaper abstract: Online learners are hugely diverse with varying prior knowledge, but most instructional videos online are created to be one-size-fits-all. Thus, learners may struggle to understand the content by only watching the videos. Providing scaffolding prompts can help learners overcome these struggles through questions and hints that relate different concepts in the videos and elicit meaningful learning. However, serving diverse learners would require a spectrum of scaffolding prompts, which incurs high authoring effort. In this work, we introduce Promptiverse, an approach for generating diverse, multi-turn scaffolding prompts at scale, powered by numerous traversal paths over knowledge graphs. To facilitate the construction of the knowledge graphs, we propose a hybrid human-AI annotation tool, Grannotate. In our study (N=24), participants produced 40 times more on-par quality prompts with higher diversity, through Promptiverse and Grannotate, compared to hand-designed prompts. Promptiverse presents a model for creating diverse and adaptive learning experiences online.\nSatisfied: True\n\nPresupposition: Human-AI collaboration is involved in this paper.\nPaper title: ConceptScape: Collaborative Concept Mapping for Video Learning\nPaper abstract: While video has become a widely adopted medium for online learning, existing video players provide limited support for navigation and learning. It is difficult to locate parts of the video that are linked to specific concepts. Also, most video players afford passive watching, thus making it difficult for learners with limited metacognitive skills to deeply engage with the content and reflect on their understanding. To support concept-driven navigation and comprehension of lecture videos, we present ConceptScape, a system that generates and presents a concept map for lecture videos. ConceptScape engages crowd workers to collaboratively generate a concept map by prompting them to externalize reflections on the video. We present two studies to show that (1) interactive concept maps can be useful tools for concept-based video navigation and comprehension, and (2) with ConceptScape, novice crowd workers can collaboratively generate complex concept maps that match the quality of those by experts.\nSatisfied: False\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "generate_answer":{
        "prompt": "Answer a given question based on a given paper's title and abstract a short phrase (within fifteen words).\n\nQuestion: What is the problem with instructional videos online for online learners this paper tackles?\nPaper title: ConceptScape: Collaborative Concept Mapping for Video Learning\nPaper abstract: While video has become a widely adopted medium for online learning, existing video players provide limited support for navigation and learning. It is difficult to locate parts of the video that are linked to specific concepts. Also, most video players afford passive watching, thus making it difficult for learners with limited metacognitive skills to deeply engage with the content and reflect on their understanding. To support concept-driven navigation and comprehension of lecture videos, we present ConceptScape, a system that generates and presents a concept map for lecture videos. ConceptScape engages crowd workers to collaboratively generate a concept map by prompting them to externalize reflections on the video. We present two studies to show that (1) interactive concept maps can be useful tools for concept-based video navigation and comprehension, and (2) with ConceptScape, novice crowd workers can collaboratively generate complex concept maps that match the quality of those by experts.\nAnswer: The paper tackles the limited support for navigation, comprehension, and active engagement in online instructional videos.\n\nQuestion: What kind of human-AI collaboration is involved in this paper?\nPaper title: Promptiverse: Scalable Generation of Scaffolding Prompts Through Human-AI Hybrid Knowledge Graph Annotation\nPaper abstract: Online learners are hugely diverse with varying prior knowledge, but most instructional videos online are created to be one-size-fits-all. Thus, learners may struggle to understand the content by only watching the videos. Providing scaffolding prompts can help learners overcome these struggles through questions and hints that relate different concepts in the videos and elicit meaningful learning. However, serving diverse learners would require a spectrum of scaffolding prompts, which incurs high authoring effort. In this work, we introduce Promptiverse, an approach for generating diverse, multi-turn scaffolding prompts at scale, powered by numerous traversal paths over knowledge graphs. To facilitate the construction of the knowledge graphs, we propose a hybrid human-AI annotation tool, Grannotate. First, Grannotate has two representations of an annotated graph: overlaid on the transcript and a graph visualization. Our tool also shows how prompts would be created out of the annotation. Finally, to alleviate the burden of having many options for entities and relation classes, our tool provides following AI-driven recommendations: 1) entity recommendation, 2) relation existence recommendation, and 3) relation class recommendation. In our study (N=24), participants produced 40 times more on-par quality prompts with higher diversity, through Promptiverse and Grannotate, compared to hand-designed prompts. Promptiverse presents a model for creating diverse and adaptive learning experiences online.\nAnswer: The paper involves human-AI collaboration in knowledge graph annotation for diverse scaffolding prompt generation.\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "is_repetitive":{
        "prompt": "Determine whether a given question is repetitive to a given question list.\n\nQuestion: What is the problem with instructional videos online for online learners this paper tackles?\nQuestion list: [“What learners’ problem does the paper address regarding online instructional videos?”, “What are the issues that online learners face when navigating online instructional videos as per the study?“, “What comprehension and engagement problems are discussed in this paper with regard to online instructional videos?“]\nRepetitive: True\n\nQuestion: What kind of human-AI collaboration is involved in this paper?\nQuestion list: [“What is the role of AI in this collaboration?”, “What are the benefits and challenges of using human-AI collaboration in knowledge graph annotation?“]\nRepetitive: False\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "generate_followup":{
        "prompt": "Generate a follow-up question that asks further information based on a given question and answer. Return a list of questions as follows: \"[\"<followup_question>\", ...]\"\n\nQuestion: What is the problem with instructional videos online for online learners this paper tackles?\nAnswer: The paper tackles the limited support for navigation, comprehension, and active engagement in online instructional videos.\nFollow-up question: [\"What solutions does the paper propose to improve navigation, comprehension, and active engagement in online instructional videos?\", \"How does the lack of support for navigation, comprehension, and active engagement affect online learners according to the paper?\"]\n\nQuestion: What kind of human-AI collaboration is involved in this paper?\nAnswer: The paper involves human-AI collaboration in knowledge graph annotation for diverse scaffolding prompt generation.\nFollow-up question: [\"Can you elaborate on how human-AI collaboration is utilized for diverse scaffolding prompt generation in knowledge graph annotation?\", \"What are the benefits and challenges of using human-AI collaboration in knowledge graph annotation?\", \"What is the role of AI in this collaboration?\"]\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "generate_lowlevel":{
        "prompt": "Generate low-level questions that ask for information already in the given answer to the main question. Prevent generating repetitive questions. Return a list of questions as follows: \"[\"<lowlevel_question>\", ...]\"\n\nMain question: What is the problem with instructional videos online for online learners this paper tackles?\nAnswer: The paper tackles the limited support for navigation, comprehension, and active engagement in online instructional videos.\nLow-level question: [\"What problem does this paper address?\", \"What is the issue with instructional videos online?\", \"Which videos does this paper address?\"]\n\nMain question: What kind of human-AI collaboration is involved in this paper?\nAnswer: The paper involves human-AI collaboration in knowledge graph annotation for diverse scaffolding prompt generation.\nLow-level question: [\"What type of collaboration does this paper involve?\", \"What kind of annotation is the human-AI collaboration involved in?\", \"What's the purpose of the knowledge graph annotation?\"]\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "generate_generic":{
        "prompt": "Generate questions by abstracting specific details from the original question and replacing them with general terms. Prevent generating repetitive questions. Return a list of questions as follows: \"[\"<generic_question>\", ...]\"\n\nOriginal Question: What kind of human-AI collaboration is involved in this paper used for prompt generation?\nGeneric questions: [\"What kind of human-AI collaboration is involved in this paper?\"]\n\nOriginal Question: What were the metrics used to measure the quality and diversity of the prompts in this paper?\nGeneric questions: [\"What were the metrics used to measure the quality and diversity of the artifacts?\", \"What were the metrics used to measure the artifacts?\"]\n\n",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "zero_shot_paper_to_table": {
        "prompt": "[System]\nWe would like you to build a table that has each paper as a row and each important dimension to be compared as a column. You will be given multiple papers labeled A, B, and C. You will be provided with the title of each paper and abstract.\n\n{paper}[System]\nPlease create a table that compares and contrasts given papers. Please identify relevant questions for which comparisons/contrasts can be made among the answers to the question acquired from each paper. Return the list of pairs of question and the dictionary of each paper's answer as a Python JSON object of the following format: \"{{\"<question that asks the content of given papers> \": {{\"paper_1\": [\"<answer to the identified question grounded on Paper 1>\"], \"paper_2\":[\" <answer to the identified question grounded on Paper 2>\"], \"paper_3\": [\"<answer to the identified question grounded on Paper 3>\"]}}, ..}}\n\n[Table]", 
        "prompt_max": "[System]\nWe would like you to build a table that has each paper as a row and each important dimension to be compared as a column. You will be given multiple papers labeled A, B, and C. You will be provided with the title of each paper and abstract.\n\n{paper}[System]\nPlease create a table that compares and contrasts given papers. Please identify questions for which comparisons/contrasts can be made with the answers to the questions acquired from each paper. Make questions as many as possible. Return the list of pairs of questions and the dictionary of each paper's answer as a Python JSON object of the following format: \"{{\"<question that asks the content of given papers> \": {{\"paper_1\": [\"<answer to the identified question grounded on Paper 1>\"], \"paper_2\":[\" <answer to the identified question grounded on Paper 2>\"], \"paper_3\": [\"<answer to the identified question grounded on Paper 3>\"]}}, ..}}\n\n[Table]", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "zero_shot_paper_to_cc": {
        "prompt": "[System]\nWe would like you to compare and contrast multiple research papers. You will be provided with the title of each paper and their abstracts. Make compare and contrast statements with the bullet points. One statement with one bullet point. \n\n{paper}[Response]", 
        "prompt_max": "[System]\nWe would like you to compare and contrast multiple research papers. You will be provided with the title of each paper and their abstracts. Make compare and contrast statements with the bullet points as many as possible. One statement with one bullet point. \n\n{paper}[Response]", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "zero_shot_cc_to_table": {
        "prompt": "[System]\nWe would like you to build a table that has each paper as a row and each important dimension to be compared as a column. You will be given multiple papers labeled A, B, and C. You will be provided with the title of each paper and abstract. You will also be given comparison and contrast statements to help you to build a table. {paper_cc}[System]\nPlease create a table that compares and contrasts given papers grounded on given statements. Please extract dimensions that compare those papers from each statement. For each of the extracted dimension, find the value relevant to the dimension from each paper. Return the list of pairs of dimension and the dictionary of each paper's value as a Python JSON object of the following format: \"{{\"<dimension of comparison and contrast from the given statements> \": {{\"paper_1\": [\"<relevant value to the identified dimension grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the identified dimension grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the identified dimension grounded on Paper 3>\"]}}, ..}}\"\n\n[Table]",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "zero_shot_paper_to_scheme": {
        "prompt": "[System]\nWe would like you to generate as many questions that can be answered with at least one paper as possible. You will be provided with the title of each paper and their abstracts. Return a list of questions as follows: \"[\"<question that can be answered with at least one paper>\", ...]\"\n\n{paper}[Response]",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "simplifying_table": {
        "prompt":"We would like you to compare and contrast multiple papers regarding the dimensions extracted from the question. You will be given multiple papers labeled Paper 1, 2, and so on. You will be provided with the title of each paper and abstract. You will also be given one question from which you need to extract information units to be asked.\n\n{paper}\n{question}\n\n[System]\nPlease create a one-column table that compares and contrasts given papers regarding the information units extracted from the question. Please extract which information units are asked in each question. For each of the extracted unit, find the value relevant to the dimension from each paper. Return the list of pairs of information unit and the dictionary of each paper’s value as a Python JSON object of the following format: \"{{\"<extracted informatioin unit from the given question> \": {{\"paper_1\": [\"<relevant value to the extracted unit grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the extracted unit grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the extracted unit grounded on Paper 3>\"]}}, ..}}\"\n\n[Table]",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "find_similarity": {
        "prompt_abstract": "[System]\nWe would like you to find similar aspects that multiple given research papers have. You will be provided with the title of each paper and their abstracts. Find similar aspects as many as possible. Return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\"\n\n{paper}[System]", 
        "prompt_intro": "[System]\nWe would like you to find similar aspects that multiple given research papers have. You will be provided with the title, abstract, and introduction of each paper. Find similar aspects as many as possible. Return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\"\n\n{paper}[System]", 
        "prompt_full": "[System]\nWe would like you to find similar aspects that multiple given research papers have. You will be provided with the title, abstract, and full text of each paper. Find similar aspects as many as possible. Return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\"\n\n{paper}[System]",
        "prompt_withoutmax": "[System]\nWe would like you to find similar aspects that multiple given research papers have. You will be provided with the title of each paper and their abstracts. Return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\"\n\n{paper}[System]", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "find_attributes": {
        "prompt1": "[System]\nWe would like you to identify attributes that are relevant to given research topic. You will be provided with a list of research topics. Find relevant attributes to each research topic as many as possible. Return the list of attributes for each research topics a Python JSON object of the following format: \"{{\"<given research topic 1>\": [\"<relevant attribute to research topic 1>\", ...], \"<given research topic 2>\":[\" <relevant attribute to research topic 2>\", ...], \"<given research topic 3>\":[\" <relevant attribute to research topic 3>\", ...]}}\"\n\n{topic_list}[System]", 
        "prompt2": "[System]\nI want to write related work section called \"{research_topic}\". We would like you to identify attributes that should be compared between related papers. You will be provided with a list of the title of each paper and abstract. Find attributes that can compare the given papers within the subsection called \"{research_topic}\". Return the list of attributes as a Python list object as follows: \"[\"<comparable attribute>\", \"<comparable attribute>\", ...]\". Do not write any other content except the attribute elements in the list.\n\n[Papers]\n{paper}\n\n[System]", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "value_generation": {
        "prompt_multiple_abstract": "[System]\nWe would like you to build a table that has each paper as a row and each given dimension as a column.  You will be given multiple papers labeled Paper 1, 2, and so on. You will be provided with the title of each paper and abstract. You will also be given table's caption and column names to help you to build a table. {paper_cc}\n[System]\nPlease create a table that compares and contrasts given papers based on the column name, interpreting each column within the context of the given caption. Please add more context from the caption into column name if needed. For each of the column name, find the value relevant to the column name from each paper. If there is no relevant value, only write down \"N/A\"Return the list of pairs of column name and the dictionary of each paper's value as a Python JSON object of the following format: \"{{\"<column name 1> \": {{\"paper_1\": [\"<relevant value to the column name grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the column name grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the column name grounded on Paper 3>\"]}}, ..}}\"\n\n[System]",
        "prompt_multiple_intro": "[System]\nWe would like you to build a table that has each paper as a row and each given dimension as a column.  You will be given multiple papers labeled Paper 1, 2, and so on. You will be provided with the title, abstract, and introduction of each paper. You will also be given table's caption and column names to help you to build a table. {paper_cc}\n[System]\nPlease create a table that compares and contrasts given papers based on the column name, interpreting each column within the context of the given caption. Please add more context from the caption into column name if needed. For each of the column name, find the value relevant to the column name from each paper. If there is no relevant value, only write down \"N/A\"Return the list of pairs of column name and the dictionary of each paper's value as a Python JSON object of the following format: \"{{\"<column name 1> \": {{\"paper_1\": [\"<relevant value to the column name grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the column name grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the column name grounded on Paper 3>\"]}}, ..}}\"\n\n[System]",
        "prompt_multiple_full": "[System]\nWe would like you to build a table that has each paper as a row and each given dimension as a column.  You will be given multiple papers labeled Paper 1, 2, and so on. You will be provided with the title and full text of each paper. You will also be given table's caption and column names to help you to build a table. {paper_cc}\n[System]\nPlease create a table that compares and contrasts given papers based on the column name, interpreting each column within the context of the given caption. Please add more context from the caption into column name if needed. For each of the column name, find the value relevant to the column name from each paper. If there is no relevant value, only write down \"N/A\"Return the list of pairs of column name and the dictionary of each paper's value as a Python JSON object of the following format: \"{{\"<column name 1> \": {{\"paper_1\": [\"<relevant value to the column name grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the column name grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the column name grounded on Paper 3>\"]}}, ..}}\"\n\n[System]",
        "prompt_single_abstract": "[System]\nWe would like you to build a table that has a relevant content from the given paper as a value and given dimension as a column. You will be provided with the title and abstract of given paper. You will also be given table's caption and column names to help you to build a table. {paper_cc}\n[System]\nPlease create a table that composes content of given papers based on the column name, interpreting each column within the context of the given caption. For each of the column name, find the value relevant to the column name from the given paper. If there is no relevant value, only write down \"N/A\". Return pairs of column index (e.g., column 1) and a value from the given paper as a Python dictionary object as a following format: \"{{\"column 1\": [\"<relevant value to the Column name 1 grounded on given Paper>\"], \"column 2\": [\"<relevant value to the Column name 2 grounded on given Paper>\"], ..}}\". Do not write any other comments with \"#\" except the value list as a value of each column.\n\n[System]",
        "prompt_single_intro": "[System]\nWe would like you to build a table that has a relevant content from the given paper as a value and given dimension as a column. You will be provided with the title, abstract, and introduction of given paper. You will also be given table's caption and column names to help you to build a table. {paper_cc}\n[System]\nPlease create a table that composes main content of given papers based on the column name, interpreting each column within the context of the given caption. For each of the column name, find the value relevant to the column name from the given paper. If there is no relevant value, only write down \"N/A\". Return pairs of column index (e.g., column 1) and a value from the given paper as a Python dictionary object as a following format: \"{{\"column 1\": [\"<relevant value to the Column name 1 grounded on given Paper>\"], \"column 2\": [\"<relevant value to the Column name 2 grounded on given Paper>\"], ..}}\". Do not write any other comments with \"#\" except the value list as a value of each column.\n\n[System]",
        "prompt_single_full": "[System]\nWe would like you to build a table that has a relevant content from the given paper as a value and given dimension as a column. You will be provided with the title and full text of given paper. You will also be given table's caption and column names to help you to build a table. {paper_cc}\n[System]\nPlease create a table that composes main content of given papers based on the column name, interpreting each column within the context of the given caption. For each of the column name, find the value relevant to the column name from the given paper. If there is no relevant value, only write down \"N/A\". Return pairs of column index (e.g., column 1) and a value from the given paper as a Python dictionary object as a following format: \"{{\"column 1\": [\"<relevant value to the Column name 1 grounded on given Paper>\"], \"column 2\": [\"<relevant value to the Column name 2 grounded on given Paper>\"], ..}}\". Do not write any other comments with \"#\" except the value list as a value of each column.\n\n[System]",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers."
    },
    "value_generation_qa": {
        "prompt_multiple_abstract": "[System]\nImagine the following scenario: A user is making a table with multiple papers to compare them in the scholarly paper. To compare and contrast the papers, the user provides the title and abstract of each paper. The user also provides the table's caption and column names indicating the aspects by which papers should be compared. Your task is the following: Given a list of papers and table information, you should fill the value in the table. Based on the given column names of the table, grounded on each paper, you should find the part that discusses the aspects provided as column names.\nFirst, you should explain your thinking about questions that need to be asked to find specific aspects of papers discussing the content related to column names in the given caption table. Then, find the answers to those questions in each paper. If there is no answer in the paper, only write down \"N/A\". After explaining your thinking, return a JSON object of the following format: \"{{\"<column name 1> \": {{\"paper_1\": [\"<relevant value to the column name grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the column name grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the column name grounded on Paper 3>\"], ..}}, ..}}\". **Before and after the JSON object, add the character \"[JSON]\"**.\n\n{input_info}",
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers.",
        "parse_str": "[JSON]"
    },
    "baseline_paper_to_table": {
        "prompt_simple": "[System]\nWe would like you to build a table that has each paper as a row and each dimension as a column that compare multiple papers. You will be given multiple papers labeled Paper 1, 2, and so on. You will be provided with title and abstract of each paper. Please create a table that compares and contrasts given papers. Make {col_num} dimensions which are phrases that can compare multiple papers, so that the table can have {col_num} columns. Table should have {paper_num} papers as rows. Return a JSON object of the following format: \"{{\"<dimension 1 that can compare papers>\": {{\"paper_1\": [\"<relevant value to the dimension 1 grounded on Paper 1>\"], \"paper_2\": [\"<relevant value to the dimension 1 grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the dimension 1 grounded on Paper 3>\"], ...}}, ...}}\". **Check if the table has {paper_num} papers as rows and {col_num} columns as columns. Before and after the JSON object, add the character \"[JSON]\"**.\n\n{input_info}",
        "prompt_medium": "[System]\nWe would like you to build a table that has each paper as a row and each dimension as a column that compare multiple papers. You will receive a series of papers, each identified as Paper 1, 2, and so forth, along with their titles and abstracts. You need to make a table that has a caption of \"{caption}\". Please create a table that compares and contrasts given papers. Make {col_num} dimensions which are phrases that can compare multiple papers, so that the table can have {col_num} columns. Table should have {paper_num} papers as rows. Return a JSON object of the following format: \"{{\"<dimension 1 that can compare papers>\": {{\"paper_1\": [\"<relevant value to the dimension 1 grounded on Paper 1>\"], \"paper_2\": [\"<relevant value to the dimension 1 grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the dimension 1 grounded on Paper 3>\"], ...}}, ...}}\". **Check if the table has {paper_num} papers as rows and {col_num} columns as columns. Before and after the JSON object, add the character \"[JSON]\"**.\n\n{input_info}",
        "prompt_max": "[System]\nWe would like you to build a table that has each paper as a row and each important dimension to be compared as a column. You will be given multiple papers labeled Paper 1, 2, and so on. You will be provided with title and abstract of each paper.\n\n{paper}[System]\nPlease create a table that compares and contrasts given papers. Please identify questions for which comparisons/contrasts can be made with the answers to the questions acquired from each paper. Make questions as many as possible. Return the list of pairs of questions and the dictionary of each paper's answer as a Python JSON object of the following format: \"{{\"<question that asks the content of given papers> \": {{\"paper_1\": [\"<answer to the identified question grounded on Paper 1>\"], \"paper_2\":[\" <answer to the identified question grounded on Paper 2>\"], \"paper_3\": [\"<answer to the identified question grounded on Paper 3>\"]}}, ..}}\n\n[Table]", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers.",
        "parse_str": "[JSON]"
    },
    "scheme_attribute_generation": {
        "prompt_abstract": "[System]\nImagine the following scenario: A user is making a table with multiple papers to compare them in the scholarly paper. To compare and contrast the papers, the user provides the title and abstract of each paper. Your task is the following: Given a list of papers, you should find  similar aspects that multiple given research papers have. Then, within each aspect, you should identify {num_attributes} number of attributes that can compare the given multiple papers.\nFirst, you should return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\". Then, think of each aspect as a related work section topic. Finally, find attributes that can compare the given papers within the related work section. Return a JSON object of the following format: \"{{\"<aspect 1> \": [\"<comparable attribute within the aspect 1>\", \"<comparable attribute within the aspect 1>\", ...], ..}}\". Before and after the JSON object, add the character \"[JSON]\".\n\n{input_info}",
        "prompt_intro": "[System]\nImagine the following scenario: A user is making a table with multiple papers to compare them in the scholarly paper. To compare and contrast the papers, the user provides the title and introduction of each paper. Your task is the following: Given a list of papers, you should find similar aspects that multiple given research papers have as many as possible. Then, within each aspect, you should identify attributes that can compare the given multiple papers.\nFirst, you should return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\". Then, think of each aspect as a related work section topic. Finally, find attributes that can compare the given papers within the related work section. Return a JSON object of the following format: \"{{\"<aspect 1> \": [\"<comparable attribute within the aspect 1>\", \"<comparable attribute within the aspect 1>\", ...], ..}}\". Before and after the JSON object, add the character \"[JSON]\".\n\n{input_info}",
        "prompt_full": "[System]\nImagine the following scenario: A user is making a table with multiple papers to compare them in the scholarly paper. To compare and contrast the papers, the user provides the title and full text of each paper. Your task is the following: Given a list of papers, you should find similar aspects that multiple given research papers have as many as possible. Then, within each aspect, you should identify attributes that can compare the given multiple papers.\nFirst, you should return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\". Then, think of each aspect as a related work section topic. Finally, find attributes that can compare the given papers within the related work section. Return a JSON object of the following format: \"{{\"<aspect 1> \": [\"<comparable attribute within the aspect 1>\", \"<comparable attribute within the aspect 1>\", ...], ..}}\". Before and after the JSON object, add the character \"[JSON]\".\n\n{input_info}",
        "prompt_withoutmax": "[System]\nImagine the following scenario: A user is making a table with multiple papers to compare them in the scholarly paper. To compare and contrast the papers, the user provides the title and abstract of each paper. Your task is the following: Given a list of papers, you should find similar aspects that multiple given research papers have. Then, within each aspect, you should identify attributes that can compare the given multiple papers.\nFirst, you should return the list of similar aspects as a Python list object as follows: \"[\"<similar aspect that all given papers shared>\", ...]\". Then, think of each aspect as a related work section topic. Finally, find attributes that can compare the given papers within the related work section. Return a JSON object of the following format: \"{{\"<aspect 1> \": [\"<comparable attribute within the aspect 1>\", \"<comparable attribute within the aspect 1>\", ...], ..}}\". Before and after the JSON object, add the character \"[JSON]\".\n\n{input_info}", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers.",
        "parse_str": "[JSON]"
    },
    "identify_best_scheme": {
        "prompt": "[System]\nImagine the following scenario: A user is making a table with multiple papers to compare them in the scholarly paper. To compare and contrast the given papers, the user provides the title and abstract of each paper. The user also provides several sets of potential table's captions and column names indicating the aspects by which papers should be compared. Your task is the following: Given a list of papers and potential table information, you should choose the best set that has unique and important aspects to compare the given papers.\nFirst, you should explain your thinking about what makes you choose the following set as the best set. After explaining your thinking, return a JSON object of the following format: \"{{\"<caption> \": [\"<column name within the chosen caption>\", \"<column name within the chosen caption>\", ...], ..}}\". Before and after the JSON object, add the character \"[JSON]\".\n\n{input_info}", 
        "system_instruction": "You are an intelligent and precise assistant that can understand the contents of research papers. You are knowledgable on different fields and domains of science, in particular computer science. You are able to interpret research papers, create questions and answers, and compare multiple papers.",
        "parse_str": "[JSON]"
    },
    "json_formatting": {
        "prompt": "[System]\nGiven the following string below, please format this information into a valid JSON object. Ensure that each piece of information is represented as a separate key-value pair in the JSON.\n\nThe JSON object should contain free-form columns of tables as keys and have dictionary composed of Paper indexes as keys and a list of free-form values as values. Return a JSON object of the following format: \"{{\"<column name 1> \": {{\"paper_1\": [\"<relevant value to the column name grounded on Paper 1>\"], \"paper_2\":[\" <relevant value to the column name grounded on Paper 2>\"], \"paper_3\": [\"<relevant value to the column name grounded on Paper 3>\"], ..}}, ..}}\". **Before and after the JSON object, add the character \"[JSON]\"**.\n\n[Input string]\n{input_info}",
        "system_instruction": "You are an intelligent and precise assistant that can format the data as guided.",
        "parse_str": "[JSON]"
    }
}
